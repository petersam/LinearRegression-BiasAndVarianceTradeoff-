{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear regression analysis :-\n",
    "\n",
    "- Group Number :13, Section 2\n",
    "\n",
    "\n",
    "- Group Member Names :-\n",
    "    - Bassetti, Chandrasheker\n",
    "    - Balla, Harshavardhan Reddy\n",
    "    - Adhikari, Shambhu\n",
    "    - Adabala, Likhita Chandana\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "Find best model\n",
    "\n",
    "- Including Bias-Variance Tradeoff\n",
    "\n",
    "- Prediction\n",
    "\n",
    "- Using numpy\n",
    "\n",
    "- Other libraries, e.g. scikit-learn, are not allowed for calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Abstract of the Report :-\n",
    "\n",
    "- This report is focussed on determining the the best model using Bias-variance tradeoff by adding prediction parameters. \n",
    "\n",
    "- All the calculation are done by using the numpy library. \n",
    "\n",
    "- For the main analysis, we are using the columns provided in the raw dataset to find the best fit model. \n",
    "\n",
    "- We see how multiple independent features also make a huge impact on the dependent features.  equation of simple linear regression y=A+Bx is converted to something like:\n",
    "                        \n",
    "                        equation:  y = A+B1x1+B2x2+B3x3+B4x4\n",
    "\n",
    "- We first implement Bias Variance Tadeoff using Linear regression by applying Gradient Descent method.\n",
    "\n",
    "- Different models are developed namely Lasso Regularization, Ridge Regularization and Elastic Net Regularization.\n",
    "\n",
    "- These results are compared using metrics like Mean Absolute Error, Root Mean Square Error and R square to determine the best fit model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Theory :- \n",
    "\n",
    "*Linear Regression*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is one of the most basic algorithms in the world of machine learning. It is the door to the magical world in front of us. \n",
    "But before we move on to the algorithm, let's first discuss the life cycle of a machine learning model. This figure creates a machine learning model from scratch, uses hyperparameter tuning to improve the same model for greater accuracy, determine the deployment strategy for that model, deploy it, and then set up a logging and monitoring framework. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Regression Analysis?\n",
    "\n",
    "Regression in statistics is the process of predicting a Label (or Dependent Variable) based on the features (Independent Variables) at hand. Regression is used for time series modelling and finding the causal effect relationship between the variables and forecasting. For example, the relationship between the stock prices of the company and various factors like customer reputation and company annual performance etc. can be studied using regression. \n",
    "\n",
    "Regression analysis is an important tool for analysing and modelling data. Here, the curve / line is fitted to the data point so that the difference in the distance of the actual data point from the drawn curve / line is minimized. This topic is discussed in detail in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The use of Regression\n",
    "\n",
    "The relationship between two or more features is investigated using regression analysis. Consider the following scenario:\n",
    "\n",
    "Let's say we want to create an application that predicts a student's odds of being admitted to a foreign university. If this is the case, the\n",
    "\n",
    "The following are some of the advantages of employing regression analysis:\n",
    "\n",
    "   * It shows the significant relationships between the Lable (dependent variable) and the features(independent variable).\n",
    "   * It shows the extent of the impact of multiple independent variables on the dependent variable.\n",
    "   *  It can also measure these effects even if the variables are on a different scale.\n",
    "\n",
    "These features enable the data scientists to find the best set of independent variables for predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression\n",
    "\n",
    "Simple Linear regression is a method for predicting a **quantitative response** using a **single feature** (\"input variable\"). The mathematical equation is:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x$\n",
    "\n",
    "What do terms represent?\n",
    "- $y$ is the response or the target variable\n",
    "- $x$ is the feature\n",
    "- $\\beta_1$ is the coefficient of x\n",
    "- $\\beta_0$ is the intercept\n",
    "\n",
    "$\\beta_0$ and $\\beta_1$ are the **model coefficients**. To create a model, we must \"learn\" the values of these coefficients. And once we have the value of these coefficients, we can use the model to predict the Sales!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating (\"Learning\") Model Coefficients\n",
    "\n",
    "The coefficients are estimated using the **least-squares criterion**,  i.e., the best fit line has to be calculated that minimizes the **sum of squared residuals** (or \"sum of squared errors\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The mathematics involved\n",
    "Take a quick look at the plot created. Now consider each point, and know that each of them has a coordinate in the form (X, Y). Now draw an imaginary line between each point and the current \"best-fit\" line. We'll call the distance between each point and the current best-fit line as D. To get a quick image of what we're trying to visualize, take a look at the picture below:\n",
    "\n",
    "<img src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Linear_least_squares_example2.svg/220px-Linear_least_squares_example2.svg.png\">\n",
    "\n",
    "What elements are present in the diagram?\n",
    "- The red points are the **observed values** of x and y.\n",
    "- The blue line is the **least squares line**.\n",
    "- The green lines are the **residuals**, which is the distance between the observed values and the least squares line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, we're labelling each green line as having a distance D, and each red point as having a coordinate of (X, Y). Then we can define our best fit line as the line having the property were:\n",
    "$$ D_{1}^2 + D_{2}^2 + D_{3}^2 + D_{4}^2 + ....+ D_{N}^2$$\n",
    "\n",
    "So how do we find this line? The least-square line approximating the set of points:\n",
    "\n",
    "$$ (X,Y)_{1},(X,Y)_{2},(X,Y)_{3},(X,Y)_{4},(X,Y)_{5}, $$\n",
    "\n",
    "has the equation:\n",
    "$$ Y = a_{0} +a_{1}X $$\n",
    "this is basically just a rewritten form of the standard equation for a line:\n",
    "$$Y=mx+b$$\n",
    "\n",
    "We can solve for these constants a0 and a1 by simultaneously solving these equations:\n",
    "$$ \\Sigma Y = a_{0}N + a_{1}\\Sigma X $$\n",
    "$$ \\Sigma XY = a_{0}\\Sigma X + a_{1}\\Sigma X^2 $$\n",
    "These are called the normal equations for the least-squares line. There are further steps that can be taken in rearranging these equations to solve for y, but we'll let scikit-learn do the rest of the heavy lifting here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs see the underlying assumptions: -\n",
    "* The regression model is linear in terms of coefficients and error term.\n",
    "* The mean of the residuals is zero.\n",
    "* The error terms are not correlated with each other, i.e. given an error value; we cannot predict the next error value.\n",
    "* The independent variables(x) are uncorrelated with the residual term, also termed as **exogeneity**. This, in layman term, generalises that in no way should the error term be predicted given the value of independent variables.\n",
    "* The error terms have a constant variance, i.e. **homoscedasticity**.\n",
    "* No Multicollinearity, i.e. no independent variables should be correlated with each other or affect one another. If there is multicollinearity, the precision of prediction by the OLS model decreases.\n",
    "* The error terms are normally distributed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general equation of a straight line is:$$ùë¶={mx+b}$$\n",
    "It means that if we have the value of m and b, we can predict all the values of y for corresponding x.\n",
    "During construction of a Linear Regression Model, the computer tries to calculate the values of m and b to get a straight line.\n",
    "But the question is:\n",
    "###### How Do you Know this is the best fit line?\n",
    "The best fit line is obtained by minimizing the _residual_.\n",
    "Residual is the distance between the actual Y and the predicted Y, as shown below:\n",
    "<img src=\"residual.png\" width=\"300\">\n",
    "Mathematically, Residual is: $$r={y-(mx+b)}$$\n",
    "Hence, the sum of the square of residuals is:\n",
    "<img src=\"sumOfResiduals.png\" width=\"300\">\n",
    "\n",
    "As we can see that the residual is both a function of m and b, so differentiating partially with respect to m and b will give us:\n",
    "<img src=\"partialDerivatives.png\" width=\"300\">\n",
    "\n",
    "For getting the best fit line, residual should be minimum. The minima of a function occurs where the derivative=0. So, equating our corresponding derivatives to 0, we get:\n",
    "<img src=\"minima.png\" width=\"300\">\n",
    "\n",
    "This same equation can be written in matrix form as:\n",
    "<img src=\"matrix1.png\" width=\"300\">\n",
    "\n",
    "Ideally, if we'd have an equation of one dependent and one independent variable the minima will look as follows:\n",
    "<img src=\"minima2.png\" width=\"300\">\n",
    "\n",
    "But as the residual's minima is dependent on two variables m and b, it becomes a _Paraboloid_ and the appropriate m and b are calculated using _*Gradient Descent*_ as shown below:\n",
    "<img src=\"GradientDescent.gif\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let‚Äôs understand how to check, how well the model fits our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new values for 'slope' and 'intercept' are caluclated as follows:\n",
    "\n",
    "<img src=\"new_m.PNG\" width=\"300\">\n",
    "\n",
    "where, $\\theta_0$ is 'intercept' , $\\theta_1$ is the slope, $\\alpha$ is the learning rate, m is the total number of observations and the term after the $\\sum$ sign is the loss. Google Tensor board recommends a Learning rate between 0.00001 and 10. Generally a smaller learning rate is recommended to avoid overshooting while creating a model.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization \n",
    "\n",
    "When we use regression models to train some data, there is a good chance that the model will overfit the given training data set.  Regularization helps sort this overfitting problem by restricting the degrees of freedom of a given equation i.e. simply reducing the number of degrees of a polynomial function by reducing their corresponding weights.  \n",
    "In a linear equation, we do not want huge weights/coefficients as a small change in weight can make a large difference for the dependent variable (Y). So, regularization constraints the weights of such features to avoid overfitting. Simple linear regression is given as:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x1+ \\beta_2x2 +\\beta_3x3+...+\\beta_PxP$\n",
    "\n",
    "Using the OLS method, we try to minimize the cost function given as:\n",
    "\n",
    "<img src=\"RSS_reg.PNG\" width=\"300\">\n",
    "\n",
    "To regularize the model, a Shrinkage penalty is added to the cost function.\n",
    "Let‚Äôs see different types of regularizations in regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO (Least Absolute Shrinkage and Selection Operator) Regression (L1 Form)\n",
    "LASSO regression penalizes the model based on the sum of magnitude of the coefficients. The regularization term is given by\n",
    "\n",
    " regularization=$ \\lambda *\\sum  |\\beta_j| $\n",
    "\n",
    "Where, Œª is the shrinkage factor.\n",
    "\n",
    "and hence the formula for loss after regularization is:\n",
    "\n",
    "<img src=\"L1.PNG\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression (L2 Form)\n",
    "Ridge regression penalizes the model based on the sum of squares of magnitude of the coefficients. The regularization term is given by\n",
    "\n",
    " regularization=$ \\lambda *\\sum  |\\beta_j ^ 2| $\n",
    "\n",
    "Where, Œª is the shrinkage factor.\n",
    "\n",
    "and hence the formula for loss after regularization is:\n",
    "\n",
    "<img src=\"ridge.PNG\" width=\"300\">\n",
    "\n",
    "This value of lambda can be anything and should be calculated by cross validation as to what suits the model.\n",
    "\n",
    "Let‚Äôs consider $\\beta_1$ and $\\beta_2$ be coefficients of a linear regression and Œª = 1:\n",
    "\n",
    "For Lasso, $\\beta_1$ + $\\beta_2$ <= s  \n",
    "\n",
    "For Ridge, $\\beta_1^2$ + $\\beta_2^2$  <= s  \n",
    "\n",
    "Where s is the maximum value the equations can achieve\n",
    ".\n",
    "If we plot both the above equations, we get the following graph:\n",
    "\n",
    "<img src=\"ridge_vs_lasso.PNG\" width=\"500\">\n",
    "\n",
    "The red ellipse represents the cost function of the model, whereas the square (left side) represents the Lasso regression and the circle (right side) represents the Ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net\n",
    "\n",
    "According to the Hands-on Machine Learning book, elastic Net is a middle ground between Ridge Regression and Lasso Regression. The regularization term is a simple mix of both Ridge and Lasso‚Äôs regularization terms, and you can control the mix ratio Œ±. \n",
    "\n",
    "<img src=\"elasticNet.PNG\" width=\"300\">\n",
    "where Œ± is the mixing parameter between ridge (Œ±‚ÄÑ=‚ÄÑ0) and lasso (Œ±‚ÄÑ=‚ÄÑ1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why use Regularization?\n",
    "Regularization reduces the model's variance without significantly increasing the bias. If the model has variance, it won't fit well for datasets that aren't the same as the training data. This bias and variance tradeoff is controlled by the tuning setting. When the value of is increased up to a specific point, the variance is reduced without any key qualities in the data being lost. However, beyond a certain point, the model begins to lose some crucial properties, increasing the bias in the data. As a result, selecting an appropriate value of is crucial\n",
    "\n",
    "The value of Œª is selected using cross-validation methods. A set of Œª is selected and cross-validation error is calculated for each value of Œª and that value of Œª is selected for which the cross-validation error is minimum.\n",
    "\n",
    "##### When should you use plain Linear Regression (i.e., without any regularization), Ridge, Lasso, or Elastic Net?\n",
    "\n",
    "According to the Hands-on Machine Learning book, it is almost always preferable to have at least a little bit of regularization, so generally you should avoid plain Linear Regression. Ridge is a good default, but if you suspect that only a few features are actually useful, you should prefer Lasso or Elastic Net since they tend to reduce the useless features‚Äô weights down to zero as we have discussed. In general, Elastic Net is preferred over Lasso since Lasso may behave erratically when the number of features is greater than the number of\n",
    "training instances or when several features are strongly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias Variance Trade-off:\n",
    "\n",
    "Variance: Captures how much your classifier changes if you train on a different training set. How \"over-specialized\" is your classifier to a particular training set (overfitting)? If we have the best possible model for our training data, how far off are we from the average classifier?\n",
    "\n",
    "Bias: What is the inherent error that you obtain from your classifier even with infinite training data? This is due to your classifier being \"biased\" to a particular kind of solution (e.g. linear classifier). In other words, bias is inherent to your model.\n",
    "\n",
    "Noise: How big is the data-intrinsic noise? This error measures ambiguity due to your data distribution and feature representation. You can never beat this, it is an aspect of the data.\n",
    "\n",
    "\n",
    "The bias-variance trade-off is a central problem in supervised learning. One wants to choose model that both accurately captures the regularities in its training data, but also generalizes well to unseen data. It is typically impossible to do both simultaneously. High variance learning methods may be able to represent their training set well but are at risk of overfitting to noisy or unrepresentative training data. In contrast, algorithms with high bias typically produce simpler models that may fail to capture important regularities (i.e., underfit) in the data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                       Graphical illustration of bias and variance\n",
    "<img src=\"bullseye.PNG\" width=\"300\">\n",
    "\n",
    "\n",
    "The variation of Bias and Variance with the model complexity. This is similar to the concept of overfitting and underfitting. More complex models overfit while the simplest models underfit\n",
    "\n",
    "<img src=\"BiasVariance.PNG\" width=\"300\">\n",
    "\n",
    "#### Detecting High Bias and High Variance\n",
    "\n",
    "If a classifier is under-performing (e.g. if the test or training error is too high), there are several ways to improve performance. To find out which of these many techniques is the right one for the situation, the first step is to determine the root of the problem.\n",
    "\n",
    "                        Test and training error as the number of training instances increases.\n",
    "\n",
    "<img src=\"Traininginstances.PNG\" width=\"300\">\n",
    "\n",
    "The graph above plots the training error and the test error and can be divided into two overarching regimes. In the first regime (on the left side of the graph), training error is below the desired error threshold (denoted by œµ), but test error is significantly higher. In the second regime (on the right side of the graph), test error is remarkably close to training error, but both are above the desired tolerance of œµ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis Results & Explanation :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data file\n",
    "X= pd.read_csv('S22_M4DS_PRJ_01_LinReg_data_X.csv')\n",
    "y= pd.read_csv('S22_M4DS_PRJ_01_LinReg_data_Y.csv')\n",
    "X = X.dropna(axis=1)\n",
    "y = y.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.099362</td>\n",
       "      <td>-0.085577</td>\n",
       "      <td>-0.143910</td>\n",
       "      <td>-0.104020</td>\n",
       "      <td>0.294070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.166140</td>\n",
       "      <td>0.277080</td>\n",
       "      <td>-0.190330</td>\n",
       "      <td>-0.056387</td>\n",
       "      <td>-0.134220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.252780</td>\n",
       "      <td>-0.085391</td>\n",
       "      <td>-0.096496</td>\n",
       "      <td>0.422420</td>\n",
       "      <td>-0.270440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072448</td>\n",
       "      <td>0.554370</td>\n",
       "      <td>-0.046507</td>\n",
       "      <td>0.325990</td>\n",
       "      <td>-0.333080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.266970</td>\n",
       "      <td>-0.108820</td>\n",
       "      <td>0.038903</td>\n",
       "      <td>0.215480</td>\n",
       "      <td>-0.448170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.026047</td>\n",
       "      <td>-0.113850</td>\n",
       "      <td>-0.216470</td>\n",
       "      <td>-0.277540</td>\n",
       "      <td>-0.508570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.269570</td>\n",
       "      <td>-0.174100</td>\n",
       "      <td>-0.165340</td>\n",
       "      <td>0.340080</td>\n",
       "      <td>-0.344010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.058377</td>\n",
       "      <td>0.219050</td>\n",
       "      <td>-0.130630</td>\n",
       "      <td>-0.289320</td>\n",
       "      <td>-0.184430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.064301</td>\n",
       "      <td>0.113230</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.145940</td>\n",
       "      <td>-0.229670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.204890</td>\n",
       "      <td>-0.009512</td>\n",
       "      <td>0.096320</td>\n",
       "      <td>-0.063046</td>\n",
       "      <td>-0.211770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.112310</td>\n",
       "      <td>0.189110</td>\n",
       "      <td>-0.272530</td>\n",
       "      <td>0.253770</td>\n",
       "      <td>-0.237380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010858</td>\n",
       "      <td>-0.093202</td>\n",
       "      <td>0.178020</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>-0.199840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.057883</td>\n",
       "      <td>0.056138</td>\n",
       "      <td>0.115670</td>\n",
       "      <td>-0.118620</td>\n",
       "      <td>0.065630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.094047</td>\n",
       "      <td>-0.333480</td>\n",
       "      <td>-0.188190</td>\n",
       "      <td>0.126990</td>\n",
       "      <td>0.090238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.386070</td>\n",
       "      <td>0.364860</td>\n",
       "      <td>0.118390</td>\n",
       "      <td>-0.095188</td>\n",
       "      <td>0.113360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.430270</td>\n",
       "      <td>-0.097851</td>\n",
       "      <td>-0.125630</td>\n",
       "      <td>-0.052929</td>\n",
       "      <td>0.225460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.101340</td>\n",
       "      <td>-0.062144</td>\n",
       "      <td>-0.139700</td>\n",
       "      <td>-0.242580</td>\n",
       "      <td>0.055439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.100710</td>\n",
       "      <td>0.404470</td>\n",
       "      <td>0.076967</td>\n",
       "      <td>-0.194820</td>\n",
       "      <td>0.105150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.103310</td>\n",
       "      <td>-0.094876</td>\n",
       "      <td>0.142240</td>\n",
       "      <td>0.416660</td>\n",
       "      <td>-0.032058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.052583</td>\n",
       "      <td>-0.245330</td>\n",
       "      <td>0.179940</td>\n",
       "      <td>0.212020</td>\n",
       "      <td>0.145170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.242900</td>\n",
       "      <td>-0.023089</td>\n",
       "      <td>0.013480</td>\n",
       "      <td>-0.565800</td>\n",
       "      <td>0.105400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.187240</td>\n",
       "      <td>0.246390</td>\n",
       "      <td>-0.074786</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.491430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.069239</td>\n",
       "      <td>0.376950</td>\n",
       "      <td>0.278210</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>0.142690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.502970</td>\n",
       "      <td>-0.191210</td>\n",
       "      <td>-0.051006</td>\n",
       "      <td>-0.057027</td>\n",
       "      <td>0.324640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.106270</td>\n",
       "      <td>0.312040</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>-0.577580</td>\n",
       "      <td>0.349500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.188960</td>\n",
       "      <td>-0.008210</td>\n",
       "      <td>0.645770</td>\n",
       "      <td>0.290260</td>\n",
       "      <td>-0.086992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.154030</td>\n",
       "      <td>0.029357</td>\n",
       "      <td>0.270570</td>\n",
       "      <td>-0.019890</td>\n",
       "      <td>-0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.497030</td>\n",
       "      <td>-0.425920</td>\n",
       "      <td>0.176660</td>\n",
       "      <td>0.279120</td>\n",
       "      <td>0.132740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.124290</td>\n",
       "      <td>0.121970</td>\n",
       "      <td>-0.354230</td>\n",
       "      <td>-0.347460</td>\n",
       "      <td>-0.095941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.051966</td>\n",
       "      <td>-0.445630</td>\n",
       "      <td>-0.087070</td>\n",
       "      <td>-0.114910</td>\n",
       "      <td>-0.021618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.072571</td>\n",
       "      <td>0.146150</td>\n",
       "      <td>0.117740</td>\n",
       "      <td>0.361720</td>\n",
       "      <td>0.322150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.183650</td>\n",
       "      <td>-0.251100</td>\n",
       "      <td>-0.217830</td>\n",
       "      <td>0.065908</td>\n",
       "      <td>0.188180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.081465</td>\n",
       "      <td>-0.254440</td>\n",
       "      <td>-0.116630</td>\n",
       "      <td>-0.338500</td>\n",
       "      <td>0.031079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.200930</td>\n",
       "      <td>-0.307450</td>\n",
       "      <td>-0.099281</td>\n",
       "      <td>-0.251160</td>\n",
       "      <td>0.156110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1        X2        X3        X4        X5\n",
       "0  -0.099362 -0.085577 -0.143910 -0.104020  0.294070\n",
       "1  -0.166140  0.277080 -0.190330 -0.056387 -0.134220\n",
       "2  -0.252780 -0.085391 -0.096496  0.422420 -0.270440\n",
       "3   0.072448  0.554370 -0.046507  0.325990 -0.333080\n",
       "4  -0.266970 -0.108820  0.038903  0.215480 -0.448170\n",
       "5  -0.026047 -0.113850 -0.216470 -0.277540 -0.508570\n",
       "6  -0.269570 -0.174100 -0.165340  0.340080 -0.344010\n",
       "7   0.058377  0.219050 -0.130630 -0.289320 -0.184430\n",
       "8   0.064301  0.113230  0.012695  0.145940 -0.229670\n",
       "9  -0.204890 -0.009512  0.096320 -0.063046 -0.211770\n",
       "10  0.112310  0.189110 -0.272530  0.253770 -0.237380\n",
       "11  0.010858 -0.093202  0.178020  0.149020 -0.199840\n",
       "12  0.057883  0.056138  0.115670 -0.118620  0.065630\n",
       "13  0.094047 -0.333480 -0.188190  0.126990  0.090238\n",
       "14  0.386070  0.364860  0.118390 -0.095188  0.113360\n",
       "15 -0.430270 -0.097851 -0.125630 -0.052929  0.225460\n",
       "16 -0.101340 -0.062144 -0.139700 -0.242580  0.055439\n",
       "17  0.100710  0.404470  0.076967 -0.194820  0.105150\n",
       "18 -0.103310 -0.094876  0.142240  0.416660 -0.032058\n",
       "19 -0.052583 -0.245330  0.179940  0.212020  0.145170\n",
       "20  0.242900 -0.023089  0.013480 -0.565800  0.105400\n",
       "21 -0.187240  0.246390 -0.074786  0.057200  0.491430\n",
       "22  0.069239  0.376950  0.278210  0.104200  0.142690\n",
       "23 -0.502970 -0.191210 -0.051006 -0.057027  0.324640\n",
       "24  0.106270  0.312040  0.255000 -0.577580  0.349500\n",
       "25  0.188960 -0.008210  0.645770  0.290260 -0.086992\n",
       "26  0.154030  0.029357  0.270570 -0.019890 -0.000241\n",
       "27  0.497030 -0.425920  0.176660  0.279120  0.132740\n",
       "28  0.124290  0.121970 -0.354230 -0.347460 -0.095941\n",
       "29 -0.051966 -0.445630 -0.087070 -0.114910 -0.021618\n",
       "30  0.072571  0.146150  0.117740  0.361720  0.322150\n",
       "31  0.183650 -0.251100 -0.217830  0.065908  0.188180\n",
       "32 -0.081465 -0.254440 -0.116630 -0.338500  0.031079\n",
       "33  0.200930 -0.307450 -0.099281 -0.251160  0.156110"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X #Adding Column names and printing X data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.72</td>\n",
       "      <td>3.02</td>\n",
       "      <td>31.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.90</td>\n",
       "      <td>1.98</td>\n",
       "      <td>21.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.63</td>\n",
       "      <td>2.84</td>\n",
       "      <td>29.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.24</td>\n",
       "      <td>1.69</td>\n",
       "      <td>20.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.94</td>\n",
       "      <td>1.99</td>\n",
       "      <td>22.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.07</td>\n",
       "      <td>1.60</td>\n",
       "      <td>60.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.66</td>\n",
       "      <td>3.21</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.24</td>\n",
       "      <td>2.65</td>\n",
       "      <td>23.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.70</td>\n",
       "      <td>3.20</td>\n",
       "      <td>20.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.31</td>\n",
       "      <td>2.13</td>\n",
       "      <td>24.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.90</td>\n",
       "      <td>3.08</td>\n",
       "      <td>26.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.06</td>\n",
       "      <td>2.24</td>\n",
       "      <td>20.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.34</td>\n",
       "      <td>2.40</td>\n",
       "      <td>20.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.12</td>\n",
       "      <td>3.00</td>\n",
       "      <td>30.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.05</td>\n",
       "      <td>2.54</td>\n",
       "      <td>17.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.88</td>\n",
       "      <td>3.12</td>\n",
       "      <td>27.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.08</td>\n",
       "      <td>1.72</td>\n",
       "      <td>10.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.08</td>\n",
       "      <td>2.04</td>\n",
       "      <td>17.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.69</td>\n",
       "      <td>2.04</td>\n",
       "      <td>36.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.03</td>\n",
       "      <td>2.90</td>\n",
       "      <td>20.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.47</td>\n",
       "      <td>2.61</td>\n",
       "      <td>21.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.05</td>\n",
       "      <td>30.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.44</td>\n",
       "      <td>2.13</td>\n",
       "      <td>32.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.85</td>\n",
       "      <td>2.85</td>\n",
       "      <td>29.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.83</td>\n",
       "      <td>4.30</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.34</td>\n",
       "      <td>2.43</td>\n",
       "      <td>31.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.52</td>\n",
       "      <td>3.04</td>\n",
       "      <td>25.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.93</td>\n",
       "      <td>3.96</td>\n",
       "      <td>30.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.27</td>\n",
       "      <td>2.36</td>\n",
       "      <td>37.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.11</td>\n",
       "      <td>3.12</td>\n",
       "      <td>22.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.90</td>\n",
       "      <td>3.08</td>\n",
       "      <td>34.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.04</td>\n",
       "      <td>2.47</td>\n",
       "      <td>22.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.02</td>\n",
       "      <td>3.32</td>\n",
       "      <td>26.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.84</td>\n",
       "      <td>2.80</td>\n",
       "      <td>33.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y1    Y2     Y3\n",
       "0   2.72  3.02  31.52\n",
       "1   2.90  1.98  21.73\n",
       "2   3.63  2.84  29.20\n",
       "3   3.24  1.69  20.32\n",
       "4   3.94  1.99  22.73\n",
       "5   3.07  1.60  60.39\n",
       "6   3.66  3.21  17.55\n",
       "7   3.24  2.65  23.99\n",
       "8   2.70  3.20  20.63\n",
       "9   3.31  2.13  24.64\n",
       "10  2.90  3.08  26.63\n",
       "11  3.06  2.24  20.19\n",
       "12  3.34  2.40  20.99\n",
       "13  4.12  3.00  30.83\n",
       "14  4.05  2.54  17.62\n",
       "15  2.88  3.12  27.43\n",
       "16  2.08  1.72  10.35\n",
       "17  3.08  2.04  17.51\n",
       "18  3.69  2.04  36.10\n",
       "19  4.03  2.90  20.48\n",
       "20  3.47  2.61  21.32\n",
       "21  3.89  3.05  30.35\n",
       "22  2.44  2.13  32.65\n",
       "23  2.85  2.85  29.42\n",
       "24  3.83  4.30  15.00\n",
       "25  3.34  2.43  31.40\n",
       "26  3.52  3.04  25.16\n",
       "27  2.93  3.96  30.72\n",
       "28  3.27  2.36  37.74\n",
       "29  3.11  3.12  22.20\n",
       "30  3.90  3.08  34.51\n",
       "31  4.04  2.47  22.45\n",
       "32  3.02  3.32  26.66\n",
       "33  4.84  2.80  33.51"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y #Adding Column names and printing Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X1    0\n",
       "X2    0\n",
       "X3    0\n",
       "X4    0\n",
       "X5    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum() #Checking for null values for X dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y1    0\n",
       "Y2    0\n",
       "Y3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isna().sum() #Checking for null values for Y dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Raw Data')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting X dataset\n",
    "p = plt.figure()\n",
    "p.add_subplot(1,2,1)\n",
    "plt.title(\"X dataset\")\n",
    "plt.plot(X)\n",
    "plt.xlabel(\"Raw Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Y dataset\n",
    "p.add_subplot(1,2,2)\n",
    "plt.title(\"Y dataset\")\n",
    "plt.plot(y)\n",
    "plt.xlabel(\"Raw Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.iloc[:24] #Considering first 25 rows of X dataset as train variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X.iloc[24:] #Considering last 10 rows as of X dataset as test variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.099362</td>\n",
       "      <td>-0.085577</td>\n",
       "      <td>-0.143910</td>\n",
       "      <td>-0.104020</td>\n",
       "      <td>0.294070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.166140</td>\n",
       "      <td>0.277080</td>\n",
       "      <td>-0.190330</td>\n",
       "      <td>-0.056387</td>\n",
       "      <td>-0.134220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.252780</td>\n",
       "      <td>-0.085391</td>\n",
       "      <td>-0.096496</td>\n",
       "      <td>0.422420</td>\n",
       "      <td>-0.270440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072448</td>\n",
       "      <td>0.554370</td>\n",
       "      <td>-0.046507</td>\n",
       "      <td>0.325990</td>\n",
       "      <td>-0.333080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.266970</td>\n",
       "      <td>-0.108820</td>\n",
       "      <td>0.038903</td>\n",
       "      <td>0.215480</td>\n",
       "      <td>-0.448170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.026047</td>\n",
       "      <td>-0.113850</td>\n",
       "      <td>-0.216470</td>\n",
       "      <td>-0.277540</td>\n",
       "      <td>-0.508570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.269570</td>\n",
       "      <td>-0.174100</td>\n",
       "      <td>-0.165340</td>\n",
       "      <td>0.340080</td>\n",
       "      <td>-0.344010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.058377</td>\n",
       "      <td>0.219050</td>\n",
       "      <td>-0.130630</td>\n",
       "      <td>-0.289320</td>\n",
       "      <td>-0.184430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.064301</td>\n",
       "      <td>0.113230</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.145940</td>\n",
       "      <td>-0.229670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.204890</td>\n",
       "      <td>-0.009512</td>\n",
       "      <td>0.096320</td>\n",
       "      <td>-0.063046</td>\n",
       "      <td>-0.211770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.112310</td>\n",
       "      <td>0.189110</td>\n",
       "      <td>-0.272530</td>\n",
       "      <td>0.253770</td>\n",
       "      <td>-0.237380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010858</td>\n",
       "      <td>-0.093202</td>\n",
       "      <td>0.178020</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>-0.199840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.057883</td>\n",
       "      <td>0.056138</td>\n",
       "      <td>0.115670</td>\n",
       "      <td>-0.118620</td>\n",
       "      <td>0.065630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.094047</td>\n",
       "      <td>-0.333480</td>\n",
       "      <td>-0.188190</td>\n",
       "      <td>0.126990</td>\n",
       "      <td>0.090238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.386070</td>\n",
       "      <td>0.364860</td>\n",
       "      <td>0.118390</td>\n",
       "      <td>-0.095188</td>\n",
       "      <td>0.113360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.430270</td>\n",
       "      <td>-0.097851</td>\n",
       "      <td>-0.125630</td>\n",
       "      <td>-0.052929</td>\n",
       "      <td>0.225460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.101340</td>\n",
       "      <td>-0.062144</td>\n",
       "      <td>-0.139700</td>\n",
       "      <td>-0.242580</td>\n",
       "      <td>0.055439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.100710</td>\n",
       "      <td>0.404470</td>\n",
       "      <td>0.076967</td>\n",
       "      <td>-0.194820</td>\n",
       "      <td>0.105150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.103310</td>\n",
       "      <td>-0.094876</td>\n",
       "      <td>0.142240</td>\n",
       "      <td>0.416660</td>\n",
       "      <td>-0.032058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.052583</td>\n",
       "      <td>-0.245330</td>\n",
       "      <td>0.179940</td>\n",
       "      <td>0.212020</td>\n",
       "      <td>0.145170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.242900</td>\n",
       "      <td>-0.023089</td>\n",
       "      <td>0.013480</td>\n",
       "      <td>-0.565800</td>\n",
       "      <td>0.105400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.187240</td>\n",
       "      <td>0.246390</td>\n",
       "      <td>-0.074786</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.491430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.069239</td>\n",
       "      <td>0.376950</td>\n",
       "      <td>0.278210</td>\n",
       "      <td>0.104200</td>\n",
       "      <td>0.142690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.502970</td>\n",
       "      <td>-0.191210</td>\n",
       "      <td>-0.051006</td>\n",
       "      <td>-0.057027</td>\n",
       "      <td>0.324640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1        X2        X3        X4        X5\n",
       "0  -0.099362 -0.085577 -0.143910 -0.104020  0.294070\n",
       "1  -0.166140  0.277080 -0.190330 -0.056387 -0.134220\n",
       "2  -0.252780 -0.085391 -0.096496  0.422420 -0.270440\n",
       "3   0.072448  0.554370 -0.046507  0.325990 -0.333080\n",
       "4  -0.266970 -0.108820  0.038903  0.215480 -0.448170\n",
       "5  -0.026047 -0.113850 -0.216470 -0.277540 -0.508570\n",
       "6  -0.269570 -0.174100 -0.165340  0.340080 -0.344010\n",
       "7   0.058377  0.219050 -0.130630 -0.289320 -0.184430\n",
       "8   0.064301  0.113230  0.012695  0.145940 -0.229670\n",
       "9  -0.204890 -0.009512  0.096320 -0.063046 -0.211770\n",
       "10  0.112310  0.189110 -0.272530  0.253770 -0.237380\n",
       "11  0.010858 -0.093202  0.178020  0.149020 -0.199840\n",
       "12  0.057883  0.056138  0.115670 -0.118620  0.065630\n",
       "13  0.094047 -0.333480 -0.188190  0.126990  0.090238\n",
       "14  0.386070  0.364860  0.118390 -0.095188  0.113360\n",
       "15 -0.430270 -0.097851 -0.125630 -0.052929  0.225460\n",
       "16 -0.101340 -0.062144 -0.139700 -0.242580  0.055439\n",
       "17  0.100710  0.404470  0.076967 -0.194820  0.105150\n",
       "18 -0.103310 -0.094876  0.142240  0.416660 -0.032058\n",
       "19 -0.052583 -0.245330  0.179940  0.212020  0.145170\n",
       "20  0.242900 -0.023089  0.013480 -0.565800  0.105400\n",
       "21 -0.187240  0.246390 -0.074786  0.057200  0.491430\n",
       "22  0.069239  0.376950  0.278210  0.104200  0.142690\n",
       "23 -0.502970 -0.191210 -0.051006 -0.057027  0.324640"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train #Displaying X train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.106270</td>\n",
       "      <td>0.312040</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>-0.577580</td>\n",
       "      <td>0.349500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.188960</td>\n",
       "      <td>-0.008210</td>\n",
       "      <td>0.645770</td>\n",
       "      <td>0.290260</td>\n",
       "      <td>-0.086992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.154030</td>\n",
       "      <td>0.029357</td>\n",
       "      <td>0.270570</td>\n",
       "      <td>-0.019890</td>\n",
       "      <td>-0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.497030</td>\n",
       "      <td>-0.425920</td>\n",
       "      <td>0.176660</td>\n",
       "      <td>0.279120</td>\n",
       "      <td>0.132740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.124290</td>\n",
       "      <td>0.121970</td>\n",
       "      <td>-0.354230</td>\n",
       "      <td>-0.347460</td>\n",
       "      <td>-0.095941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.051966</td>\n",
       "      <td>-0.445630</td>\n",
       "      <td>-0.087070</td>\n",
       "      <td>-0.114910</td>\n",
       "      <td>-0.021618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.072571</td>\n",
       "      <td>0.146150</td>\n",
       "      <td>0.117740</td>\n",
       "      <td>0.361720</td>\n",
       "      <td>0.322150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.183650</td>\n",
       "      <td>-0.251100</td>\n",
       "      <td>-0.217830</td>\n",
       "      <td>0.065908</td>\n",
       "      <td>0.188180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.081465</td>\n",
       "      <td>-0.254440</td>\n",
       "      <td>-0.116630</td>\n",
       "      <td>-0.338500</td>\n",
       "      <td>0.031079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.200930</td>\n",
       "      <td>-0.307450</td>\n",
       "      <td>-0.099281</td>\n",
       "      <td>-0.251160</td>\n",
       "      <td>0.156110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1        X2        X3        X4        X5\n",
       "24  0.106270  0.312040  0.255000 -0.577580  0.349500\n",
       "25  0.188960 -0.008210  0.645770  0.290260 -0.086992\n",
       "26  0.154030  0.029357  0.270570 -0.019890 -0.000241\n",
       "27  0.497030 -0.425920  0.176660  0.279120  0.132740\n",
       "28  0.124290  0.121970 -0.354230 -0.347460 -0.095941\n",
       "29 -0.051966 -0.445630 -0.087070 -0.114910 -0.021618\n",
       "30  0.072571  0.146150  0.117740  0.361720  0.322150\n",
       "31  0.183650 -0.251100 -0.217830  0.065908  0.188180\n",
       "32 -0.081465 -0.254440 -0.116630 -0.338500  0.031079\n",
       "33  0.200930 -0.307450 -0.099281 -0.251160  0.156110"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test #Displaying X test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.iloc[:24] #Considering first 25 rows of Y dataset as train variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y.iloc[24:] #Considering last 10 rows as of Y dataset as test variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.72</td>\n",
       "      <td>3.02</td>\n",
       "      <td>31.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.90</td>\n",
       "      <td>1.98</td>\n",
       "      <td>21.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.63</td>\n",
       "      <td>2.84</td>\n",
       "      <td>29.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.24</td>\n",
       "      <td>1.69</td>\n",
       "      <td>20.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.94</td>\n",
       "      <td>1.99</td>\n",
       "      <td>22.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.07</td>\n",
       "      <td>1.60</td>\n",
       "      <td>60.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.66</td>\n",
       "      <td>3.21</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.24</td>\n",
       "      <td>2.65</td>\n",
       "      <td>23.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.70</td>\n",
       "      <td>3.20</td>\n",
       "      <td>20.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.31</td>\n",
       "      <td>2.13</td>\n",
       "      <td>24.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.90</td>\n",
       "      <td>3.08</td>\n",
       "      <td>26.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.06</td>\n",
       "      <td>2.24</td>\n",
       "      <td>20.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.34</td>\n",
       "      <td>2.40</td>\n",
       "      <td>20.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.12</td>\n",
       "      <td>3.00</td>\n",
       "      <td>30.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.05</td>\n",
       "      <td>2.54</td>\n",
       "      <td>17.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.88</td>\n",
       "      <td>3.12</td>\n",
       "      <td>27.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.08</td>\n",
       "      <td>1.72</td>\n",
       "      <td>10.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.08</td>\n",
       "      <td>2.04</td>\n",
       "      <td>17.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.69</td>\n",
       "      <td>2.04</td>\n",
       "      <td>36.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.03</td>\n",
       "      <td>2.90</td>\n",
       "      <td>20.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.47</td>\n",
       "      <td>2.61</td>\n",
       "      <td>21.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.05</td>\n",
       "      <td>30.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.44</td>\n",
       "      <td>2.13</td>\n",
       "      <td>32.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.85</td>\n",
       "      <td>2.85</td>\n",
       "      <td>29.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y1    Y2     Y3\n",
       "0   2.72  3.02  31.52\n",
       "1   2.90  1.98  21.73\n",
       "2   3.63  2.84  29.20\n",
       "3   3.24  1.69  20.32\n",
       "4   3.94  1.99  22.73\n",
       "5   3.07  1.60  60.39\n",
       "6   3.66  3.21  17.55\n",
       "7   3.24  2.65  23.99\n",
       "8   2.70  3.20  20.63\n",
       "9   3.31  2.13  24.64\n",
       "10  2.90  3.08  26.63\n",
       "11  3.06  2.24  20.19\n",
       "12  3.34  2.40  20.99\n",
       "13  4.12  3.00  30.83\n",
       "14  4.05  2.54  17.62\n",
       "15  2.88  3.12  27.43\n",
       "16  2.08  1.72  10.35\n",
       "17  3.08  2.04  17.51\n",
       "18  3.69  2.04  36.10\n",
       "19  4.03  2.90  20.48\n",
       "20  3.47  2.61  21.32\n",
       "21  3.89  3.05  30.35\n",
       "22  2.44  2.13  32.65\n",
       "23  2.85  2.85  29.42"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train #Displaying y train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.83</td>\n",
       "      <td>4.30</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.34</td>\n",
       "      <td>2.43</td>\n",
       "      <td>31.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.52</td>\n",
       "      <td>3.04</td>\n",
       "      <td>25.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.93</td>\n",
       "      <td>3.96</td>\n",
       "      <td>30.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.27</td>\n",
       "      <td>2.36</td>\n",
       "      <td>37.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.11</td>\n",
       "      <td>3.12</td>\n",
       "      <td>22.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.90</td>\n",
       "      <td>3.08</td>\n",
       "      <td>34.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.04</td>\n",
       "      <td>2.47</td>\n",
       "      <td>22.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.02</td>\n",
       "      <td>3.32</td>\n",
       "      <td>26.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.84</td>\n",
       "      <td>2.80</td>\n",
       "      <td>33.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y1    Y2     Y3\n",
       "24  3.83  4.30  15.00\n",
       "25  3.34  2.43  31.40\n",
       "26  3.52  3.04  25.16\n",
       "27  2.93  3.96  30.72\n",
       "28  3.27  2.36  37.74\n",
       "29  3.11  3.12  22.20\n",
       "30  3.90  3.08  34.51\n",
       "31  4.04  2.47  22.45\n",
       "32  3.02  3.32  26.66\n",
       "33  4.84  2.80  33.51"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test #Displaying y test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression using Gradient Descent method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression function formulation\n",
    "\n",
    "def mean_squ_error(y_true, y_pred):\n",
    "    c = np.sum((y_true-y_pred)**2) / len(y_true)\n",
    "    return c\n",
    "\n",
    "def gradient_descent(x, y, iterations = 400, l_rate=0.0001,stopping_threshold = 1e-6):\n",
    "    c_w = 0.1\n",
    "    c_b = 0.01\n",
    "    iterations = iterations\n",
    "    l_rate = l_rate\n",
    "    n = float(len(x))\n",
    "    costs = []\n",
    "    weights = []\n",
    "    previous_cost = None\n",
    "    for i in range(iterations):\n",
    "          \n",
    "        y_pred = (c_w * x) + c_b\n",
    "          \n",
    "        c_cost = mean_squ_error(y, y_pred)\n",
    "        if previous_cost and abs(previous_cost-c_cost)<=stopping_threshold:\n",
    "            break\n",
    "          \n",
    "        previous_cost = c_cost\n",
    "  \n",
    "        costs.append(c_cost)\n",
    "        weights.append(c_w)\n",
    "          \n",
    "        weight_derivative = -(2/n) * sum(x * (y-y_pred))\n",
    "        bias_derivative = -(2/n) * sum(y-y_pred)\n",
    "        c_w = c_w - (l_rate * weight_derivative)\n",
    "        c_b = c_b - (l_rate * bias_derivative)\n",
    "        print(f\"Iterate {i+1}: Cost {c_cost*l_rate},   \\n  |    Weight  {c_w},\\n    |     Bias {c_b}\")\n",
    "    return c_w, c_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train.to_numpy()\n",
    "y0 = y_train.iloc[:,0:1].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterate 1: Cost 0.005430564318042739,   \n",
      "  |    Weight  [0.09996384 0.10002324 0.09998577 0.10002419 0.09997127],\n",
      "    |     Bias [0.01065158 0.01064951 0.01065091 0.01064987 0.01065123]\n",
      "Iterate 2: Cost 0.005428444530062072,   \n",
      "  |    Weight  [0.09992769 0.10004647 0.09997154 0.10004837 0.09994255],\n",
      "    |     Bias [0.01130303 0.0112989  0.01130169 0.01129962 0.01130233]\n",
      "Iterate 3: Cost 0.005426325591371422,   \n",
      "  |    Weight  [0.09989155 0.1000697  0.09995731 0.10007255 0.09991383],\n",
      "    |     Bias [0.01195434 0.01194815 0.01195234 0.01194923 0.0119533 ]\n",
      "Iterate 4: Cost 0.0054242075016305135,   \n",
      "  |    Weight  [0.09985541 0.10009293 0.09994309 0.10009673 0.09988511],\n",
      "    |     Bias [0.01260553 0.01259728 0.01260285 0.01259871 0.01260413]\n",
      "Iterate 5: Cost 0.005422090260499194,   \n",
      "  |    Weight  [0.09981929 0.10011614 0.09992886 0.1001209  0.09985641],\n",
      "    |     Bias [0.01325659 0.01324627 0.01325324 0.01324806 0.01325484]\n",
      "Iterate 6: Cost 0.005419973867637459,   \n",
      "  |    Weight  [0.09978317 0.10013935 0.09991465 0.10014507 0.09982771],\n",
      "    |     Bias [0.01390751 0.01389513 0.0139035  0.01389729 0.01390542]\n",
      "Iterate 7: Cost 0.005417858322705433,   \n",
      "  |    Weight  [0.09974705 0.10016256 0.09990043 0.10016924 0.09979901],\n",
      "    |     Bias [0.01455831 0.01454387 0.01455363 0.01454638 0.01455586]\n",
      "Iterate 8: Cost 0.005415743625363379,   \n",
      "  |    Weight  [0.09971095 0.10018575 0.09988622 0.1001934  0.09977032],\n",
      "    |     Bias [0.01520897 0.01519247 0.01520363 0.01519534 0.01520618]\n",
      "Iterate 9: Cost 0.0054136297752716955,   \n",
      "  |    Weight  [0.09967486 0.10020894 0.09987202 0.10021756 0.09974164],\n",
      "    |     Bias [0.0158595  0.01584094 0.01585349 0.01584417 0.01585637]\n",
      "Iterate 10: Cost 0.005411516772090918,   \n",
      "  |    Weight  [0.09963877 0.10023213 0.09985781 0.10024171 0.09971296],\n",
      "    |     Bias [0.01650991 0.01648929 0.01650323 0.01649288 0.01650642]\n",
      "Iterate 11: Cost 0.005409404615481717,   \n",
      "  |    Weight  [0.09960269 0.10025531 0.09984361 0.10026586 0.09968428],\n",
      "    |     Bias [0.01716018 0.0171375  0.01715284 0.01714145 0.01715635]\n",
      "Iterate 12: Cost 0.005407293305104903,   \n",
      "  |    Weight  [0.09956662 0.10027848 0.09982941 0.10029001 0.09965562],\n",
      "    |     Bias [0.01781032 0.01778559 0.01780232 0.01778989 0.01780614]\n",
      "Iterate 13: Cost 0.005405182840621413,   \n",
      "  |    Weight  [0.09953055 0.10030165 0.09981522 0.10031415 0.09962695],\n",
      "    |     Bias [0.01846033 0.01843354 0.01845166 0.01843821 0.01845581]\n",
      "Iterate 14: Cost 0.005403073221692331,   \n",
      "  |    Weight  [0.0994945  0.10032481 0.09980103 0.10033829 0.0995983 ],\n",
      "    |     Bias [0.01911021 0.01908137 0.01910088 0.01908639 0.01910534]\n",
      "Iterate 15: Cost 0.005400964447978869,   \n",
      "  |    Weight  [0.09945845 0.10034797 0.09978684 0.10036242 0.09956965],\n",
      "    |     Bias [0.01975996 0.01972906 0.01974997 0.01973444 0.01975475]\n",
      "Iterate 16: Cost 0.005398856519142377,   \n",
      "  |    Weight  [0.09942241 0.10037112 0.09977265 0.10038655 0.099541  ],\n",
      "    |     Bias [0.02040958 0.02037662 0.02039893 0.02038237 0.02040402]\n",
      "Iterate 17: Cost 0.005396749434844343,   \n",
      "  |    Weight  [0.09938637 0.10039426 0.09975847 0.10041068 0.09951236],\n",
      "    |     Bias [0.02105907 0.02102406 0.02104775 0.02103016 0.02105317]\n",
      "Iterate 18: Cost 0.005394643194746388,   \n",
      "  |    Weight  [0.09935035 0.1004174  0.09974429 0.1004348  0.09948373],\n",
      "    |     Bias [0.02170843 0.02167137 0.02169645 0.02167783 0.02170218]\n",
      "Iterate 19: Cost 0.005392537798510268,   \n",
      "  |    Weight  [0.09931433 0.10044053 0.09973012 0.10045892 0.0994551 ],\n",
      "    |     Bias [0.02235766 0.02231854 0.02234502 0.02232536 0.02235107]\n",
      "Iterate 20: Cost 0.005390433245797875,   \n",
      "  |    Weight  [0.09927832 0.10046365 0.09971595 0.10048304 0.09942648],\n",
      "    |     Bias [0.02300676 0.02296559 0.02299346 0.02297277 0.02299982]\n",
      "Iterate 21: Cost 0.00538832953627124,   \n",
      "  |    Weight  [0.09924232 0.10048677 0.09970178 0.10050715 0.09939786],\n",
      "    |     Bias [0.02365573 0.0236125  0.02364177 0.02362004 0.02364845]\n",
      "Iterate 22: Cost 0.0053862266695925256,   \n",
      "  |    Weight  [0.09920633 0.10050988 0.09968761 0.10053126 0.09936925],\n",
      "    |     Bias [0.02430457 0.02425929 0.02428995 0.02426719 0.02429694]\n",
      "Iterate 23: Cost 0.005384124645424029,   \n",
      "  |    Weight  [0.09917034 0.10053299 0.09967345 0.10055536 0.09934065],\n",
      "    |     Bias [0.02495328 0.02490595 0.024938   0.02491421 0.02494531]\n",
      "Iterate 24: Cost 0.005382023463428186,   \n",
      "  |    Weight  [0.09913437 0.10055609 0.09965929 0.10057946 0.09931205],\n",
      "    |     Bias [0.02560186 0.02555248 0.02558592 0.02556109 0.02559354]\n",
      "Iterate 25: Cost 0.005379923123267567,   \n",
      "  |    Weight  [0.0990984  0.10057918 0.09964514 0.10060356 0.09928345],\n",
      "    |     Bias [0.0262503  0.02619888 0.02623371 0.02620785 0.02624164]\n",
      "Iterate 26: Cost 0.005377823624604876,   \n",
      "  |    Weight  [0.09906243 0.10060227 0.09963099 0.10062765 0.09925486],\n",
      "    |     Bias [0.02689862 0.02684514 0.02688137 0.02685448 0.02688962]\n",
      "Iterate 27: Cost 0.0053757249671029525,   \n",
      "  |    Weight  [0.09902648 0.10062535 0.09961684 0.10065174 0.09922628],\n",
      "    |     Bias [0.02754681 0.02749128 0.0275289  0.02750098 0.02753746]\n",
      "Iterate 28: Cost 0.0053736271504247705,   \n",
      "  |    Weight  [0.09899053 0.10064843 0.09960269 0.10067583 0.0991977 ],\n",
      "    |     Bias [0.02819487 0.02813729 0.0281763  0.02814735 0.02818518]\n",
      "Iterate 29: Cost 0.005371530174233442,   \n",
      "  |    Weight  [0.09895459 0.1006715  0.09958855 0.10069991 0.09916913],\n",
      "    |     Bias [0.0288428  0.02878318 0.02882357 0.02879359 0.02883277]\n",
      "Iterate 30: Cost 0.005369434038192211,   \n",
      "  |    Weight  [0.09891866 0.10069456 0.09957441 0.10072398 0.09914057],\n",
      "    |     Bias [0.02949059 0.02942893 0.02947071 0.0294397  0.02948022]\n",
      "Iterate 31: Cost 0.005367338741964457,   \n",
      "  |    Weight  [0.09888274 0.10071762 0.09956027 0.10074806 0.09911201],\n",
      "    |     Bias [0.03013826 0.03007455 0.03011773 0.03008568 0.03012755]\n",
      "Iterate 32: Cost 0.005365244285213697,   \n",
      "  |    Weight  [0.09884683 0.10074067 0.09954614 0.10077213 0.09908345],\n",
      "    |     Bias [0.0307858  0.03072004 0.03076461 0.03073153 0.03077474]\n",
      "Iterate 33: Cost 0.005363150667603577,   \n",
      "  |    Weight  [0.09881092 0.10076372 0.09953201 0.10079619 0.0990549 ],\n",
      "    |     Bias [0.03143321 0.0313654  0.03141136 0.03137725 0.03142181]\n",
      "Iterate 34: Cost 0.005361057888797884,   \n",
      "  |    Weight  [0.09877502 0.10078676 0.09951789 0.10082026 0.09902636],\n",
      "    |     Bias [0.03208049 0.03201064 0.03205799 0.03202285 0.03206875]\n",
      "Iterate 35: Cost 0.005358965948460536,   \n",
      "  |    Weight  [0.09873913 0.10080979 0.09950376 0.10084432 0.09899782],\n",
      "    |     Bias [0.03272763 0.03265574 0.03270448 0.03266831 0.03271556]\n",
      "Iterate 36: Cost 0.005356874846255587,   \n",
      "  |    Weight  [0.09870325 0.10083282 0.09948964 0.10086837 0.09896929],\n",
      "    |     Bias [0.03337465 0.03330072 0.03335085 0.03331364 0.03336223]\n",
      "Iterate 37: Cost 0.005354784581847226,   \n",
      "  |    Weight  [0.09866737 0.10085584 0.09947553 0.10089242 0.09894076],\n",
      "    |     Bias [0.03402154 0.03394556 0.03399708 0.03395885 0.03400878]\n",
      "Iterate 38: Cost 0.005352695154899774,   \n",
      "  |    Weight  [0.0986315  0.10087885 0.09946141 0.10091647 0.09891224],\n",
      "    |     Bias [0.0346683  0.03459028 0.03464319 0.03460393 0.0346552 ]\n",
      "Iterate 39: Cost 0.005350606565077691,   \n",
      "  |    Weight  [0.09859564 0.10090186 0.0994473  0.10094051 0.09888373],\n",
      "    |     Bias [0.03531493 0.03523487 0.03528917 0.03524887 0.03530149]\n",
      "Iterate 40: Cost 0.005348518812045567,   \n",
      "  |    Weight  [0.09855979 0.10092487 0.0994332  0.10096455 0.09885522],\n",
      "    |     Bias [0.03596143 0.03587933 0.03593502 0.03589369 0.03594765]\n",
      "Iterate 41: Cost 0.005346431895468129,   \n",
      "  |    Weight  [0.09852394 0.10094786 0.09941909 0.10098859 0.09882671],\n",
      "    |     Bias [0.0366078  0.03652366 0.03658074 0.03653838 0.03659368]\n",
      "Iterate 42: Cost 0.005344345815010237,   \n",
      "  |    Weight  [0.09848811 0.10097085 0.09940499 0.10101262 0.09879821],\n",
      "    |     Bias [0.03725404 0.03716786 0.03722633 0.03718294 0.03723958]\n",
      "Iterate 43: Cost 0.005342260570336885,   \n",
      "  |    Weight  [0.09845228 0.10099384 0.0993909  0.10103665 0.09876972],\n",
      "    |     Bias [0.03790015 0.03781193 0.03787179 0.03782737 0.03788535]\n",
      "Iterate 44: Cost 0.0053401761611132055,   \n",
      "  |    Weight  [0.09841646 0.10101682 0.0993768  0.10106067 0.09874123],\n",
      "    |     Bias [0.03854613 0.03845587 0.03851712 0.03847167 0.03853099]\n",
      "Iterate 45: Cost 0.005338092587004456,   \n",
      "  |    Weight  [0.09838064 0.10103979 0.09936271 0.10108469 0.09871275],\n",
      "    |     Bias [0.03919198 0.03909969 0.03916232 0.03911585 0.03917651]\n",
      "Iterate 46: Cost 0.0053360098476760405,   \n",
      "  |    Weight  [0.09834484 0.10106276 0.09934862 0.10110871 0.09868428],\n",
      "    |     Bias [0.0398377  0.03974337 0.03980739 0.03975989 0.03982189]\n",
      "Iterate 47: Cost 0.005333927942793485,   \n",
      "  |    Weight  [0.09830904 0.10108572 0.09933454 0.10113272 0.09865581],\n",
      "    |     Bias [0.04048329 0.04038693 0.04045234 0.0404038  0.04046714]\n",
      "Iterate 48: Cost 0.005331846872022457,   \n",
      "  |    Weight  [0.09827325 0.10110867 0.09932046 0.10115673 0.09862734],\n",
      "    |     Bias [0.04112876 0.04103035 0.04109715 0.04104759 0.04111227]\n",
      "Iterate 49: Cost 0.005329766635028757,   \n",
      "  |    Weight  [0.09823747 0.10113162 0.09930638 0.10118074 0.09859888],\n",
      "    |     Bias [0.04177409 0.04167365 0.04174184 0.04169125 0.04175726]\n",
      "Iterate 50: Cost 0.005327687231478316,   \n",
      "  |    Weight  [0.0982017  0.10115456 0.09929231 0.10120474 0.09857043],\n",
      "    |     Bias [0.04241929 0.04231682 0.0423864  0.04233478 0.04240213]\n",
      "Iterate 51: Cost 0.005325608661037203,   \n",
      "  |    Weight  [0.09816593 0.1011775  0.09927824 0.10122874 0.09854198],\n",
      "    |     Bias [0.04306437 0.04295986 0.04303082 0.04297817 0.04304687]\n",
      "Iterate 52: Cost 0.005323530923371618,   \n",
      "  |    Weight  [0.09813017 0.10120043 0.09926417 0.10125273 0.09851354],\n",
      "    |     Bias [0.04370931 0.04360277 0.04367512 0.04362145 0.04369148]\n",
      "Iterate 53: Cost 0.005321454018147895,   \n",
      "  |    Weight  [0.09809442 0.10122335 0.0992501  0.10127672 0.0984851 ],\n",
      "    |     Bias [0.04435413 0.04424556 0.04431929 0.04426459 0.04433595]\n",
      "Iterate 54: Cost 0.005319377945032505,   \n",
      "  |    Weight  [0.09805868 0.10124627 0.09923604 0.10130071 0.09845667],\n",
      "    |     Bias [0.04499881 0.04488821 0.04496334 0.0449076  0.0449803 ]\n",
      "Iterate 55: Cost 0.005317302703692047,   \n",
      "  |    Weight  [0.09802294 0.10126918 0.09922198 0.10132469 0.09842825],\n",
      "    |     Bias [0.04564337 0.04553073 0.04560725 0.04555048 0.04562452]\n",
      "Iterate 56: Cost 0.005315228293793257,   \n",
      "  |    Weight  [0.09798722 0.10129209 0.09920793 0.10134867 0.09839983],\n",
      "    |     Bias [0.04628779 0.04617313 0.04625103 0.04619324 0.04626862]\n",
      "Iterate 57: Cost 0.005313154715003005,   \n",
      "  |    Weight  [0.0979515  0.10131499 0.09919388 0.10137265 0.09837141],\n",
      "    |     Bias [0.04693209 0.0468154  0.04689469 0.04683587 0.04691258]\n",
      "Iterate 58: Cost 0.005311081966988294,   \n",
      "  |    Weight  [0.09791578 0.10133788 0.09917983 0.10139662 0.09834301],\n",
      "    |     Bias [0.04757626 0.04745754 0.04753821 0.04747837 0.04755641]\n",
      "Iterate 59: Cost 0.005309010049416259,   \n",
      "  |    Weight  [0.09788008 0.10136077 0.09916578 0.10142058 0.0983146 ],\n",
      "    |     Bias [0.0482203  0.04809955 0.04818161 0.04812074 0.04820012]\n",
      "Iterate 60: Cost 0.005306938961954169,   \n",
      "  |    Weight  [0.09784438 0.10138365 0.09915174 0.10144455 0.09828621],\n",
      "    |     Bias [0.04886421 0.04874143 0.04882488 0.04876298 0.04884369]\n",
      "Iterate 61: Cost 0.005304868704269429,   \n",
      "  |    Weight  [0.0978087  0.10140653 0.0991377  0.10146851 0.09825781],\n",
      "    |     Bias [0.04950799 0.04938318 0.04946802 0.04940509 0.04948714]\n",
      "Iterate 62: Cost 0.005302799276029573,   \n",
      "  |    Weight  [0.09777302 0.1014294  0.09912367 0.10149247 0.09822943],\n",
      "    |     Bias [0.05015164 0.05002481 0.05011103 0.05004707 0.05013046]\n",
      "Iterate 63: Cost 0.00530073067690227,   \n",
      "  |    Weight  [0.09773734 0.10145226 0.09910964 0.10151642 0.09820105],\n",
      "    |     Bias [0.05079516 0.0506663  0.05075391 0.05068893 0.05077364]\n",
      "Iterate 64: Cost 0.005298662906555323,   \n",
      "  |    Weight  [0.09770168 0.10147512 0.09909561 0.10154037 0.09817267],\n",
      "    |     Bias [0.05143856 0.05130767 0.05139667 0.05133065 0.0514167 ]\n",
      "Iterate 65: Cost 0.005296595964656668,   \n",
      "  |    Weight  [0.09766602 0.10149797 0.09908158 0.10156431 0.0981443 ],\n",
      "    |     Bias [0.05208182 0.05194891 0.05203929 0.05197225 0.05205964]\n",
      "Iterate 66: Cost 0.005294529850874371,   \n",
      "  |    Weight  [0.09763037 0.10152082 0.09906756 0.10158825 0.09811594],\n",
      "    |     Bias [0.05272496 0.05259002 0.05268179 0.05261372 0.05270244]\n",
      "Iterate 67: Cost 0.005292464564876637,   \n",
      "  |    Weight  [0.09759473 0.10154366 0.09905354 0.10161219 0.09808758],\n",
      "    |     Bias [0.05336796 0.053231   0.05332415 0.05325506 0.05334511]\n",
      "Iterate 68: Cost 0.005290400106331796,   \n",
      "  |    Weight  [0.0975591  0.10156649 0.09903952 0.10163612 0.09805923],\n",
      "    |     Bias [0.05401084 0.05387186 0.05396639 0.05389628 0.05398766]\n",
      "Iterate 69: Cost 0.0052883364749083195,   \n",
      "  |    Weight  [0.09752347 0.10158932 0.09902551 0.10166005 0.09803088],\n",
      "    |     Bias [0.05465359 0.05451258 0.05460851 0.05453736 0.05463007]\n",
      "Iterate 70: Cost 0.005286273670274805,   \n",
      "  |    Weight  [0.09748785 0.10161214 0.0990115  0.10168398 0.09800254],\n",
      "    |     Bias [0.05529621 0.05515318 0.05525049 0.05517832 0.05527236]\n",
      "Iterate 71: Cost 0.005284211692099987,   \n",
      "  |    Weight  [0.09745224 0.10163496 0.09899749 0.1017079  0.0979742 ],\n",
      "    |     Bias [0.0559387  0.05579365 0.05589234 0.05581915 0.05591452]\n",
      "Iterate 72: Cost 0.005282150540052729,   \n",
      "  |    Weight  [0.09741664 0.10165777 0.09898349 0.10173182 0.09794587],\n",
      "    |     Bias [0.05658106 0.05643399 0.05653407 0.05645985 0.05655655]\n",
      "Iterate 73: Cost 0.005280090213802032,   \n",
      "  |    Weight  [0.09738104 0.10168057 0.09896949 0.10175574 0.09791755],\n",
      "    |     Bias [0.05722329 0.0570742  0.05717566 0.05710042 0.05719845]\n",
      "Iterate 74: Cost 0.005278030713017026,   \n",
      "  |    Weight  [0.09734546 0.10170337 0.09895549 0.10177965 0.09788923],\n",
      "    |     Bias [0.05786539 0.05771429 0.05781713 0.05774086 0.05784022]\n",
      "Iterate 75: Cost 0.005275972037366973,   \n",
      "  |    Weight  [0.09730988 0.10172616 0.0989415  0.10180355 0.09786092],\n",
      "    |     Bias [0.05850737 0.05835424 0.05845847 0.05838118 0.05848186]\n",
      "Iterate 76: Cost 0.005273914186521271,   \n",
      "  |    Weight  [0.09727431 0.10174894 0.09892751 0.10182746 0.09783261],\n",
      "    |     Bias [0.05914921 0.05899407 0.05909969 0.05902136 0.05912338]\n",
      "Iterate 77: Cost 0.005271857160149445,   \n",
      "  |    Weight  [0.09723874 0.10177172 0.09891352 0.10185136 0.09780431],\n",
      "    |     Bias [0.05979093 0.05963377 0.05974077 0.05966142 0.05976477]\n",
      "Iterate 78: Cost 0.005269800957921161,   \n",
      "  |    Weight  [0.09720319 0.1017945  0.09889954 0.10187525 0.09777601],\n",
      "    |     Bias [0.06043252 0.06027334 0.06038172 0.06030135 0.06040602]\n",
      "Iterate 79: Cost 0.005267745579506209,   \n",
      "  |    Weight  [0.09716764 0.10181726 0.09888556 0.10189915 0.09774772],\n",
      "    |     Bias [0.06107398 0.06091278 0.06102255 0.06094116 0.06104715]\n",
      "Iterate 80: Cost 0.005265691024574515,   \n",
      "  |    Weight  [0.0971321  0.10184003 0.09887158 0.10192304 0.09771944],\n",
      "    |     Bias [0.06171531 0.0615521  0.06166325 0.06158083 0.06168816]\n",
      "Iterate 81: Cost 0.005263637292796136,   \n",
      "  |    Weight  [0.09709656 0.10186278 0.0988576  0.10194692 0.09769116],\n",
      "    |     Bias [0.06235651 0.06219128 0.06230382 0.06222038 0.06232903]\n",
      "Iterate 82: Cost 0.005261584383841264,   \n",
      "  |    Weight  [0.09706104 0.10188553 0.09884363 0.1019708  0.09766288],\n",
      "    |     Bias [0.06299759 0.06283034 0.06294426 0.06285979 0.06296977]\n",
      "Iterate 83: Cost 0.0052595322973802185,   \n",
      "  |    Weight  [0.09702552 0.10190827 0.09882967 0.10199468 0.09763461],\n",
      "    |     Bias [0.06363853 0.06346927 0.06358458 0.06349908 0.06361039]\n",
      "Iterate 84: Cost 0.005257481033083457,   \n",
      "  |    Weight  [0.09699001 0.10193101 0.0988157  0.10201855 0.09760635],\n",
      "    |     Bias [0.06427935 0.06410808 0.06422476 0.06413825 0.06425088]\n",
      "Iterate 85: Cost 0.005255430590621563,   \n",
      "  |    Weight  [0.09695451 0.10195374 0.09880174 0.10204242 0.09757809],\n",
      "    |     Bias [0.06492004 0.06474675 0.06486482 0.06477728 0.06489124]\n",
      "Iterate 86: Cost 0.005253380969665254,   \n",
      "  |    Weight  [0.09691902 0.10197647 0.09878778 0.10206629 0.09754984],\n",
      "    |     Bias [0.06556059 0.0653853  0.06550475 0.06541619 0.06553147]\n",
      "Iterate 87: Cost 0.005251332169885384,   \n",
      "  |    Weight  [0.09688353 0.10199919 0.09877383 0.10209015 0.09752159],\n",
      "    |     Bias [0.06620103 0.06602372 0.06614455 0.06605497 0.06617157]\n",
      "Iterate 88: Cost 0.005249284190952932,   \n",
      "  |    Weight  [0.09684805 0.1020219  0.09875987 0.10211401 0.09749335],\n",
      "    |     Bias [0.06684133 0.06666201 0.06678423 0.06669362 0.06681155]\n",
      "Iterate 89: Cost 0.005247237032539013,   \n",
      "  |    Weight  [0.09681258 0.10204461 0.09874592 0.10213786 0.09746512],\n",
      "    |     Bias [0.0674815  0.06730017 0.06742377 0.06733214 0.06745139]\n",
      "Iterate 90: Cost 0.005245190694314872,   \n",
      "  |    Weight  [0.09677712 0.10206731 0.09873198 0.10216171 0.09743689],\n",
      "    |     Bias [0.06812155 0.06793821 0.06806319 0.06797053 0.06809111]\n",
      "Iterate 91: Cost 0.005243145175951887,   \n",
      "  |    Weight  [0.09674166 0.10209    0.09871804 0.10218556 0.09740866],\n",
      "    |     Bias [0.06876146 0.06857612 0.06870248 0.0686088  0.0687307 ]\n",
      "Iterate 92: Cost 0.005241100477121568,   \n",
      "  |    Weight  [0.09670622 0.10211269 0.0987041  0.1022094  0.09738045],\n",
      "    |     Bias [0.06940125 0.0692139  0.06934164 0.06924694 0.06937016]\n",
      "Iterate 93: Cost 0.005239056597495553,   \n",
      "  |    Weight  [0.09667078 0.10213538 0.09869016 0.10223324 0.09735223],\n",
      "    |     Bias [0.07004091 0.06985155 0.06998068 0.06988495 0.0700095 ]\n",
      "Iterate 94: Cost 0.005237013536745616,   \n",
      "  |    Weight  [0.09663534 0.10215805 0.09867623 0.10225708 0.09732403],\n",
      "    |     Bias [0.07068044 0.07048907 0.07061958 0.07052284 0.0706487 ]\n",
      "Iterate 95: Cost 0.00523497129454366,   \n",
      "  |    Weight  [0.09659992 0.10218073 0.0986623  0.10228091 0.09729582],\n",
      "    |     Bias [0.07131985 0.07112647 0.07125836 0.07116059 0.07128778]\n",
      "Iterate 96: Cost 0.0052329298705617215,   \n",
      "  |    Weight  [0.0965645  0.10220339 0.09864837 0.10230474 0.09726763],\n",
      "    |     Bias [0.07195912 0.07176374 0.07189701 0.07179822 0.07192673]\n",
      "Iterate 97: Cost 0.005230889264471966,   \n",
      "  |    Weight  [0.09652909 0.10222605 0.09863445 0.10232856 0.09723944],\n",
      "    |     Bias [0.07259827 0.07240088 0.07253554 0.07243572 0.07256555]\n",
      "Iterate 98: Cost 0.005228849475946691,   \n",
      "  |    Weight  [0.09649369 0.1022487  0.09862053 0.10235239 0.09721125],\n",
      "    |     Bias [0.07323729 0.07303789 0.07317393 0.07307309 0.07320424]\n",
      "Iterate 99: Cost 0.005226810504658326,   \n",
      "  |    Weight  [0.0964583  0.10227135 0.09860661 0.1023762  0.09718307],\n",
      "    |     Bias [0.07387618 0.07367478 0.0738122  0.07371034 0.07384281]\n",
      "Iterate 100: Cost 0.005224772350279432,   \n",
      "  |    Weight  [0.09642291 0.10229399 0.0985927  0.10240002 0.0971549 ],\n",
      "    |     Bias [0.07451494 0.07431154 0.07445034 0.07434746 0.07448125]\n",
      "Iterate 101: Cost 0.0052227350124827016,   \n",
      "  |    Weight  [0.09638754 0.10231663 0.09857879 0.10242383 0.09712673],\n",
      "    |     Bias [0.07515357 0.07494817 0.07508835 0.07498445 0.07511956]\n",
      "Iterate 102: Cost 0.005220698490940955,   \n",
      "  |    Weight  [0.09635217 0.10233926 0.09856488 0.10244763 0.09709857],\n",
      "    |     Bias [0.07579208 0.07558467 0.07572623 0.07562131 0.07575774]\n",
      "Iterate 103: Cost 0.0052186627853271494,   \n",
      "  |    Weight  [0.0963168  0.10236188 0.09855098 0.10247143 0.09707041],\n",
      "    |     Bias [0.07643046 0.07622105 0.07636399 0.07625805 0.07639579]\n",
      "Iterate 104: Cost 0.005216627895314367,   \n",
      "  |    Weight  [0.09628145 0.1023845  0.09853708 0.10249523 0.09704226],\n",
      "    |     Bias [0.07706871 0.0768573  0.07700162 0.07689465 0.07703372]\n",
      "Iterate 105: Cost 0.005214593820575825,   \n",
      "  |    Weight  [0.0962461  0.10240711 0.09852318 0.10251903 0.09701411],\n",
      "    |     Bias [0.07770683 0.07749342 0.07763912 0.07753113 0.07767152]\n",
      "Iterate 106: Cost 0.00521256056078487,   \n",
      "  |    Weight  [0.09621076 0.10242971 0.09850929 0.10254282 0.09698597],\n",
      "    |     Bias [0.07834482 0.07812941 0.0782765  0.07816749 0.07830919]\n",
      "Iterate 107: Cost 0.005210528115614979,   \n",
      "  |    Weight  [0.09617543 0.10245231 0.0984954  0.10256661 0.09695784],\n",
      "    |     Bias [0.07898269 0.07876528 0.07891374 0.07880371 0.07894673]\n",
      "Iterate 108: Cost 0.005208496484739762,   \n",
      "  |    Weight  [0.09614011 0.10247491 0.09848151 0.10259039 0.09692971],\n",
      "    |     Bias [0.07962043 0.07940102 0.07955086 0.07943981 0.07958415]\n",
      "Iterate 109: Cost 0.005206465667832957,   \n",
      "  |    Weight  [0.09610479 0.10249749 0.09846762 0.10261417 0.09690158],\n",
      "    |     Bias [0.08025804 0.08003663 0.08018785 0.08007578 0.08022143]\n",
      "Iterate 110: Cost 0.005204435664568435,   \n",
      "  |    Weight  [0.09606948 0.10252008 0.09845374 0.10263794 0.09687346],\n",
      "    |     Bias [0.08089552 0.08067211 0.08082472 0.08071163 0.08085859]\n",
      "Iterate 111: Cost 0.005202406474620197,   \n",
      "  |    Weight  [0.09603418 0.10254265 0.09843986 0.10266172 0.09684535],\n",
      "    |     Bias [0.08153287 0.08130747 0.08146145 0.08134734 0.08149563]\n",
      "Iterate 112: Cost 0.005200378097662375,   \n",
      "  |    Weight  [0.09599889 0.10256522 0.09842599 0.10268549 0.09681724],\n",
      "    |     Bias [0.0821701  0.0819427  0.08209806 0.08198293 0.08213253]\n",
      "Iterate 113: Cost 0.005198350533369227,   \n",
      "  |    Weight  [0.0959636  0.10258778 0.09841212 0.10270925 0.09678914],\n",
      "    |     Bias [0.0828072  0.0825778  0.08273454 0.08261839 0.08276931]\n",
      "Iterate 114: Cost 0.00519632378141515,   \n",
      "  |    Weight  [0.09592833 0.10261034 0.09839825 0.10273301 0.09676105],\n",
      "    |     Bias [0.08344417 0.08321278 0.0833709  0.08325373 0.08340596]\n",
      "Iterate 115: Cost 0.005194297841474664,   \n",
      "  |    Weight  [0.09589306 0.10263289 0.09838438 0.10275677 0.09673296],\n",
      "    |     Bias [0.08408101 0.08384762 0.08400712 0.08388893 0.08404248]\n",
      "Iterate 116: Cost 0.005192272713222425,   \n",
      "  |    Weight  [0.09585779 0.10265544 0.09837052 0.10278052 0.09670487],\n",
      "    |     Bias [0.08471772 0.08448234 0.08464322 0.08452401 0.08467887]\n",
      "Iterate 117: Cost 0.005190248396333214,   \n",
      "  |    Weight  [0.09582254 0.10267798 0.09835666 0.10280427 0.09667679],\n",
      "    |     Bias [0.08535431 0.08511694 0.0852792  0.08515897 0.08531514]\n",
      "Iterate 118: Cost 0.005188224890481946,   \n",
      "  |    Weight  [0.09578729 0.10270051 0.09834281 0.10282802 0.09664872],\n",
      "    |     Bias [0.08599077 0.0857514  0.08591504 0.08579379 0.08595128]\n",
      "Iterate 119: Cost 0.005186202195343666,   \n",
      "  |    Weight  [0.09575205 0.10272304 0.09832895 0.10285176 0.09662065],\n",
      "    |     Bias [0.0866271  0.08638574 0.08655076 0.08642849 0.08658729]\n",
      "Iterate 120: Cost 0.0051841803105935474,   \n",
      "  |    Weight  [0.09571682 0.10274556 0.0983151  0.1028755  0.09659258],\n",
      "    |     Bias [0.0872633  0.08701996 0.08718635 0.08706306 0.08722317]\n",
      "Iterate 121: Cost 0.005182159235906894,   \n",
      "  |    Weight  [0.0956816  0.10276808 0.09830126 0.10289923 0.09656453],\n",
      "    |     Bias [0.08789938 0.08765404 0.08782181 0.08769751 0.08785893]\n",
      "Iterate 122: Cost 0.005180138970959141,   \n",
      "  |    Weight  [0.09564638 0.10279059 0.09828741 0.10292296 0.09653648],\n",
      "    |     Bias [0.08853533 0.088288   0.08845715 0.08833183 0.08849456]\n",
      "Iterate 123: Cost 0.005178119515425855,   \n",
      "  |    Weight  [0.09561118 0.10281309 0.09827357 0.10294669 0.09650843],\n",
      "    |     Bias [0.08917115 0.08892183 0.08909236 0.08896602 0.08913006]\n",
      "Iterate 124: Cost 0.00517610086898273,   \n",
      "  |    Weight  [0.09557598 0.10283559 0.09825974 0.10297042 0.09648039],\n",
      "    |     Bias [0.08980684 0.08955553 0.08972744 0.08960008 0.08976544]\n",
      "Iterate 125: Cost 0.005174083031305589,   \n",
      "  |    Weight  [0.09554078 0.10285808 0.0982459  0.10299414 0.09645235],\n",
      "    |     Bias [0.09044241 0.09018911 0.09036239 0.09023402 0.09040068]\n",
      "Iterate 126: Cost 0.005172066002070386,   \n",
      "  |    Weight  [0.0955056  0.10288057 0.09823207 0.10301785 0.09642432],\n",
      "    |     Bias [0.09107785 0.09082256 0.09099722 0.09086783 0.0910358 ]\n",
      "Iterate 127: Cost 0.005170049780953209,   \n",
      "  |    Weight  [0.09547042 0.10290305 0.09821825 0.10304156 0.0963963 ],\n",
      "    |     Bias [0.09171316 0.09145589 0.09163192 0.09150151 0.0916708 ]\n",
      "Iterate 128: Cost 0.0051680343676302675,   \n",
      "  |    Weight  [0.09543525 0.10292552 0.09820442 0.10306527 0.09636828],\n",
      "    |     Bias [0.09234834 0.09208908 0.0922665  0.09213507 0.09230566]\n",
      "Iterate 129: Cost 0.005166019761777912,   \n",
      "  |    Weight  [0.09540009 0.10294799 0.0981906  0.10308898 0.09634027],\n",
      "    |     Bias [0.0929834  0.09272215 0.09290094 0.0927685  0.0929404 ]\n",
      "Iterate 130: Cost 0.005164005963072607,   \n",
      "  |    Weight  [0.09536493 0.10297045 0.09817678 0.10311268 0.09631226],\n",
      "    |     Bias [0.09361833 0.09335509 0.09353526 0.0934018  0.09357501]\n",
      "Iterate 131: Cost 0.005161992971190963,   \n",
      "  |    Weight  [0.09532979 0.10299291 0.09816297 0.10313638 0.09628426],\n",
      "    |     Bias [0.09425313 0.09398791 0.09416946 0.09403497 0.0942095 ]\n",
      "Iterate 132: Cost 0.005159980785809709,   \n",
      "  |    Weight  [0.09529465 0.10301536 0.09814916 0.10316007 0.09625626],\n",
      "    |     Bias [0.0948878  0.0946206  0.09480352 0.09466802 0.09484385]\n",
      "Iterate 133: Cost 0.00515796940660571,   \n",
      "  |    Weight  [0.09525952 0.1030378  0.09813535 0.10318376 0.09622827],\n",
      "    |     Bias [0.09552235 0.09525316 0.09543746 0.09530094 0.09547808]\n",
      "Iterate 134: Cost 0.005155958833255954,   \n",
      "  |    Weight  [0.09522439 0.10306024 0.09812154 0.10320745 0.09620028],\n",
      "    |     Bias [0.09615677 0.0958856  0.09607127 0.09593374 0.09611219]\n",
      "Iterate 135: Cost 0.0051539490654375665,   \n",
      "  |    Weight  [0.09518928 0.10308267 0.09810774 0.10323113 0.0961723 ],\n",
      "    |     Bias [0.09679106 0.09651791 0.09670496 0.09656641 0.09674616]\n",
      "Iterate 136: Cost 0.005151940102827795,   \n",
      "  |    Weight  [0.09515417 0.1031051  0.09809394 0.10325481 0.09614433],\n",
      "    |     Bias [0.09742522 0.09715009 0.09733852 0.09719895 0.09738001]\n",
      "Iterate 137: Cost 0.005149931945104021,   \n",
      "  |    Weight  [0.09511907 0.10312752 0.09808015 0.10327848 0.09611636],\n",
      "    |     Bias [0.09805926 0.09778215 0.09797195 0.09783137 0.09801373]\n",
      "Iterate 138: Cost 0.005147924591943752,   \n",
      "  |    Weight  [0.09508398 0.10314993 0.09806636 0.10330216 0.0960884 ],\n",
      "    |     Bias [0.09869317 0.09841408 0.09860525 0.09846366 0.09864733]\n",
      "Iterate 139: Cost 0.0051459180430246275,   \n",
      "  |    Weight  [0.09504889 0.10317234 0.09805257 0.10332582 0.09606044],\n",
      "    |     Bias [0.09932695 0.09904588 0.09923843 0.09909582 0.0992808 ]\n",
      "Iterate 140: Cost 0.005143912298024415,   \n",
      "  |    Weight  [0.09501381 0.10319474 0.09803878 0.10334949 0.09603249],\n",
      "    |     Bias [0.09996061 0.09967755 0.09987148 0.09972785 0.09991414]\n",
      "Iterate 141: Cost 0.00514190735662101,   \n",
      "  |    Weight  [0.09497874 0.10321714 0.098025   0.10337315 0.09600454],\n",
      "    |     Bias [0.10059414 0.1003091  0.10050441 0.10035976 0.10054735]\n",
      "Iterate 142: Cost 0.005139903218492438,   \n",
      "  |    Weight  [0.09494368 0.10323953 0.09801122 0.1033968  0.0959766 ],\n",
      "    |     Bias [0.10122754 0.10094053 0.10113721 0.10099154 0.10118044]\n",
      "Iterate 143: Cost 0.005137899883316857,   \n",
      "  |    Weight  [0.09490863 0.10326191 0.09799744 0.10342046 0.09594866],\n",
      "    |     Bias [0.10186081 0.10157182 0.10176988 0.1016232  0.1018134 ]\n",
      "Iterate 144: Cost 0.005135897350772546,   \n",
      "  |    Weight  [0.09487358 0.10328429 0.09798367 0.10344411 0.09592073],\n",
      "    |     Bias [0.10249396 0.10220299 0.10240242 0.10225473 0.10244623]\n",
      "Iterate 145: Cost 0.005133895620537922,   \n",
      "  |    Weight  [0.09483854 0.10330667 0.0979699  0.10346775 0.09589281],\n",
      "    |     Bias [0.10312698 0.10283404 0.10303484 0.10288613 0.10307894]\n",
      "Iterate 146: Cost 0.0051318946922915215,   \n",
      "  |    Weight  [0.09480351 0.10332903 0.09795613 0.10349139 0.09586489],\n",
      "    |     Bias [0.10375987 0.10346496 0.10366713 0.10351741 0.10371152]\n",
      "Iterate 147: Cost 0.005129894565712016,   \n",
      "  |    Weight  [0.09476848 0.10335139 0.09794237 0.10351503 0.09583697],\n",
      "    |     Bias [0.10439264 0.10409575 0.1042993  0.10414856 0.10434397]\n",
      "Iterate 148: Cost 0.005127895240478208,   \n",
      "  |    Weight  [0.09473347 0.10337375 0.09792861 0.10353867 0.09580906],\n",
      "    |     Bias [0.10502528 0.10472641 0.10493134 0.10477959 0.1049763 ]\n",
      "Iterate 149: Cost 0.005125896716269023,   \n",
      "  |    Weight  [0.09469846 0.1033961  0.09791485 0.1035623  0.09578116],\n",
      "    |     Bias [0.10565779 0.10535695 0.10556325 0.10541048 0.1056085 ]\n",
      "Iterate 150: Cost 0.005123898992763515,   \n",
      "  |    Weight  [0.09466346 0.10341844 0.0979011  0.10358592 0.09575326],\n",
      "    |     Bias [0.10629018 0.10598736 0.10619504 0.10604125 0.10624057]\n",
      "Iterate 151: Cost 0.005121902069640871,   \n",
      "  |    Weight  [0.09462846 0.10344078 0.09788735 0.10360955 0.09572537],\n",
      "    |     Bias [0.10692244 0.10661765 0.1068267  0.1066719  0.10687252]\n",
      "Iterate 152: Cost 0.005119905946580405,   \n",
      "  |    Weight  [0.09459348 0.10346311 0.0978736  0.10363317 0.09569749],\n",
      "    |     Bias [0.10755457 0.10724781 0.10745823 0.10730242 0.10750434]\n",
      "Iterate 153: Cost 0.005117910623261557,   \n",
      "  |    Weight  [0.0945585  0.10348544 0.09785985 0.10365678 0.09566961],\n",
      "    |     Bias [0.10818657 0.10787784 0.10808964 0.10793281 0.10813603]\n",
      "Iterate 154: Cost 0.005115916099363898,   \n",
      "  |    Weight  [0.09452353 0.10350775 0.09784611 0.10368039 0.09564173],\n",
      "    |     Bias [0.10881845 0.10850775 0.10872092 0.10856308 0.1087676 ]\n",
      "Iterate 155: Cost 0.005113922374567127,   \n",
      "  |    Weight  [0.09448857 0.10353007 0.09783237 0.103704   0.09561386],\n",
      "    |     Bias [0.1094502  0.10913753 0.10935207 0.10919322 0.10939904]\n",
      "Iterate 156: Cost 0.005111929448551072,   \n",
      "  |    Weight  [0.09445361 0.10355238 0.09781864 0.10372761 0.095586  ],\n",
      "    |     Bias [0.11008183 0.10976718 0.1099831  0.10982323 0.11003035]\n",
      "Iterate 157: Cost 0.005109937320995685,   \n",
      "  |    Weight  [0.09441867 0.10357468 0.09780491 0.10375121 0.09555814],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |     Bias [0.11071332 0.11039671 0.110614   0.11045312 0.11066154]\n",
      "Iterate 158: Cost 0.005107945991581054,   \n",
      "  |    Weight  [0.09438373 0.10359697 0.09779118 0.10377481 0.09553028],\n",
      "    |     Bias [0.1113447  0.11102611 0.11124478 0.11108288 0.1112926 ]\n",
      "Iterate 159: Cost 0.0051059554599873856,   \n",
      "  |    Weight  [0.09434879 0.10361926 0.09777745 0.1037984  0.09550244],\n",
      "    |     Bias [0.11197594 0.11165539 0.11187543 0.11171252 0.11192353]\n",
      "Iterate 160: Cost 0.005103965725895025,   \n",
      "  |    Weight  [0.09431387 0.10364155 0.09776373 0.10382199 0.09547459],\n",
      "    |     Bias [0.11260706 0.11228454 0.11250595 0.11234203 0.11255434]\n",
      "Iterate 161: Cost 0.005101976788984436,   \n",
      "  |    Weight  [0.09427895 0.10366383 0.09775001 0.10384558 0.09544676],\n",
      "    |     Bias [0.11323805 0.11291356 0.11313634 0.11297141 0.11318502]\n",
      "Iterate 162: Cost 0.005099988648936216,   \n",
      "  |    Weight  [0.09424404 0.1036861  0.09773629 0.10386916 0.09541893],\n",
      "    |     Bias [0.11386891 0.11354246 0.11376662 0.11360067 0.11381558]\n",
      "Iterate 163: Cost 0.0050980013054310915,   \n",
      "  |    Weight  [0.09420914 0.10370836 0.09772258 0.10389274 0.0953911 ],\n",
      "    |     Bias [0.11449965 0.11417123 0.11439676 0.1142298  0.11444601]\n",
      "Iterate 164: Cost 0.005096014758149907,   \n",
      "  |    Weight  [0.09417425 0.10373062 0.09770887 0.10391631 0.09536328],\n",
      "    |     Bias [0.11513026 0.11479988 0.11502678 0.11485881 0.11507631]\n",
      "Iterate 165: Cost 0.005094029006773652,   \n",
      "  |    Weight  [0.09413936 0.10375288 0.09769516 0.10393988 0.09533546],\n",
      "    |     Bias [0.11576075 0.1154284  0.11565667 0.11548769 0.11570649]\n",
      "Iterate 166: Cost 0.005092044050983426,   \n",
      "  |    Weight  [0.09410448 0.10377513 0.09768146 0.10396345 0.09530765],\n",
      "    |     Bias [0.11639111 0.11605679 0.11628644 0.11611644 0.11633654]\n",
      "Iterate 167: Cost 0.005090059890460468,   \n",
      "  |    Weight  [0.09406961 0.10379737 0.09766776 0.10398701 0.09527985],\n",
      "    |     Bias [0.11702134 0.11668506 0.11691608 0.11674507 0.11696646]\n",
      "Iterate 168: Cost 0.005088076524886139,   \n",
      "  |    Weight  [0.09403475 0.10381961 0.09765406 0.10401058 0.09525205],\n",
      "    |     Bias [0.11765144 0.11731321 0.11754559 0.11737357 0.11759626]\n",
      "Iterate 169: Cost 0.005086093953941933,   \n",
      "  |    Weight  [0.09399989 0.10384184 0.09764037 0.10403413 0.09522426],\n",
      "    |     Bias [0.11828142 0.11794122 0.11817498 0.11800195 0.11822593]\n",
      "Iterate 170: Cost 0.005084112177309467,   \n",
      "  |    Weight  [0.09396504 0.10386406 0.09762668 0.10405768 0.09519647],\n",
      "    |     Bias [0.11891127 0.11856911 0.11880424 0.1186302  0.11885547]\n",
      "Iterate 171: Cost 0.005082131194670484,   \n",
      "  |    Weight  [0.0939302  0.10388628 0.09761299 0.10408123 0.09516869],\n",
      "    |     Bias [0.119541   0.11919688 0.11943338 0.11925832 0.11948489]\n",
      "Iterate 172: Cost 0.005080151005706861,   \n",
      "  |    Weight  [0.09389537 0.10390849 0.09759931 0.10410478 0.09514091],\n",
      "    |     Bias [0.1201706  0.11982452 0.12006239 0.11988632 0.12011419]\n",
      "Iterate 173: Cost 0.005078171610100597,   \n",
      "  |    Weight  [0.09386054 0.1039307  0.09758562 0.10412832 0.09511314],\n",
      "    |     Bias [0.12080007 0.12045203 0.12069127 0.1205142  0.12074335]\n",
      "Iterate 174: Cost 0.0050761930075338205,   \n",
      "  |    Weight  [0.09382573 0.1039529  0.09757195 0.10415186 0.09508538],\n",
      "    |     Bias [0.12142942 0.12107942 0.12132003 0.12114194 0.12137239]\n",
      "Iterate 175: Cost 0.005074215197688788,   \n",
      "  |    Weight  [0.09379092 0.1039751  0.09755827 0.10417539 0.09505762],\n",
      "    |     Bias [0.12205864 0.12170668 0.12194866 0.12176956 0.12200131]\n",
      "Iterate 176: Cost 0.0050722381802478815,   \n",
      "  |    Weight  [0.09375611 0.10399729 0.0975446  0.10419892 0.09502986],\n",
      "    |     Bias [0.12268774 0.12233382 0.12257717 0.12239706 0.1226301 ]\n",
      "Iterate 177: Cost 0.005070261954893611,   \n",
      "  |    Weight  [0.09372132 0.10401947 0.09753093 0.10422245 0.09500211],\n",
      "    |     Bias [0.12331671 0.12296083 0.12320555 0.12302443 0.12325876]\n",
      "Iterate 178: Cost 0.005068286521308615,   \n",
      "  |    Weight  [0.09368653 0.10404165 0.09751726 0.10424597 0.09497437],\n",
      "    |     Bias [0.12394555 0.12358772 0.12383381 0.12365168 0.1238873 ]\n",
      "Iterate 179: Cost 0.0050663118791756554,   \n",
      "  |    Weight  [0.09365175 0.10406382 0.0975036  0.10426949 0.09494663],\n",
      "    |     Bias [0.12457426 0.12421448 0.12446194 0.1242788  0.12451571]\n",
      "Iterate 180: Cost 0.0050643380281776285,   \n",
      "  |    Weight  [0.09361698 0.10408598 0.09748994 0.10429301 0.0949189 ],\n",
      "    |     Bias [0.12520285 0.12484111 0.12508994 0.12490579 0.12514399]\n",
      "Iterate 181: Cost 0.00506236496799755,   \n",
      "  |    Weight  [0.09358222 0.10410814 0.09747629 0.10431652 0.09489117],\n",
      "    |     Bias [0.12583132 0.12546762 0.12571782 0.12553266 0.12577215]\n",
      "Iterate 182: Cost 0.005060392698318564,   \n",
      "  |    Weight  [0.09354746 0.1041303  0.09746263 0.10434003 0.09486345],\n",
      "    |     Bias [0.12645966 0.126094   0.12634557 0.1261594  0.12640018]\n",
      "Iterate 183: Cost 0.005058421218823946,   \n",
      "  |    Weight  [0.09351271 0.10415245 0.09744898 0.10436354 0.09483573],\n",
      "    |     Bias [0.12708787 0.12672026 0.1269732  0.12678602 0.12702809]\n",
      "Iterate 184: Cost 0.005056450529197097,   \n",
      "  |    Weight  [0.09347797 0.10417459 0.09743534 0.10438704 0.09480802],\n",
      "    |     Bias [0.12771595 0.12734639 0.1276007  0.12741251 0.12765587]\n",
      "Iterate 185: Cost 0.005054480629121539,   \n",
      "  |    Weight  [0.09344323 0.10419672 0.09742169 0.10441053 0.09478032],\n",
      "    |     Bias [0.12834391 0.1279724  0.12822808 0.12803888 0.12828353]\n",
      "Iterate 186: Cost 0.005052511518280929,   \n",
      "  |    Weight  [0.09340851 0.10421886 0.09740805 0.10443403 0.09475262],\n",
      "    |     Bias [0.12897175 0.12859828 0.12885533 0.12866512 0.12891106]\n",
      "Iterate 187: Cost 0.005050543196359044,   \n",
      "  |    Weight  [0.09337379 0.10424098 0.09739442 0.10445752 0.09472492],\n",
      "    |     Bias [0.12959945 0.12922404 0.12948246 0.12929123 0.12953846]\n",
      "Iterate 188: Cost 0.00504857566303979,   \n",
      "  |    Weight  [0.09333908 0.1042631  0.09738078 0.104481   0.09469723],\n",
      "    |     Bias [0.13022704 0.12984967 0.13010945 0.12991722 0.13016574]\n",
      "Iterate 189: Cost 0.005046608918007204,   \n",
      "  |    Weight  [0.09330437 0.10428521 0.09736715 0.10450449 0.09466955],\n",
      "    |     Bias [0.13085449 0.13047517 0.13073633 0.13054309 0.13079289]\n",
      "Iterate 190: Cost 0.005044642960945445,   \n",
      "  |    Weight  [0.09326968 0.10430732 0.09735352 0.10452797 0.09464187],\n",
      "    |     Bias [0.13148182 0.13110056 0.13136308 0.13116883 0.13141992]\n",
      "Iterate 191: Cost 0.005042677791538799,   \n",
      "  |    Weight  [0.09323499 0.10432942 0.0973399  0.10455144 0.0946142 ],\n",
      "    |     Bias [0.13210903 0.13172581 0.1319897  0.13179444 0.13204682]\n",
      "Iterate 192: Cost 0.0050407134094716775,   \n",
      "  |    Weight  [0.09320031 0.10435151 0.09732628 0.10457491 0.09458653],\n",
      "    |     Bias [0.1327361  0.13235094 0.1326162  0.13241993 0.1326736 ]\n",
      "Iterate 193: Cost 0.005038749814428624,   \n",
      "  |    Weight  [0.09316564 0.1043736  0.09731266 0.10459838 0.09455887],\n",
      "    |     Bias [0.13336306 0.13297594 0.13324257 0.1330453  0.13330025]\n",
      "Iterate 194: Cost 0.005036787006094298,   \n",
      "  |    Weight  [0.09313097 0.10439569 0.09729904 0.10462185 0.09453121],\n",
      "    |     Bias [0.13398988 0.13360082 0.13386882 0.13367054 0.13392677]\n",
      "Iterate 195: Cost 0.005034824984153496,   \n",
      "  |    Weight  [0.09309631 0.10441776 0.09728543 0.10464531 0.09450356],\n",
      "    |     Bias [0.13461658 0.13422558 0.13449494 0.13429565 0.13455317]\n",
      "Iterate 196: Cost 0.005032863748291137,   \n",
      "  |    Weight  [0.09306166 0.10443984 0.09727182 0.10466876 0.09447592],\n",
      "    |     Bias [0.13524316 0.13485021 0.13512094 0.13492064 0.13517945]\n",
      "Iterate 197: Cost 0.005030903298192262,   \n",
      "  |    Weight  [0.09302702 0.1044619  0.09725821 0.10469222 0.09444828],\n",
      "    |     Bias [0.13586961 0.13547471 0.13574681 0.1355455  0.1358056 ]\n",
      "Iterate 198: Cost 0.005028943633542045,   \n",
      "  |    Weight  [0.09299238 0.10448396 0.09724461 0.10471567 0.09442064],\n",
      "    |     Bias [0.13649593 0.13609909 0.13637255 0.13617024 0.13643162]\n",
      "Iterate 199: Cost 0.005026984754025783,   \n",
      "  |    Weight  [0.09295775 0.10450601 0.09723101 0.10473911 0.09439301],\n",
      "    |     Bias [0.13712213 0.13672334 0.13699818 0.13679485 0.13705752]\n",
      "Iterate 200: Cost 0.005025026659328898,   \n",
      "  |    Weight  [0.09292313 0.10452806 0.09721742 0.10476255 0.09436539],\n",
      "    |     Bias [0.1377482  0.13734747 0.13762367 0.13741934 0.13768329]\n",
      "Iterate 201: Cost 0.005023069349136938,   \n",
      "  |    Weight  [0.09288852 0.10455011 0.09720382 0.10478599 0.09433777],\n",
      "    |     Bias [0.13837415 0.13797148 0.13824904 0.13804371 0.13830894]\n",
      "Iterate 202: Cost 0.00502111282313558,   \n",
      "  |    Weight  [0.09285392 0.10457214 0.09719023 0.10480943 0.09431016],\n",
      "    |     Bias [0.13899997 0.13859535 0.13887429 0.13866794 0.13893446]\n",
      "Iterate 203: Cost 0.005019157081010627,   \n",
      "  |    Weight  [0.09281932 0.10459417 0.09717665 0.10483286 0.09428255],\n",
      "    |     Bias [0.13962567 0.13921911 0.13949941 0.13929206 0.13955985]\n",
      "Iterate 204: Cost 0.005017202122448,   \n",
      "  |    Weight  [0.09278473 0.1046162  0.09716306 0.10485629 0.09425495],\n",
      "    |     Bias [0.14025124 0.13984274 0.1401244  0.13991604 0.14018512]\n",
      "Iterate 205: Cost 0.005015247947133758,   \n",
      "  |    Weight  [0.09275015 0.10463822 0.09714948 0.10487971 0.09422735],\n",
      "    |     Bias [0.14087668 0.14046624 0.14074927 0.14053991 0.14081027]\n",
      "Iterate 206: Cost 0.005013294554754075,   \n",
      "  |    Weight  [0.09271557 0.10466023 0.0971359  0.10490313 0.09419976],\n",
      "    |     Bias [0.141502   0.14108962 0.14137402 0.14116365 0.14143529]\n",
      "Iterate 207: Cost 0.00501134194499526,   \n",
      "  |    Weight  [0.09268101 0.10468224 0.09712233 0.10492655 0.09417218],\n",
      "    |     Bias [0.14212719 0.14171287 0.14199864 0.14178726 0.14206018]\n",
      "Iterate 208: Cost 0.005009390117543738,   \n",
      "  |    Weight  [0.09264645 0.10470424 0.09710876 0.10494996 0.0941446 ],\n",
      "    |     Bias [0.14275226 0.142336   0.14262313 0.14241075 0.14268495]\n",
      "Iterate 209: Cost 0.005007439072086067,   \n",
      "  |    Weight  [0.09261189 0.10472623 0.09709519 0.10497337 0.09411702],\n",
      "    |     Bias [0.1433772  0.14295901 0.1432475  0.14303411 0.1433096 ]\n",
      "Iterate 210: Cost 0.005005488808308931,   \n",
      "  |    Weight  [0.09257735 0.10474822 0.09708162 0.10499678 0.09408945],\n",
      "    |     Bias [0.14400202 0.14358189 0.14387175 0.14365735 0.14393412]\n",
      "Iterate 211: Cost 0.005003539325899132,   \n",
      "  |    Weight  [0.09254281 0.1047702  0.09706806 0.10502018 0.09406189],\n",
      "    |     Bias [0.14462671 0.14420464 0.14449587 0.14428047 0.14455851]\n",
      "Iterate 212: Cost 0.005001590624543604,   \n",
      "  |    Weight  [0.09250828 0.10479218 0.0970545  0.10504358 0.09403433],\n",
      "    |     Bias [0.14525128 0.14482727 0.14511986 0.14490346 0.14518278]\n",
      "Iterate 213: Cost 0.0049996427039294055,   \n",
      "  |    Weight  [0.09247376 0.10481415 0.09704095 0.10506697 0.09400678],\n",
      "    |     Bias [0.14587572 0.14544978 0.14574373 0.14552632 0.14580693]\n",
      "Iterate 214: Cost 0.004997695563743719,   \n",
      "  |    Weight  [0.09243925 0.10483612 0.09702739 0.10509036 0.09397923],\n",
      "    |     Bias [0.14650004 0.14607216 0.14636748 0.14614906 0.14643094]\n",
      "Iterate 215: Cost 0.004995749203673853,   \n",
      "  |    Weight  [0.09240474 0.10485808 0.09701384 0.10511375 0.09395169],\n",
      "    |     Bias [0.14712423 0.14669441 0.1469911  0.14677168 0.14705484]\n",
      "Iterate 216: Cost 0.004993803623407242,   \n",
      "  |    Weight  [0.09237024 0.10488003 0.0970003  0.10513713 0.09392415],\n",
      "    |     Bias [0.14774829 0.14731654 0.1476146  0.14739417 0.14767861]\n",
      "Iterate 217: Cost 0.004991858822631445,   \n",
      "  |    Weight  [0.09233575 0.10490198 0.09698676 0.10516051 0.09389662],\n",
      "    |     Bias [0.14837223 0.14793855 0.14823797 0.14801653 0.14830225]\n",
      "Iterate 218: Cost 0.004989914801034143,   \n",
      "  |    Weight  [0.09230126 0.10492393 0.09697322 0.10518389 0.0938691 ],\n",
      "    |     Bias [0.14899605 0.14856043 0.14886121 0.14863877 0.14892577]\n",
      "Iterate 219: Cost 0.004987971558303149,   \n",
      "  |    Weight  [0.09226679 0.10494586 0.09695968 0.10520726 0.09384158],\n",
      "    |     Bias [0.14961974 0.14918219 0.14948434 0.14926089 0.14954916]\n",
      "Iterate 220: Cost 0.004986029094126396,   \n",
      "  |    Weight  [0.09223232 0.10496779 0.09694614 0.10523063 0.09381406],\n",
      "    |     Bias [0.1502433  0.14980382 0.15010733 0.14988288 0.15017243]\n",
      "Iterate 221: Cost 0.0049840874081919445,   \n",
      "  |    Weight  [0.09219786 0.10498972 0.09693261 0.10525399 0.09378655],\n",
      "    |     Bias [0.15086674 0.15042533 0.1507302  0.15050475 0.15079558]\n",
      "Iterate 222: Cost 0.004982146500187977,   \n",
      "  |    Weight  [0.0921634  0.10501164 0.09691909 0.10527736 0.09375905],\n",
      "    |     Bias [0.15149006 0.15104672 0.15135295 0.15112649 0.1514186 ]\n",
      "Iterate 223: Cost 0.004980206369802803,   \n",
      "  |    Weight  [0.09212896 0.10503355 0.09690556 0.10530071 0.09373155],\n",
      "    |     Bias [0.15211325 0.15166797 0.15197558 0.15174811 0.15204149]\n",
      "Iterate 224: Cost 0.004978267016724857,   \n",
      "  |    Weight  [0.09209452 0.10505546 0.09689204 0.10532407 0.09370406],\n",
      "    |     Bias [0.15273631 0.15228911 0.15259807 0.15236961 0.15266426]\n",
      "Iterate 225: Cost 0.0049763284406427,   \n",
      "  |    Weight  [0.09206009 0.10507736 0.09687852 0.10534742 0.09367657],\n",
      "    |     Bias [0.15335925 0.15291012 0.15322045 0.15299098 0.15328691]\n",
      "Iterate 226: Cost 0.004974390641245012,   \n",
      "  |    Weight  [0.09202566 0.10509926 0.09686501 0.10537077 0.09364909],\n",
      "    |     Bias [0.15398207 0.15353101 0.1538427  0.15361222 0.15390943]\n",
      "Iterate 227: Cost 0.004972453618220607,   \n",
      "  |    Weight  [0.09199125 0.10512115 0.0968515  0.10539411 0.09362161],\n",
      "    |     Bias [0.15460475 0.15415177 0.15446482 0.15423335 0.15453182]\n",
      "Iterate 228: Cost 0.004970517371258412,   \n",
      "  |    Weight  [0.09195684 0.10514303 0.09683799 0.10541745 0.09359414],\n",
      "    |     Bias [0.15522732 0.15477241 0.15508682 0.15485434 0.15515409]\n",
      "Iterate 229: Cost 0.0049685819000474885,   \n",
      "  |    Weight  [0.09192244 0.10516491 0.09682448 0.10544078 0.09356667],\n",
      "    |     Bias [0.15584976 0.15539292 0.1557087  0.15547521 0.15577624]\n",
      "Iterate 230: Cost 0.004966647204277018,   \n",
      "  |    Weight  [0.09188804 0.10518678 0.09681098 0.10546412 0.09353921],\n",
      "    |     Bias [0.15647207 0.15601331 0.15633045 0.15609596 0.15639826]\n",
      "Iterate 231: Cost 0.004964713283636309,   \n",
      "  |    Weight  [0.09185366 0.10520865 0.09679748 0.10548745 0.09351176],\n",
      "    |     Bias [0.15709426 0.15663357 0.15695208 0.15671659 0.15702016]\n",
      "Iterate 232: Cost 0.00496278013781479,   \n",
      "  |    Weight  [0.09181928 0.10523051 0.09678398 0.10551077 0.09348431],\n",
      "    |     Bias [0.15771633 0.15725371 0.15757358 0.15733709 0.15764193]\n",
      "Iterate 233: Cost 0.004960847766502022,   \n",
      "  |    Weight  [0.09178491 0.10525236 0.09677049 0.10553409 0.09345686],\n",
      "    |     Bias [0.15833827 0.15787373 0.15819496 0.15795746 0.15826358]\n",
      "Iterate 234: Cost 0.004958916169387678,   \n",
      "  |    Weight  [0.09175055 0.10527421 0.096757   0.10555741 0.09342943],\n",
      "    |     Bias [0.15896008 0.15849362 0.15881621 0.15857771 0.1588851 ]\n",
      "Iterate 235: Cost 0.004956985346161568,   \n",
      "  |    Weight  [0.09171619 0.10529606 0.09674351 0.10558072 0.09340199],\n",
      "    |     Bias [0.15958178 0.15911339 0.15943734 0.15919784 0.1595065 ]\n",
      "Iterate 236: Cost 0.00495505529651362,   \n",
      "  |    Weight  [0.09168184 0.10531789 0.09673003 0.10560403 0.09337456],\n",
      "    |     Bias [0.16020334 0.15973303 0.16005835 0.15981784 0.16012778]\n",
      "Iterate 237: Cost 0.004953126020133885,   \n",
      "  |    Weight  [0.0916475  0.10533972 0.09671655 0.10562734 0.09334714],\n",
      "    |     Bias [0.16082478 0.16035255 0.16067923 0.16043772 0.16074893]\n",
      "Iterate 238: Cost 0.0049511975167125435,   \n",
      "  |    Weight  [0.09161317 0.10536155 0.09670307 0.10565064 0.09331972],\n",
      "    |     Bias [0.1614461  0.16097195 0.16129999 0.16105748 0.16136995]\n",
      "Iterate 239: Cost 0.004949269785939896,   \n",
      "  |    Weight  [0.09157884 0.10538337 0.09668959 0.10567394 0.09329231],\n",
      "    |     Bias [0.16206729 0.16159122 0.16192062 0.16167711 0.16199085]\n",
      "Iterate 240: Cost 0.004947342827506366,   \n",
      "  |    Weight  [0.09154452 0.10540518 0.09667612 0.10569724 0.09326491],\n",
      "    |     Bias [0.16268836 0.16221036 0.16254113 0.16229662 0.16261163]\n",
      "Iterate 241: Cost 0.0049454166411025055,   \n",
      "  |    Weight  [0.09151021 0.10542699 0.09666265 0.10572053 0.09323751],\n",
      "    |     Bias [0.1633093  0.16282939 0.16316151 0.162916   0.16323228]\n",
      "Iterate 242: Cost 0.004943491226418987,   \n",
      "  |    Weight  [0.09147591 0.1054488  0.09664919 0.10574382 0.09321011],\n",
      "    |     Bias [0.16393012 0.16344829 0.16378177 0.16353526 0.16385281]\n",
      "Iterate 243: Cost 0.004941566583146607,   \n",
      "  |    Weight  [0.09144161 0.10547059 0.09663573 0.10576711 0.09318272],\n",
      "    |     Bias [0.16455081 0.16406706 0.16440191 0.16415439 0.16447321]\n",
      "Iterate 244: Cost 0.00493964271097629,   \n",
      "  |    Weight  [0.09140732 0.10549238 0.09662227 0.10579039 0.09315533],\n",
      "    |     Bias [0.16517138 0.16468571 0.16502192 0.1647734  0.16509349]\n",
      "Iterate 245: Cost 0.004937719609599078,   \n",
      "  |    Weight  [0.09137304 0.10551417 0.09660881 0.10581366 0.09312796],\n",
      "    |     Bias [0.16579183 0.16530424 0.16564181 0.16539229 0.16571365]\n",
      "Iterate 246: Cost 0.004935797278706142,   \n",
      "  |    Weight  [0.09133877 0.10553595 0.09659536 0.10583694 0.09310058],\n",
      "    |     Bias [0.16641215 0.16592264 0.16626157 0.16601105 0.16633368]\n",
      "Iterate 247: Cost 0.004933875717988774,   \n",
      "  |    Weight  [0.0913045  0.10555772 0.09658191 0.10586021 0.09307321],\n",
      "    |     Bias [0.16703234 0.16654092 0.16688121 0.16662969 0.16695358]\n",
      "Iterate 248: Cost 0.00493195492713839,   \n",
      "  |    Weight  [0.09127025 0.10557949 0.09656846 0.10588348 0.09304585],\n",
      "    |     Bias [0.16765241 0.16715908 0.16750073 0.16724821 0.16757336]\n",
      "Iterate 249: Cost 0.004930034905846532,   \n",
      "  |    Weight  [0.09123599 0.10560125 0.09655502 0.10590674 0.09301849],\n",
      "    |     Bias [0.16827236 0.16777711 0.16812012 0.1678666  0.16819302]\n",
      "Iterate 250: Cost 0.004928115653804861,   \n",
      "  |    Weight  [0.09120175 0.10562301 0.09654158 0.10593    0.09299114],\n",
      "    |     Bias [0.16889218 0.16839502 0.16873939 0.16848486 0.16881256]\n",
      "Iterate 251: Cost 0.004926197170705166,   \n",
      "  |    Weight  [0.09116752 0.10564476 0.09652814 0.10595325 0.09296379],\n",
      "    |     Bias [0.16951188 0.1690128  0.16935853 0.16910301 0.16943197]\n",
      "Iterate 252: Cost 0.004924279456239356,   \n",
      "  |    Weight  [0.09113329 0.1056665  0.09651471 0.10597651 0.09293645],\n",
      "    |     Bias [0.17013145 0.16963046 0.16997755 0.16972103 0.17005125]\n",
      "Iterate 253: Cost 0.004922362510099469,   \n",
      "  |    Weight  [0.09109907 0.10568824 0.09650128 0.10599975 0.09290911],\n",
      "    |     Bias [0.1707509  0.170248   0.17059645 0.17033892 0.17067041]\n",
      "Iterate 254: Cost 0.004920446331977659,   \n",
      "  |    Weight  [0.09106485 0.10570997 0.09648785 0.106023   0.09288178],\n",
      "    |     Bias [0.17137023 0.17086541 0.17121522 0.1709567  0.17128945]\n",
      "Iterate 255: Cost 0.004918530921566208,   \n",
      "  |    Weight  [0.09103065 0.1057317  0.09647442 0.10604624 0.09285446],\n",
      "    |     Bias [0.17198943 0.1714827  0.17183387 0.17157435 0.17190836]\n",
      "Iterate 256: Cost 0.00491661627855752,   \n",
      "  |    Weight  [0.09099645 0.10575342 0.096461   0.10606948 0.09282714],\n",
      "    |     Bias [0.17260851 0.17209987 0.17245239 0.17219187 0.17252715]\n",
      "Iterate 257: Cost 0.004914702402644123,   \n",
      "  |    Weight  [0.09096226 0.10577514 0.09644758 0.10609271 0.09279982],\n",
      "    |     Bias [0.17322746 0.17271691 0.17307079 0.17280927 0.17314582]\n",
      "Iterate 258: Cost 0.004912789293518665,   \n",
      "  |    Weight  [0.09092808 0.10579684 0.09643417 0.10611594 0.09277251],\n",
      "    |     Bias [0.17384629 0.17333383 0.17368907 0.17342655 0.17376436]\n",
      "Iterate 259: Cost 0.004910876950873925,   \n",
      "  |    Weight  [0.0908939  0.10581855 0.09642076 0.10613917 0.09274521],\n",
      "    |     Bias [0.17446499 0.17395062 0.17430722 0.1740437  0.17438278]\n",
      "Iterate 260: Cost 0.004908965374402795,   \n",
      "  |    Weight  [0.09085973 0.10584025 0.09640735 0.10616239 0.09271791],\n",
      "    |     Bias [0.17508357 0.17456729 0.17492525 0.17466074 0.17500107]\n",
      "Iterate 261: Cost 0.004907054563798297,   \n",
      "  |    Weight  [0.09082557 0.10586194 0.09639394 0.10618561 0.09269062],\n",
      "    |     Bias [0.17570202 0.17518384 0.17554316 0.17527764 0.17561924]\n",
      "Iterate 262: Cost 0.004905144518753574,   \n",
      "  |    Weight  [0.09079142 0.10588362 0.09638054 0.10620883 0.09266333],\n",
      "    |     Bias [0.17632036 0.17580027 0.17616094 0.17589443 0.17623729]\n",
      "Iterate 263: Cost 0.004903235238961892,   \n",
      "  |    Weight  [0.09075727 0.10590531 0.09636714 0.10623204 0.09263605],\n",
      "    |     Bias [0.17693856 0.17641657 0.1767786  0.17651109 0.17685521]\n",
      "Iterate 264: Cost 0.004901326724116637,   \n",
      "  |    Weight  [0.09072313 0.10592698 0.09635374 0.10625525 0.09260877],\n",
      "    |     Bias [0.17755665 0.17703274 0.17739614 0.17712762 0.17747301]\n",
      "Iterate 265: Cost 0.004899418973911325,   \n",
      "  |    Weight  [0.090689   0.10594865 0.09634035 0.10627845 0.0925815 ],\n",
      "    |     Bias [0.17817461 0.1776488  0.17801355 0.17774404 0.17809068]\n",
      "Iterate 266: Cost 0.004897511988039588,   \n",
      "  |    Weight  [0.09065488 0.10597031 0.09632696 0.10630165 0.09255423],\n",
      "    |     Bias [0.17879244 0.17826473 0.17863084 0.17836033 0.17870823]\n",
      "Iterate 267: Cost 0.004895605766195184,   \n",
      "  |    Weight  [0.09062076 0.10599197 0.09631357 0.10632485 0.09252697],\n",
      "    |     Bias [0.17941015 0.17888054 0.179248   0.17897649 0.17932566]\n",
      "Iterate 268: Cost 0.004893700308071991,   \n",
      "  |    Weight  [0.09058665 0.10601362 0.09630018 0.10634805 0.09249972],\n",
      "    |     Bias [0.18002774 0.17949622 0.17986504 0.17959254 0.17994296]\n",
      "Iterate 269: Cost 0.004891795613364012,   \n",
      "  |    Weight  [0.09055255 0.10603527 0.0962868  0.10637124 0.09247247],\n",
      "    |     Bias [0.18064521 0.18011178 0.18048196 0.18020846 0.18056014]\n",
      "Iterate 270: Cost 0.0048898916817653746,   \n",
      "  |    Weight  [0.09051846 0.10605691 0.09627342 0.10639442 0.09244522],\n",
      "    |     Bias [0.18126255 0.18072722 0.18109875 0.18082425 0.1811772 ]\n",
      "Iterate 271: Cost 0.004887988512970324,   \n",
      "  |    Weight  [0.09048437 0.10607854 0.09626005 0.10641761 0.09241798],\n",
      "    |     Bias [0.18187976 0.18134253 0.18171543 0.18143993 0.18179413]\n",
      "Iterate 272: Cost 0.004886086106673231,   \n",
      "  |    Weight  [0.09045029 0.10610017 0.09624668 0.10644079 0.09239075],\n",
      "    |     Bias [0.18249685 0.18195772 0.18233197 0.18205548 0.18241094]\n",
      "Iterate 273: Cost 0.00488418446256859,   \n",
      "  |    Weight  [0.09041622 0.10612179 0.09623331 0.10646396 0.09236352],\n",
      "    |     Bias [0.18311382 0.18257279 0.1829484  0.1826709  0.18302762]\n",
      "Iterate 274: Cost 0.004882283580351012,   \n",
      "  |    Weight  [0.09038216 0.10614341 0.09621994 0.10648713 0.0923363 ],\n",
      "    |     Bias [0.18373067 0.18318773 0.1835647  0.18328621 0.18364419]\n",
      "Iterate 275: Cost 0.004880383459715238,   \n",
      "  |    Weight  [0.0903481  0.10616502 0.09620658 0.1065103  0.09230908],\n",
      "    |     Bias [0.18434739 0.18380255 0.18418088 0.18390139 0.18426062]\n",
      "Iterate 276: Cost 0.004878484100356127,   \n",
      "  |    Weight  [0.09031405 0.10618662 0.09619322 0.10653347 0.09228187],\n",
      "    |     Bias [0.18496398 0.18441725 0.18479693 0.18451644 0.18487694]\n",
      "Iterate 277: Cost 0.00487658550196866,   \n",
      "  |    Weight  [0.09028001 0.10620822 0.09617986 0.10655663 0.09225466],\n",
      "    |     Bias [0.18558046 0.18503183 0.18541286 0.18513138 0.18549313]\n",
      "Iterate 278: Cost 0.004874687664247941,   \n",
      "  |    Weight  [0.09024598 0.10622982 0.09616651 0.10657979 0.09222746],\n",
      "    |     Bias [0.18619681 0.18564628 0.18602867 0.18574619 0.1861092 ]\n",
      "Iterate 279: Cost 0.004872790586889199,   \n",
      "  |    Weight  [0.09021195 0.10625141 0.09615316 0.10660294 0.09220026],\n",
      "    |     Bias [0.18681303 0.18626061 0.18664435 0.18636088 0.18672514]\n",
      "Iterate 280: Cost 0.00487089426958778,   \n",
      "  |    Weight  [0.09017793 0.10627299 0.09613981 0.10662609 0.09217307],\n",
      "    |     Bias [0.18742913 0.18687481 0.18725991 0.18697544 0.18734096]\n",
      "Iterate 281: Cost 0.004868998712039153,   \n",
      "  |    Weight  [0.09014392 0.10629456 0.09612647 0.10664924 0.09214589],\n",
      "    |     Bias [0.18804511 0.1874889  0.18787535 0.18758988 0.18795666]\n",
      "Iterate 282: Cost 0.004867103913938914,   \n",
      "  |    Weight  [0.09010992 0.10631613 0.09611313 0.10667238 0.09211871],\n",
      "    |     Bias [0.18866097 0.18810285 0.18849067 0.1882042  0.18857223]\n",
      "Iterate 283: Cost 0.004865209874982776,   \n",
      "  |    Weight  [0.09007592 0.1063377  0.09609979 0.10669552 0.09209153],\n",
      "    |     Bias [0.1892767  0.18871669 0.18910586 0.1888184  0.18918768]\n",
      "Iterate 284: Cost 0.004863316594866575,   \n",
      "  |    Weight  [0.09004193 0.10635926 0.09608645 0.10671866 0.09206436],\n",
      "    |     Bias [0.18989231 0.1893304  0.18972093 0.18943247 0.18980301]\n",
      "Iterate 285: Cost 0.004861424073286269,   \n",
      "  |    Weight  [0.09000795 0.10638081 0.09607312 0.10674179 0.0920372 ],\n",
      "    |     Bias [0.19050779 0.18994399 0.19033587 0.19004642 0.19041822]\n",
      "Iterate 286: Cost 0.00485953230993794,   \n",
      "  |    Weight  [0.08997398 0.10640236 0.09605979 0.10676492 0.09201004],\n",
      "    |     Bias [0.19112315 0.19055746 0.19095069 0.19066025 0.1910333 ]\n",
      "Iterate 287: Cost 0.004857641304517788,   \n",
      "  |    Weight  [0.08994001 0.1064239  0.09604647 0.10678804 0.09198288],\n",
      "    |     Bias [0.19173839 0.19117081 0.19156539 0.19127395 0.19164825]\n",
      "Iterate 288: Cost 0.0048557510567221384,   \n",
      "  |    Weight  [0.08990605 0.10644544 0.09603314 0.10681117 0.09195574],\n",
      "    |     Bias [0.1923535  0.19178403 0.19217997 0.19188753 0.19226309]\n",
      "Iterate 289: Cost 0.0048538615662474345,   \n",
      "  |    Weight  [0.0898721  0.10646697 0.09601982 0.10683428 0.09192859],\n",
      "    |     Bias [0.1929685  0.19239713 0.19279442 0.19250099 0.1928778 ]\n",
      "Iterate 290: Cost 0.004851972832790243,   \n",
      "  |    Weight  [0.08983816 0.10648849 0.09600651 0.1068574  0.09190146],\n",
      "    |     Bias [0.19358336 0.1930101  0.19340875 0.19311433 0.19349239]\n",
      "Iterate 291: Cost 0.004850084856047254,   \n",
      "  |    Weight  [0.08980422 0.10651001 0.09599319 0.10688051 0.09187432],\n",
      "    |     Bias [0.19419811 0.19362296 0.19402296 0.19372754 0.19410685]\n",
      "Iterate 292: Cost 0.0048481976357152776,   \n",
      "  |    Weight  [0.08977029 0.10653152 0.09597988 0.10690362 0.0918472 ],\n",
      "    |     Bias [0.19481273 0.19423569 0.19463705 0.19434063 0.19472119]\n",
      "Iterate 293: Cost 0.004846311171491244,   \n",
      "  |    Weight  [0.08973637 0.10655303 0.09596657 0.10692672 0.09182008],\n",
      "    |     Bias [0.19542722 0.1948483  0.19525101 0.1949536  0.19533541]\n",
      "Iterate 294: Cost 0.004844425463072208,   \n",
      "  |    Weight  [0.08970245 0.10657453 0.09595327 0.10694982 0.09179296],\n",
      "    |     Bias [0.1960416  0.19546078 0.19586485 0.19556644 0.19594951]\n",
      "Iterate 295: Cost 0.00484254051015534,   \n",
      "  |    Weight  [0.08966854 0.10659603 0.09593997 0.10697292 0.09176585],\n",
      "    |     Bias [0.19665585 0.19607314 0.19647856 0.19617916 0.19656348]\n",
      "Iterate 296: Cost 0.00484065631243794,   \n",
      "  |    Weight  [0.08963464 0.10661752 0.09592667 0.10699601 0.09173874],\n",
      "    |     Bias [0.19726998 0.19668538 0.19709216 0.19679176 0.19717733]\n",
      "Iterate 297: Cost 0.004838772869617421,   \n",
      "  |    Weight  [0.08960075 0.106639   0.09591338 0.1070191  0.09171164],\n",
      "    |     Bias [0.19788398 0.1972975  0.19770563 0.19740424 0.19779106]\n",
      "Iterate 298: Cost 0.004836890181391326,   \n",
      "  |    Weight  [0.08956687 0.10666048 0.09590008 0.10704218 0.09168455],\n",
      "    |     Bias [0.19849786 0.1979095  0.19831897 0.19801659 0.19840466]\n",
      "Iterate 299: Cost 0.00483500824745731,   \n",
      "  |    Weight  [0.08953299 0.10668195 0.0958868  0.10706527 0.09165746],\n",
      "    |     Bias [0.19911162 0.19852137 0.1989322  0.19862882 0.19901814]\n",
      "Iterate 300: Cost 0.004833127067513156,   \n",
      "  |    Weight  [0.08949912 0.10670342 0.09587351 0.10708834 0.09163038],\n",
      "    |     Bias [0.19972525 0.19913312 0.1995453  0.19924093 0.1996315 ]\n",
      "Iterate 301: Cost 0.004831246641256764,   \n",
      "  |    Weight  [0.08946526 0.10672488 0.09586023 0.10711142 0.0916033 ],\n",
      "    |     Bias [0.20033877 0.19974474 0.20015828 0.19985292 0.20024473]\n",
      "Iterate 302: Cost 0.004829366968386157,   \n",
      "  |    Weight  [0.0894314  0.10674633 0.09584695 0.10713449 0.09157622],\n",
      "    |     Bias [0.20095215 0.20035625 0.20077114 0.20046478 0.20085785]\n",
      "Iterate 303: Cost 0.004827488048599478,   \n",
      "  |    Weight  [0.08939755 0.10676778 0.09583367 0.10715756 0.09154916],\n",
      "    |     Bias [0.20156542 0.20096763 0.20138387 0.20107652 0.20147083]\n",
      "Iterate 304: Cost 0.004825609881594994,   \n",
      "  |    Weight  [0.08936371 0.10678923 0.0958204  0.10718062 0.09152209],\n",
      "    |     Bias [0.20217856 0.20157889 0.20199648 0.20168814 0.2020837 ]\n",
      "Iterate 305: Cost 0.004823732467071088,   \n",
      "  |    Weight  [0.08932988 0.10681067 0.09580713 0.10720368 0.09149504],\n",
      "    |     Bias [0.20279158 0.20219003 0.20260897 0.20229964 0.20269644]\n",
      "Iterate 306: Cost 0.0048218558047262655,   \n",
      "  |    Weight  [0.08929606 0.1068321  0.09579386 0.10722674 0.09146798],\n",
      "    |     Bias [0.20340448 0.20280104 0.20322134 0.20291101 0.20330907]\n",
      "Iterate 307: Cost 0.004819979894259157,   \n",
      "  |    Weight  [0.08926224 0.10685352 0.0957806  0.10724979 0.09144094],\n",
      "    |     Bias [0.20401725 0.20341193 0.20383358 0.20352226 0.20392156]\n",
      "Iterate 308: Cost 0.0048181047353685075,   \n",
      "  |    Weight  [0.08922843 0.10687495 0.09576733 0.10727284 0.0914139 ],\n",
      "    |     Bias [0.2046299  0.2040227  0.2044457  0.20413339 0.20453394]\n",
      "Iterate 309: Cost 0.004816230327753186,   \n",
      "  |    Weight  [0.08919462 0.10689636 0.09575408 0.10729589 0.09138686],\n",
      "    |     Bias [0.20524243 0.20463335 0.2050577  0.2047444  0.20514619]\n",
      "Iterate 310: Cost 0.004814356671112182,   \n",
      "  |    Weight  [0.08916083 0.10691777 0.09574082 0.10731893 0.09135983],\n",
      "    |     Bias [0.20585483 0.20524387 0.20566958 0.20535528 0.20575832]\n",
      "Iterate 311: Cost 0.004812483765144606,   \n",
      "  |    Weight  [0.08912704 0.10693917 0.09572757 0.10734197 0.0913328 ],\n",
      "    |     Bias [0.20646711 0.20585428 0.20628133 0.20596605 0.20637033]\n",
      "Iterate 312: Cost 0.004810611609549688,   \n",
      "  |    Weight  [0.08909326 0.10696057 0.09571432 0.107365   0.09130578],\n",
      "    |     Bias [0.20707927 0.20646456 0.20689296 0.20657669 0.20698221]\n",
      "Iterate 313: Cost 0.004808740204026779,   \n",
      "  |    Weight  [0.08905948 0.10698196 0.09570107 0.10738804 0.09127877],\n",
      "    |     Bias [0.20769131 0.20707472 0.20750447 0.2071872  0.20759397]\n",
      "Iterate 314: Cost 0.004806869548275348,   \n",
      "  |    Weight  [0.08902572 0.10700335 0.09568783 0.10741106 0.09125176],\n",
      "    |     Bias [0.20830322 0.20768475 0.20811586 0.2077976  0.20820561]\n",
      "Iterate 315: Cost 0.004804999641994988,   \n",
      "  |    Weight  [0.08899196 0.10702473 0.09567459 0.10743409 0.09122476],\n",
      "    |     Bias [0.20891501 0.20829467 0.20872713 0.20840787 0.20881713]\n",
      "Iterate 316: Cost 0.004803130484885414,   \n",
      "  |    Weight  [0.08895821 0.10704611 0.09566135 0.10745711 0.09119776],\n",
      "    |     Bias [0.20952668 0.20890446 0.20933827 0.20901802 0.20942853]\n",
      "Iterate 317: Cost 0.004801262076646455,   \n",
      "  |    Weight  [0.08892446 0.10706747 0.09564812 0.10748013 0.09117076],\n",
      "    |     Bias [0.21013823 0.20951413 0.20994929 0.20962805 0.2100398 ]\n",
      "Iterate 318: Cost 0.004799394416978066,   \n",
      "  |    Weight  [0.08889073 0.10708884 0.09563489 0.10750314 0.09114378],\n",
      "    |     Bias [0.21074965 0.21012367 0.21056019 0.21023796 0.21065095]\n",
      "Iterate 319: Cost 0.0047975275055803165,   \n",
      "  |    Weight  [0.088857   0.1071102  0.09562166 0.10752615 0.09111679],\n",
      "    |     Bias [0.21136095 0.2107331  0.21117096 0.21084774 0.21126197]\n",
      "Iterate 320: Cost 0.0047956613421534025,   \n",
      "  |    Weight  [0.08882328 0.10713155 0.09560844 0.10754916 0.09108982],\n",
      "    |     Bias [0.21197212 0.2113424  0.21178161 0.21145741 0.21187288]\n",
      "Iterate 321: Cost 0.0047937959263976366,   \n",
      "  |    Weight  [0.08878956 0.10715289 0.09559522 0.10757216 0.09106284],\n",
      "    |     Bias [0.21258318 0.21195158 0.21239214 0.21206695 0.21248366]\n",
      "Iterate 322: Cost 0.004791931258013451,   \n",
      "  |    Weight  [0.08875585 0.10717423 0.095582   0.10759516 0.09103588],\n",
      "    |     Bias [0.21319411 0.21256064 0.21300255 0.21267636 0.21309432]\n",
      "Iterate 323: Cost 0.004790067336701401,   \n",
      "  |    Weight  [0.08872215 0.10719557 0.09556878 0.10761815 0.09100892],\n",
      "    |     Bias [0.21380492 0.21316958 0.21361284 0.21328566 0.21370486]\n",
      "Iterate 324: Cost 0.004788204162162157,   \n",
      "  |    Weight  [0.08868846 0.1072169  0.09555557 0.10764115 0.09098196],\n",
      "    |     Bias [0.21441561 0.2137784  0.214223   0.21389484 0.21431527]\n",
      "Iterate 325: Cost 0.004786341734096515,   \n",
      "  |    Weight  [0.08865478 0.10723822 0.09554236 0.10766413 0.09095501],\n",
      "    |     Bias [0.21502617 0.21438709 0.21483305 0.21450389 0.21492557]\n",
      "Iterate 326: Cost 0.004784480052205387,   \n",
      "  |    Weight  [0.0886211  0.10725954 0.09552916 0.10768712 0.09092806],\n",
      "    |     Bias [0.21563661 0.21499566 0.21544297 0.21511282 0.21553574]\n",
      "Iterate 327: Cost 0.004782619116189807,   \n",
      "  |    Weight  [0.08858743 0.10728085 0.09551595 0.1077101  0.09090112],\n",
      "    |     Bias [0.21624693 0.21560411 0.21605277 0.21572163 0.21614578]\n",
      "Iterate 328: Cost 0.004780758925750924,   \n",
      "  |    Weight  [0.08855377 0.10730216 0.09550275 0.10773308 0.09087419],\n",
      "    |     Bias [0.21685713 0.21621244 0.21666244 0.21633031 0.21675571]\n",
      "Iterate 329: Cost 0.0047788994805900145,   \n",
      "  |    Weight  [0.08852011 0.10732346 0.09548956 0.10775605 0.09084726],\n",
      "    |     Bias [0.2174672  0.21682064 0.217272   0.21693888 0.21736551]\n",
      "Iterate 330: Cost 0.004777040780408468,   \n",
      "  |    Weight  [0.08848646 0.10734475 0.09547636 0.10777902 0.09082034],\n",
      "    |     Bias [0.21807715 0.21742873 0.21788143 0.21754732 0.2179752 ]\n",
      "Iterate 331: Cost 0.0047751828249077985,   \n",
      "  |    Weight  [0.08845282 0.10736604 0.09546317 0.10780199 0.09079342],\n",
      "    |     Bias [0.21868698 0.21803669 0.21849074 0.21815564 0.21858476]\n",
      "Iterate 332: Cost 0.004773325613789636,   \n",
      "  |    Weight  [0.08841919 0.10738732 0.09544998 0.10782495 0.0907665 ],\n",
      "    |     Bias [0.21929669 0.21864453 0.21909993 0.21876384 0.21919419]\n",
      "Iterate 333: Cost 0.004771469146755731,   \n",
      "  |    Weight  [0.08838556 0.1074086  0.0954368  0.10784791 0.09073959],\n",
      "    |     Bias [0.21990627 0.21925225 0.21970899 0.21937192 0.21980351]\n",
      "Iterate 334: Cost 0.004769613423507955,   \n",
      "  |    Weight  [0.08835194 0.10742987 0.09542362 0.10787087 0.09071269],\n",
      "    |     Bias [0.22051574 0.21985984 0.22031794 0.21997988 0.2204127 ]\n",
      "Iterate 335: Cost 0.004767758443748297,   \n",
      "  |    Weight  [0.08831833 0.10745114 0.09541044 0.10789382 0.09068579],\n",
      "    |     Bias [0.22112508 0.22046732 0.22092676 0.22058771 0.22102177]\n",
      "Iterate 336: Cost 0.0047659042071788674,   \n",
      "  |    Weight  [0.08828473 0.1074724  0.09539726 0.10791677 0.0906589 ],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |     Bias [0.2217343  0.22107467 0.22153546 0.22119542 0.22163072]\n",
      "Iterate 337: Cost 0.004764050713501894,   \n",
      "  |    Weight  [0.08825113 0.10749366 0.09538409 0.10793972 0.09063201],\n",
      "    |     Bias [0.22234339 0.2216819  0.22214404 0.22180301 0.22223955]\n",
      "Iterate 338: Cost 0.004762197962419725,   \n",
      "  |    Weight  [0.08821754 0.1075149  0.09537092 0.10796266 0.09060513],\n",
      "    |     Bias [0.22295236 0.22228901 0.2227525  0.22241048 0.22284825]\n",
      "Iterate 339: Cost 0.0047603459536348265,   \n",
      "  |    Weight  [0.08818396 0.10753615 0.09535776 0.1079856  0.09057826],\n",
      "    |     Bias [0.22356122 0.222896   0.22336083 0.22301783 0.22345684]\n",
      "Iterate 340: Cost 0.0047584946868497865,   \n",
      "  |    Weight  [0.08815039 0.10755739 0.09534459 0.10800853 0.09055138],\n",
      "    |     Bias [0.22416994 0.22350287 0.22396905 0.22362506 0.2240653 ]\n",
      "Iterate 341: Cost 0.00475664416176731,   \n",
      "  |    Weight  [0.08811682 0.10757862 0.09533143 0.10803146 0.09052452],\n",
      "    |     Bias [0.22477855 0.22410961 0.22457714 0.22423216 0.22467364]\n",
      "Iterate 342: Cost 0.004754794378090219,   \n",
      "  |    Weight  [0.08808326 0.10759984 0.09531828 0.10805439 0.09049766],\n",
      "    |     Bias [0.22538704 0.22471624 0.22518511 0.22483914 0.22528186]\n",
      "Iterate 343: Cost 0.004752945335521464,   \n",
      "  |    Weight  [0.08804971 0.10762106 0.09530512 0.10807732 0.0904708 ],\n",
      "    |     Bias [0.2259954  0.22532274 0.22579296 0.225446   0.22588995]\n",
      "Iterate 344: Cost 0.0047510970337641,   \n",
      "  |    Weight  [0.08801617 0.10764228 0.09529197 0.10810024 0.09044395],\n",
      "    |     Bias [0.22660364 0.22592912 0.22640069 0.22605274 0.22649792]\n",
      "Iterate 345: Cost 0.004749249472521313,   \n",
      "  |    Weight  [0.08798263 0.10766349 0.09527882 0.10812315 0.09041711],\n",
      "    |     Bias [0.22721176 0.22653538 0.22700829 0.22665936 0.22710578]\n",
      "Iterate 346: Cost 0.004747402651496405,   \n",
      "  |    Weight  [0.0879491  0.10768469 0.09526568 0.10814607 0.09039027],\n",
      "    |     Bias [0.22781975 0.22714152 0.22761578 0.22726586 0.22771351]\n",
      "Iterate 347: Cost 0.004745556570392793,   \n",
      "  |    Weight  [0.08791558 0.10770589 0.09525254 0.10816898 0.09036343],\n",
      "    |     Bias [0.22842763 0.22774753 0.22822314 0.22787223 0.22832111]\n",
      "Iterate 348: Cost 0.004743711228914015,   \n",
      "  |    Weight  [0.08788206 0.10772708 0.0952394  0.10819188 0.09033661],\n",
      "    |     Bias [0.22903538 0.22835343 0.22883038 0.22847849 0.2289286 ]\n",
      "Iterate 349: Cost 0.004741866626763728,   \n",
      "  |    Weight  [0.08784855 0.10774827 0.09522626 0.10821478 0.09030978],\n",
      "    |     Bias [0.22964301 0.2289592  0.2294375  0.22908462 0.22953597]\n",
      "Iterate 350: Cost 0.00474002276364571,   \n",
      "  |    Weight  [0.08781505 0.10776945 0.09521313 0.10823768 0.09028296],\n",
      "    |     Bias [0.23025052 0.22956485 0.2300445  0.22969063 0.23014321]\n",
      "Iterate 351: Cost 0.004738179639263854,   \n",
      "  |    Weight  [0.08778156 0.10779062 0.0952     0.10826058 0.09025615],\n",
      "    |     Bias [0.23085791 0.23017038 0.23065137 0.23029652 0.23075033]\n",
      "Iterate 352: Cost 0.004736337253322174,   \n",
      "  |    Weight  [0.08774807 0.10781179 0.09518687 0.10828347 0.09022934],\n",
      "    |     Bias [0.23146517 0.23077579 0.23125813 0.23090229 0.23135733]\n",
      "Iterate 353: Cost 0.004734495605524801,   \n",
      "  |    Weight  [0.08771459 0.10783295 0.09517375 0.10830636 0.09020254],\n",
      "    |     Bias [0.23207232 0.23138108 0.23186476 0.23150794 0.23196421]\n",
      "Iterate 354: Cost 0.004732654695575988,   \n",
      "  |    Weight  [0.08768112 0.10785411 0.09516063 0.10832924 0.09017574],\n",
      "    |     Bias [0.23267934 0.23198625 0.23247127 0.23211346 0.23257097]\n",
      "Iterate 355: Cost 0.004730814523180101,   \n",
      "  |    Weight  [0.08764766 0.10787526 0.09514751 0.10835213 0.09014895],\n",
      "    |     Bias [0.23328624 0.2325913  0.23307767 0.23271887 0.2331776 ]\n",
      "Iterate 356: Cost 0.004728975088041628,   \n",
      "  |    Weight  [0.0876142  0.10789641 0.0951344  0.108375   0.09012217],\n",
      "    |     Bias [0.23389302 0.23319622 0.23368393 0.23332415 0.23378411]\n",
      "Iterate 357: Cost 0.004727136389865174,   \n",
      "  |    Weight  [0.08758075 0.10791755 0.09512128 0.10839788 0.09009538],\n",
      "    |     Bias [0.23449967 0.23380102 0.23429008 0.23392932 0.23439051]\n",
      "Iterate 358: Cost 0.004725298428355463,   \n",
      "  |    Weight  [0.08754731 0.10793869 0.09510818 0.10842075 0.09006861],\n",
      "    |     Bias [0.23510621 0.23440571 0.23489611 0.23453436 0.23499678]\n",
      "Iterate 359: Cost 0.004723461203217338,   \n",
      "  |    Weight  [0.08751388 0.10795982 0.09509507 0.10844361 0.09004184],\n",
      "    |     Bias [0.23571262 0.23501027 0.23550202 0.23513928 0.23560293]\n",
      "Iterate 360: Cost 0.004721624714155761,   \n",
      "  |    Weight  [0.08748045 0.10798094 0.09508197 0.10846648 0.09001507],\n",
      "    |     Bias [0.23631891 0.23561471 0.2361078  0.23574408 0.23620895]\n",
      "Iterate 361: Cost 0.00471978896087581,   \n",
      "  |    Weight  [0.08744703 0.10800206 0.09506887 0.10848934 0.08998831],\n",
      "    |     Bias [0.23692508 0.23621903 0.23671346 0.23634875 0.23681486]\n",
      "Iterate 362: Cost 0.004717953943082682,   \n",
      "  |    Weight  [0.08741362 0.10802317 0.09505577 0.10851219 0.08996156],\n",
      "    |     Bias [0.23753113 0.23682322 0.237319   0.23695331 0.23742065]\n",
      "Iterate 363: Cost 0.0047161196604816906,   \n",
      "  |    Weight  [0.08738021 0.10804428 0.09504268 0.10853505 0.08993481],\n",
      "    |     Bias [0.23813705 0.2374273  0.23792443 0.23755775 0.23802631]\n",
      "Iterate 364: Cost 0.00471428611277827,   \n",
      "  |    Weight  [0.08734681 0.10806538 0.09502959 0.1085579  0.08990806],\n",
      "    |     Bias [0.23874286 0.23803126 0.23852973 0.23816206 0.23863185]\n",
      "Iterate 365: Cost 0.004712453299677973,   \n",
      "  |    Weight  [0.08731342 0.10808647 0.0950165  0.10858074 0.08988132],\n",
      "    |     Bias [0.23934854 0.23863509 0.2391349  0.23876626 0.23923727]\n",
      "Iterate 366: Cost 0.004710621220886466,   \n",
      "  |    Weight  [0.08728004 0.10810756 0.09500342 0.10860358 0.08985459],\n",
      "    |     Bias [0.2399541  0.23923881 0.23973996 0.23937033 0.23984257]\n",
      "Iterate 367: Cost 0.00470878987610954,   \n",
      "  |    Weight  [0.08724666 0.10812865 0.09499034 0.10862642 0.08982786],\n",
      "    |     Bias [0.24055954 0.2398424  0.2403449  0.23997428 0.24044775]\n",
      "Iterate 368: Cost 0.004706959265053094,   \n",
      "  |    Weight  [0.08721329 0.10814972 0.09497726 0.10864926 0.08980114],\n",
      "    |     Bias [0.24116486 0.24044587 0.24094971 0.24057811 0.24105281]\n",
      "Iterate 369: Cost 0.004705129387423157,   \n",
      "  |    Weight  [0.08717993 0.1081708  0.09496418 0.10867209 0.08977442],\n",
      "    |     Bias [0.24177006 0.24104922 0.24155441 0.24118182 0.24165774]\n",
      "Iterate 370: Cost 0.004703300242925866,   \n",
      "  |    Weight  [0.08714658 0.10819186 0.09495111 0.10869492 0.08974771],\n",
      "    |     Bias [0.24237513 0.24165245 0.24215898 0.24178541 0.24226256]\n",
      "Iterate 371: Cost 0.00470147183126748,   \n",
      "  |    Weight  [0.08711323 0.10821293 0.09493804 0.10871774 0.089721  ],\n",
      "    |     Bias [0.24298009 0.24225556 0.24276343 0.24238888 0.24286725]\n",
      "Iterate 372: Cost 0.004699644152154375,   \n",
      "  |    Weight  [0.08707989 0.10823398 0.09492498 0.10874056 0.0896943 ],\n",
      "    |     Bias [0.24358492 0.24285855 0.24336776 0.24299223 0.24347182]\n",
      "Iterate 373: Cost 0.004697817205293046,   \n",
      "  |    Weight  [0.08704656 0.10825503 0.09491191 0.10876338 0.0896676 ],\n",
      "    |     Bias [0.24418963 0.24346142 0.24397197 0.24359546 0.24407627]\n",
      "Iterate 374: Cost 0.004695990990390104,   \n",
      "  |    Weight  [0.08701324 0.10827607 0.09489885 0.10878619 0.08964091],\n",
      "    |     Bias [0.24479422 0.24406417 0.24457606 0.24419856 0.2446806 ]\n",
      "Iterate 375: Cost 0.004694165507152277,   \n",
      "  |    Weight  [0.08697992 0.10829711 0.0948858  0.108809   0.08961422],\n",
      "    |     Bias [0.24539869 0.24466679 0.24518003 0.24480155 0.24528481]\n",
      "Iterate 376: Cost 0.004692340755286411,   \n",
      "  |    Weight  [0.08694661 0.10831815 0.09487274 0.10883181 0.08958754],\n",
      "    |     Bias [0.24600304 0.2452693  0.24578388 0.24540441 0.2458889 ]\n",
      "Iterate 377: Cost 0.004690516734499471,   \n",
      "  |    Weight  [0.08691331 0.10833917 0.09485969 0.10885461 0.08956087],\n",
      "    |     Bias [0.24660726 0.24587168 0.24638761 0.24600716 0.24649287]\n",
      "Iterate 378: Cost 0.004688693444498537,   \n",
      "  |    Weight  [0.08688001 0.10836019 0.09484664 0.10887741 0.0895342 ],\n",
      "    |     Bias [0.24721137 0.24647395 0.24699121 0.24660978 0.24709671]\n",
      "Iterate 379: Cost 0.004686870884990808,   \n",
      "  |    Weight  [0.08684672 0.10838121 0.0948336  0.10890021 0.08950753],\n",
      "    |     Bias [0.24781535 0.24707609 0.2475947  0.24721228 0.24770044]\n",
      "Iterate 380: Cost 0.004685049055683602,   \n",
      "  |    Weight  [0.08681344 0.10840222 0.09482056 0.108923   0.08948087],\n",
      "    |     Bias [0.24841922 0.24767811 0.24819806 0.24781466 0.24830404]\n",
      "Iterate 381: Cost 0.004683227956284349,   \n",
      "  |    Weight  [0.08678017 0.10842323 0.09480752 0.10894579 0.08945422],\n",
      "    |     Bias [0.24902296 0.24828002 0.24880131 0.24841693 0.24890752]\n",
      "Iterate 382: Cost 0.004681407586500601,   \n",
      "  |    Weight  [0.0867469  0.10844422 0.09479448 0.10896857 0.08942757],\n",
      "    |     Bias [0.24962658 0.2488818  0.24940443 0.24901907 0.24951089]\n",
      "Iterate 383: Cost 0.0046795879460400265,   \n",
      "  |    Weight  [0.08671364 0.10846522 0.09478145 0.10899136 0.08940092],\n",
      "    |     Bias [0.25023008 0.24948346 0.25000743 0.24962109 0.25011413]\n",
      "Iterate 384: Cost 0.004677769034610409,   \n",
      "  |    Weight  [0.08668039 0.10848621 0.09476842 0.10901413 0.08937428],\n",
      "    |     Bias [0.25083346 0.250085   0.25061031 0.25022299 0.25071725]\n",
      "Iterate 385: Cost 0.0046759508519196484,   \n",
      "  |    Weight  [0.08664715 0.10850719 0.0947554  0.10903691 0.08934765],\n",
      "    |     Bias [0.25143671 0.25068642 0.25121307 0.25082477 0.25132025]\n",
      "Iterate 386: Cost 0.004674133397675766,   \n",
      "  |    Weight  [0.08661391 0.10852816 0.09474237 0.10905968 0.08932102],\n",
      "    |     Bias [0.25203985 0.25128772 0.25181572 0.25142643 0.25192312]\n",
      "Iterate 387: Cost 0.004672316671586898,   \n",
      "  |    Weight  [0.08658068 0.10854913 0.09472935 0.10908245 0.0892944 ],\n",
      "    |     Bias [0.25264286 0.2518889  0.25241824 0.25202796 0.25252588]\n",
      "Iterate 388: Cost 0.004670500673361296,   \n",
      "  |    Weight  [0.08654746 0.1085701  0.09471633 0.10910521 0.08926778],\n",
      "    |     Bias [0.25324576 0.25248996 0.25302063 0.25262938 0.25312852]\n",
      "Iterate 389: Cost 0.004668685402707329,   \n",
      "  |    Weight  [0.08651424 0.10859106 0.09470332 0.10912797 0.08924117],\n",
      "    |     Bias [0.25384853 0.2530909  0.25362291 0.25323068 0.25373104]\n",
      "Iterate 390: Cost 0.0046668708593334855,   \n",
      "  |    Weight  [0.08648104 0.10861201 0.09469031 0.10915073 0.08921456],\n",
      "    |     Bias [0.25445118 0.25369172 0.25422507 0.25383186 0.25433343]\n",
      "Iterate 391: Cost 0.004665057042948367,   \n",
      "  |    Weight  [0.08644784 0.10863296 0.0946773  0.10917348 0.08918796],\n",
      "    |     Bias [0.25505372 0.25429241 0.25482711 0.25443291 0.25493571]\n",
      "Iterate 392: Cost 0.0046632439532606935,   \n",
      "  |    Weight  [0.08641464 0.1086539  0.09466429 0.10919623 0.08916136],\n",
      "    |     Bias [0.25565613 0.25489299 0.25542903 0.25503385 0.25553786]\n",
      "Iterate 393: Cost 0.004661431589979304,   \n",
      "  |    Weight  [0.08638146 0.10867484 0.09465129 0.10921898 0.08913477],\n",
      "    |     Bias [0.25625841 0.25549345 0.25603082 0.25563467 0.25613989]\n",
      "Iterate 394: Cost 0.004659619952813148,   \n",
      "  |    Weight  [0.08634828 0.10869577 0.09463829 0.10924172 0.08910818],\n",
      "    |     Bias [0.25686058 0.25609379 0.2566325  0.25623536 0.25674181]\n",
      "Iterate 395: Cost 0.0046578090414713,   \n",
      "  |    Weight  [0.08631511 0.1087167  0.0946253  0.10926446 0.0890816 ],\n",
      "    |     Bias [0.25746263 0.256694   0.25723406 0.25683594 0.2573436 ]\n",
      "Iterate 396: Cost 0.004655998855662944,   \n",
      "  |    Weight  [0.08628194 0.10873762 0.0946123  0.1092872  0.08905502],\n",
      "    |     Bias [0.25806456 0.2572941  0.25783549 0.25743639 0.25794527]\n",
      "Iterate 397: Cost 0.004654189395097382,   \n",
      "  |    Weight  [0.08624879 0.10875853 0.09459931 0.10930993 0.08902845],\n",
      "    |     Bias [0.25866636 0.25789408 0.25843681 0.25803673 0.25854682]\n",
      "Iterate 398: Cost 0.004652380659484038,   \n",
      "  |    Weight  [0.08621564 0.10877944 0.09458632 0.10933266 0.08900189],\n",
      "    |     Bias [0.25926805 0.25849393 0.259038   0.25863694 0.25914825]\n",
      "Iterate 399: Cost 0.0046505726485324425,   \n",
      "  |    Weight  [0.08618249 0.10880034 0.09457334 0.10935538 0.08897533],\n",
      "    |     Bias [0.25986962 0.25909367 0.25963908 0.25923704 0.25974956]\n",
      "Iterate 400: Cost 0.004648765361952252,   \n",
      "  |    Weight  [0.08614936 0.10882124 0.09456036 0.1093781  0.08894877],\n",
      "    |     Bias [0.26047106 0.25969328 0.26024003 0.25983701 0.26035075]\n"
     ]
    }
   ],
   "source": [
    "equation1 =  gradient_descent(x, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterate 1: Cost 0.0032382469464377404,   \n",
      "  |    Weight  [0.09996704 0.10001418 0.09998378 0.10001692 0.09998806],\n",
      "    |     Bias [0.01049941 0.01049735 0.01049874 0.01049771 0.01049906]\n",
      "Iterate 2: Cost 0.003237002806806069,   \n",
      "  |    Weight  [0.09993409 0.10002835 0.09996757 0.10003383 0.09997613],\n",
      "    |     Bias [0.01099872 0.0109946  0.01099738 0.01099531 0.01099803]\n",
      "Iterate 3: Cost 0.003235759165580374,   \n",
      "  |    Weight  [0.09990114 0.10004252 0.09995136 0.10005074 0.0999642 ],\n",
      "    |     Bias [0.01149794 0.01149174 0.01149593 0.01149282 0.01149689]\n",
      "Iterate 4: Cost 0.003234516022560961,   \n",
      "  |    Weight  [0.0998682  0.10005668 0.09993515 0.10006765 0.09995227],\n",
      "    |     Bias [0.01199705 0.01198879 0.01199437 0.01199023 0.01199565]\n",
      "Iterate 5: Cost 0.0032332733775482154,   \n",
      "  |    Weight  [0.09983527 0.10007084 0.09991894 0.10008455 0.09994035],\n",
      "    |     Bias [0.01249606 0.01248574 0.01249271 0.01248754 0.01249431]\n",
      "Iterate 6: Cost 0.003232031230342605,   \n",
      "  |    Weight  [0.09980234 0.10008499 0.09990274 0.10010145 0.09992843],\n",
      "    |     Bias [0.01299497 0.01298259 0.01299096 0.01298474 0.01299288]\n",
      "Iterate 7: Cost 0.003230789580744675,   \n",
      "  |    Weight  [0.09976942 0.10009914 0.09988654 0.10011835 0.09991652],\n",
      "    |     Bias [0.01349378 0.01347934 0.0134891  0.01348185 0.01349134]\n",
      "Iterate 8: Cost 0.003229548428555052,   \n",
      "  |    Weight  [0.0997365  0.10011329 0.09987034 0.10013525 0.09990461],\n",
      "    |     Bias [0.01399249 0.01397599 0.01398714 0.01397886 0.0139897 ]\n",
      "Iterate 9: Cost 0.003228307773574444,   \n",
      "  |    Weight  [0.09970359 0.10012743 0.09985414 0.10015214 0.09989271],\n",
      "    |     Bias [0.0144911  0.01447254 0.01448509 0.01447577 0.01448797]\n",
      "Iterate 10: Cost 0.0032270676156036355,   \n",
      "  |    Weight  [0.09967069 0.10014156 0.09983795 0.10016903 0.09988081],\n",
      "    |     Bias [0.01498961 0.01496899 0.01498293 0.01497258 0.01498613]\n",
      "Iterate 11: Cost 0.0032258279544434927,   \n",
      "  |    Weight  [0.09963779 0.10015569 0.09982176 0.10018592 0.09986891],\n",
      "    |     Bias [0.01548802 0.01546535 0.01548068 0.01546929 0.0154842 ]\n",
      "Iterate 12: Cost 0.0032245887898949607,   \n",
      "  |    Weight  [0.0996049  0.10016982 0.09980557 0.10020281 0.09985702],\n",
      "    |     Bias [0.01598633 0.0159616  0.01597832 0.0159659  0.01598216]\n",
      "Iterate 13: Cost 0.0032233501217590666,   \n",
      "  |    Weight  [0.09957201 0.10018394 0.09978938 0.10021969 0.09984513],\n",
      "    |     Bias [0.01648454 0.01645775 0.01647587 0.01646242 0.01648002]\n",
      "Iterate 14: Cost 0.003222111949836914,   \n",
      "  |    Weight  [0.09953913 0.10019806 0.0997732  0.10023657 0.09983325],\n",
      "    |     Bias [0.01698265 0.01695381 0.01697331 0.01695883 0.01697779]\n",
      "Iterate 15: Cost 0.003220874273929689,   \n",
      "  |    Weight  [0.09950626 0.10021217 0.09975702 0.10025344 0.09982137],\n",
      "    |     Bias [0.01748066 0.01744976 0.01747066 0.01745514 0.01747546]\n",
      "Iterate 16: Cost 0.003219637093838655,   \n",
      "  |    Weight  [0.09947339 0.10022628 0.09974084 0.10027031 0.09980949],\n",
      "    |     Bias [0.01797857 0.01794562 0.01796791 0.01795136 0.01797302]\n",
      "Iterate 17: Cost 0.003218400409365157,   \n",
      "  |    Weight  [0.09944053 0.10024038 0.09972466 0.10028718 0.09979762],\n",
      "    |     Bias [0.01847638 0.01844137 0.01846506 0.01844747 0.01847049]\n",
      "Iterate 18: Cost 0.003217164220310619,   \n",
      "  |    Weight  [0.09940767 0.10025448 0.09970849 0.10030405 0.09978576],\n",
      "    |     Bias [0.01897409 0.01893703 0.0189621  0.01894348 0.01896785]\n",
      "Iterate 19: Cost 0.003215928526476543,   \n",
      "  |    Weight  [0.09937482 0.10026857 0.09969232 0.10032091 0.09977389],\n",
      "    |     Bias [0.0194717  0.01943259 0.01945905 0.0194394  0.01946512]\n",
      "Iterate 20: Cost 0.003214693327664514,   \n",
      "  |    Weight  [0.09934198 0.10028266 0.09967615 0.10033778 0.09976204],\n",
      "    |     Bias [0.01996921 0.01992805 0.0199559  0.01993522 0.01996229]\n",
      "Iterate 21: Cost 0.003213458623676192,   \n",
      "  |    Weight  [0.09930914 0.10029675 0.09965998 0.10035463 0.09975018],\n",
      "    |     Bias [0.02046662 0.0204234  0.02045265 0.02043093 0.02045936]\n",
      "Iterate 22: Cost 0.0032122244143133203,   \n",
      "  |    Weight  [0.09927631 0.10031083 0.09964382 0.10037149 0.09973833],\n",
      "    |     Bias [0.02096393 0.02091866 0.0209493  0.02092655 0.02095633]\n",
      "Iterate 23: Cost 0.0032109906993777197,   \n",
      "  |    Weight  [0.09924349 0.1003249  0.09962766 0.10038834 0.09972649],\n",
      "    |     Bias [0.02146114 0.02141383 0.02144585 0.02142207 0.0214532 ]\n",
      "Iterate 24: Cost 0.0032097574786712907,   \n",
      "  |    Weight  [0.09921067 0.10033897 0.0996115  0.10040519 0.09971464],\n",
      "    |     Bias [0.02195825 0.02190889 0.0219423  0.02191749 0.02194996]\n",
      "Iterate 25: Cost 0.0032085247519960144,   \n",
      "  |    Weight  [0.09917786 0.10035304 0.09959534 0.10042204 0.09970281],\n",
      "    |     Bias [0.02245527 0.02240385 0.02243865 0.02241281 0.02244663]\n",
      "Iterate 26: Cost 0.003207292519153949,   \n",
      "  |    Weight  [0.09914505 0.1003671  0.09957919 0.10043888 0.09969097],\n",
      "    |     Bias [0.02295218 0.02289871 0.02293491 0.02290803 0.02294321]\n",
      "Iterate 27: Cost 0.0032060607799472333,   \n",
      "  |    Weight  [0.09911225 0.10038116 0.09956304 0.10045572 0.09967915],\n",
      "    |     Bias [0.02344899 0.02339348 0.02343106 0.02340316 0.02343968]\n",
      "Iterate 28: Cost 0.003204829534178085,   \n",
      "  |    Weight  [0.09907945 0.10039521 0.09954689 0.10047256 0.09966732],\n",
      "    |     Bias [0.0239457  0.02388814 0.02392711 0.02389818 0.02393605]\n",
      "Iterate 29: Cost 0.0032035987816488028,   \n",
      "  |    Weight  [0.09904667 0.10040926 0.09953075 0.1004894  0.0996555 ],\n",
      "    |     Bias [0.02444231 0.02438271 0.02442307 0.0243931  0.02443232]\n",
      "Iterate 30: Cost 0.003202368522161762,   \n",
      "  |    Weight  [0.09901388 0.1004233  0.0995146  0.10050623 0.09964368],\n",
      "    |     Bias [0.02493882 0.02487718 0.02491892 0.02488793 0.02492849]\n",
      "Iterate 31: Cost 0.003201138755519418,   \n",
      "  |    Weight  [0.09898111 0.10043734 0.09949846 0.10052306 0.09963187],\n",
      "    |     Bias [0.02543524 0.02537154 0.02541468 0.02538265 0.02542457]\n",
      "Iterate 32: Cost 0.003199909481524306,   \n",
      "  |    Weight  [0.09894834 0.10045137 0.09948232 0.10053989 0.09962006],\n",
      "    |     Bias [0.02593155 0.02586581 0.02591034 0.02587728 0.02592054]\n",
      "Iterate 33: Cost 0.00319868069997904,   \n",
      "  |    Weight  [0.09891557 0.1004654  0.09946619 0.10055671 0.09960826],\n",
      "    |     Bias [0.02642776 0.02635998 0.02640589 0.02637181 0.02641642]\n",
      "Iterate 34: Cost 0.003197452410686313,   \n",
      "  |    Weight  [0.09888281 0.10047943 0.09945005 0.10057353 0.09959646],\n",
      "    |     Bias [0.02692388 0.02685405 0.02690135 0.02686624 0.02691219]\n",
      "Iterate 35: Cost 0.0031962246134488964,   \n",
      "  |    Weight  [0.09885006 0.10049345 0.09943392 0.10059035 0.09958466],\n",
      "    |     Bias [0.02741989 0.02734803 0.02739671 0.02736057 0.02740787]\n",
      "Iterate 36: Cost 0.003194997308069642,   \n",
      "  |    Weight  [0.09881731 0.10050746 0.09941779 0.10060716 0.09957287],\n",
      "    |     Bias [0.02791581 0.0278419  0.02789197 0.0278548  0.02790345]\n",
      "Iterate 37: Cost 0.0031937704943514784,   \n",
      "  |    Weight  [0.09878457 0.10052147 0.09940167 0.10062397 0.09956109],\n",
      "    |     Bias [0.02841162 0.02833567 0.02838713 0.02834893 0.02839893]\n",
      "Iterate 38: Cost 0.0031925441720974173,   \n",
      "  |    Weight  [0.09875184 0.10053548 0.09938555 0.10064078 0.0995493 ],\n",
      "    |     Bias [0.02890734 0.02882935 0.02888219 0.02884296 0.02889431]\n",
      "Iterate 39: Cost 0.0031913183411105433,   \n",
      "  |    Weight  [0.09871911 0.10054948 0.09936942 0.10065759 0.09953752],\n",
      "    |     Bias [0.02940295 0.02932293 0.02937716 0.0293369  0.02938959]\n",
      "Iterate 40: Cost 0.0031900930011940264,   \n",
      "  |    Weight  [0.09868639 0.10056348 0.09935331 0.10067439 0.09952575],\n",
      "    |     Bias [0.02989847 0.0298164  0.02987202 0.02983073 0.02988477]\n",
      "Iterate 41: Cost 0.0031888681521511095,   \n",
      "  |    Weight  [0.09865367 0.10057747 0.09933719 0.10069119 0.09951398],\n",
      "    |     Bias [0.03039389 0.03030978 0.03036679 0.03032447 0.03037985]\n",
      "Iterate 42: Cost 0.0031876437937851197,   \n",
      "  |    Weight  [0.09862096 0.10059146 0.09932108 0.10070799 0.09950221],\n",
      "    |     Bias [0.0308892  0.03080306 0.03086145 0.03081811 0.03087483]\n",
      "Iterate 43: Cost 0.0031864199258994576,   \n",
      "  |    Weight  [0.09858826 0.10060544 0.09930497 0.10072479 0.09949045],\n",
      "    |     Bias [0.03138442 0.03129624 0.03135602 0.03131165 0.03136971]\n",
      "Iterate 44: Cost 0.0031851965482976074,   \n",
      "  |    Weight  [0.09855556 0.10061942 0.09928886 0.10074158 0.09947869],\n",
      "    |     Bias [0.03187954 0.03178933 0.03185049 0.03180509 0.0318645 ]\n",
      "Iterate 45: Cost 0.003183973660783129,   \n",
      "  |    Weight  [0.09852287 0.10063339 0.09927275 0.10075837 0.09946694],\n",
      "    |     Bias [0.03237456 0.03228231 0.03234485 0.03229843 0.03235918]\n",
      "Iterate 46: Cost 0.003182751263159662,   \n",
      "  |    Weight  [0.09849018 0.10064736 0.09925665 0.10077515 0.09945519],\n",
      "    |     Bias [0.03286948 0.0327752  0.03283912 0.03279167 0.03285377]\n",
      "Iterate 47: Cost 0.0031815293552309243,   \n",
      "  |    Weight  [0.0984575  0.10066132 0.09924055 0.10079194 0.09944345],\n",
      "    |     Bias [0.0333643  0.03326798 0.03333329 0.03328481 0.03334826]\n",
      "Iterate 48: Cost 0.0031803079368007145,   \n",
      "  |    Weight  [0.09842483 0.10067528 0.09922445 0.10080872 0.0994317 ],\n",
      "    |     Bias [0.03385902 0.03376067 0.03382737 0.03377786 0.03384265]\n",
      "Iterate 49: Cost 0.003179087007672905,   \n",
      "  |    Weight  [0.09839216 0.10068924 0.09920835 0.10082549 0.09941997],\n",
      "    |     Bias [0.03435364 0.03425326 0.03432134 0.0342708  0.03433694]\n",
      "Iterate 50: Cost 0.0031778665676514524,   \n",
      "  |    Weight  [0.0983595  0.10070319 0.09919226 0.10084227 0.09940823],\n",
      "    |     Bias [0.03484817 0.03474575 0.03481521 0.03476365 0.03483113]\n",
      "Iterate 51: Cost 0.003176646616540388,   \n",
      "  |    Weight  [0.09832685 0.10071714 0.09917617 0.10085904 0.09939651],\n",
      "    |     Bias [0.03534259 0.03523814 0.03530899 0.0352564  0.03532522]\n",
      "Iterate 52: Cost 0.0031754271541438246,   \n",
      "  |    Weight  [0.0982942  0.10073108 0.09916008 0.10087581 0.09938478],\n",
      "    |     Bias [0.03583691 0.03573043 0.03580266 0.03574905 0.03581921]\n",
      "Iterate 53: Cost 0.003174208180265949,   \n",
      "  |    Weight  [0.09826155 0.10074502 0.099144   0.10089258 0.09937306],\n",
      "    |     Bias [0.03633114 0.03622263 0.03629624 0.0362416  0.0363131 ]\n",
      "Iterate 54: Cost 0.0031729896947110315,   \n",
      "  |    Weight  [0.09822891 0.10075895 0.09912791 0.10090934 0.09936135],\n",
      "    |     Bias [0.03682526 0.03671473 0.03678972 0.03673406 0.0368069 ]\n",
      "Iterate 55: Cost 0.0031717716972834184,   \n",
      "  |    Weight  [0.09819628 0.10077288 0.09911183 0.1009261  0.09934963],\n",
      "    |     Bias [0.03731929 0.03720672 0.0372831  0.03722641 0.03730059]\n",
      "Iterate 56: Cost 0.0031705541877875337,   \n",
      "  |    Weight  [0.09816366 0.1007868  0.09909575 0.10094286 0.09933793],\n",
      "    |     Bias [0.03781322 0.03769862 0.03777638 0.03771867 0.03779419]\n",
      "Iterate 57: Cost 0.0031693371660278806,   \n",
      "  |    Weight  [0.09813104 0.10080072 0.09907968 0.10095961 0.09932622],\n",
      "    |     Bias [0.03830704 0.03819042 0.03826956 0.03821082 0.03828769]\n",
      "Iterate 58: Cost 0.0031681206318090417,   \n",
      "  |    Weight  [0.09809842 0.10081463 0.0990636  0.10097636 0.09931452],\n",
      "    |     Bias [0.03880077 0.03868212 0.03876265 0.03870288 0.03878109]\n",
      "Iterate 59: Cost 0.003166904584935675,   \n",
      "  |    Weight  [0.09806582 0.10082854 0.09904753 0.10099311 0.09930283],\n",
      "    |     Bias [0.0392944  0.03917373 0.03925563 0.03919484 0.03927439]\n",
      "Iterate 60: Cost 0.0031656890252125206,   \n",
      "  |    Weight  [0.09803322 0.10084245 0.09903146 0.10100986 0.09929114],\n",
      "    |     Bias [0.03978793 0.03966523 0.03974852 0.03968671 0.03976759]\n",
      "Iterate 61: Cost 0.0031644739524443934,   \n",
      "  |    Weight  [0.09800062 0.10085635 0.0990154  0.1010266  0.09927945],\n",
      "    |     Bias [0.04028136 0.04015664 0.04024131 0.04017847 0.04026069]\n",
      "Iterate 62: Cost 0.003163259366436189,   \n",
      "  |    Weight  [0.09796803 0.10087024 0.09899934 0.10104334 0.09926777],\n",
      "    |     Bias [0.0407747  0.04064795 0.040734   0.04067013 0.0407537 ]\n",
      "Iterate 63: Cost 0.0031620452669928797,   \n",
      "  |    Weight  [0.09793545 0.10088413 0.09898327 0.10106008 0.09925609],\n",
      "    |     Bias [0.04126793 0.04113916 0.04122659 0.0411617  0.0412466 ]\n",
      "Iterate 64: Cost 0.003160831653919517,   \n",
      "  |    Weight  [0.09790287 0.10089802 0.09896722 0.10107681 0.09924441],\n",
      "    |     Bias [0.04176107 0.04163027 0.04171908 0.04165317 0.04173941]\n",
      "Iterate 65: Cost 0.0031596185270212286,   \n",
      "  |    Weight  [0.0978703  0.1009119  0.09895116 0.10109354 0.09923274],\n",
      "    |     Bias [0.0422541  0.04212128 0.04221147 0.04214454 0.04223212]\n",
      "Iterate 66: Cost 0.003158405886103222,   \n",
      "  |    Weight  [0.09783773 0.10092578 0.09893511 0.10111027 0.09922108],\n",
      "    |     Bias [0.04274704 0.0426122  0.04270377 0.04263581 0.04272473]\n",
      "Iterate 67: Cost 0.0031571937309707826,   \n",
      "  |    Weight  [0.09780517 0.10093965 0.09891906 0.101127   0.09920941],\n",
      "    |     Bias [0.04323987 0.04310301 0.04319596 0.04312698 0.04321724]\n",
      "Iterate 68: Cost 0.0031559820614292743,   \n",
      "  |    Weight  [0.09777262 0.10095352 0.09890301 0.10114372 0.09919776],\n",
      "    |     Bias [0.04373261 0.04359373 0.04368806 0.04361806 0.04370965]\n",
      "Iterate 69: Cost 0.0031547708772841367,   \n",
      "  |    Weight  [0.09774007 0.10096738 0.09888696 0.10116044 0.0991861 ],\n",
      "    |     Bias [0.04422525 0.04408435 0.04418006 0.04410903 0.04420197]\n",
      "Iterate 70: Cost 0.00315356017834089,   \n",
      "  |    Weight  [0.09770753 0.10098124 0.09887092 0.10117716 0.09917445],\n",
      "    |     Bias [0.04471779 0.04457487 0.04467196 0.04459991 0.04469418]\n",
      "Iterate 71: Cost 0.00315234996440513,   \n",
      "  |    Weight  [0.097675   0.1009951  0.09885488 0.10119387 0.09916281],\n",
      "    |     Bias [0.04521023 0.0450653  0.04516376 0.04509069 0.0451863 ]\n",
      "Iterate 72: Cost 0.003151140235282533,   \n",
      "  |    Weight  [0.09764247 0.10100895 0.09883884 0.10121058 0.09915117],\n",
      "    |     Bias [0.04570258 0.04555562 0.04565547 0.04558137 0.04567832]\n",
      "Iterate 73: Cost 0.00314993099077885,   \n",
      "  |    Weight  [0.09760994 0.10102279 0.0988228  0.10122729 0.09913953],\n",
      "    |     Bias [0.04619482 0.04604585 0.04614707 0.04607196 0.04617024]\n",
      "Iterate 74: Cost 0.003148722230699914,   \n",
      "  |    Weight  [0.09757743 0.10103663 0.09880677 0.101244   0.0991279 ],\n",
      "    |     Bias [0.04668697 0.04653598 0.04663858 0.04656244 0.04666206]\n",
      "Iterate 75: Cost 0.0031475139548516316,   \n",
      "  |    Weight  [0.09754491 0.10105047 0.09879074 0.1012607  0.09911627],\n",
      "    |     Bias [0.04717901 0.04702601 0.04712999 0.04705283 0.04715378]\n",
      "Iterate 76: Cost 0.0031463061630399884,   \n",
      "  |    Weight  [0.09751241 0.1010643  0.09877471 0.1012774  0.09910464],\n",
      "    |     Bias [0.04767096 0.04751594 0.0476213  0.04754312 0.04764541]\n",
      "Iterate 77: Cost 0.00314509885507105,   \n",
      "  |    Weight  [0.09747991 0.10107813 0.09875868 0.1012941  0.09909302],\n",
      "    |     Bias [0.04816281 0.04800578 0.04811251 0.04803331 0.04813693]\n",
      "Iterate 78: Cost 0.0031438920307509575,   \n",
      "  |    Weight  [0.09744742 0.10109195 0.09874266 0.10131079 0.09908141],\n",
      "    |     Bias [0.04865456 0.04849551 0.04860362 0.0485234  0.04862836]\n",
      "Iterate 79: Cost 0.0031426856898859284,   \n",
      "  |    Weight  [0.09741493 0.10110577 0.09872664 0.10132748 0.09906979],\n",
      "    |     Bias [0.04914621 0.04898515 0.04909464 0.0490134  0.04911969]\n",
      "Iterate 80: Cost 0.0031414798322822617,   \n",
      "  |    Weight  [0.09738245 0.10111958 0.09871062 0.10134417 0.09905819],\n",
      "    |     Bias [0.04963776 0.04947469 0.04958556 0.04950329 0.04961092]\n",
      "Iterate 81: Cost 0.0031402744577463315,   \n",
      "  |    Weight  [0.09734997 0.10113339 0.09869461 0.10136086 0.09904658],\n",
      "    |     Bias [0.05012922 0.04996413 0.05007638 0.04999309 0.05010205]\n",
      "Iterate 82: Cost 0.0031390695660845885,   \n",
      "  |    Weight  [0.0973175  0.1011472  0.09867859 0.10137754 0.09903498],\n",
      "    |     Bias [0.05062057 0.05045348 0.0505671  0.05048279 0.05059309]\n",
      "Iterate 83: Cost 0.0031378651571035646,   \n",
      "  |    Weight  [0.09728504 0.101161   0.09866258 0.10139422 0.09902339],\n",
      "    |     Bias [0.05111183 0.05094272 0.05105772 0.05097239 0.05108402]\n",
      "Iterate 84: Cost 0.003136661230609865,   \n",
      "  |    Weight  [0.09725258 0.10117479 0.09864657 0.1014109  0.0990118 ],\n",
      "    |     Bias [0.05160299 0.05143187 0.05154824 0.0514619  0.05157486]\n",
      "Iterate 85: Cost 0.0031354577864101747,   \n",
      "  |    Weight  [0.09722013 0.10118858 0.09863057 0.10142757 0.09900021],\n",
      "    |     Bias [0.05209405 0.05192092 0.05203867 0.0519513  0.0520656 ]\n",
      "Iterate 86: Cost 0.0031342548243112564,   \n",
      "  |    Weight  [0.09718769 0.10120237 0.09861456 0.10144424 0.09898863],\n",
      "    |     Bias [0.05258501 0.05240988 0.052529   0.05244061 0.05255624]\n",
      "Iterate 87: Cost 0.0031330523441199494,   \n",
      "  |    Weight  [0.09715525 0.10121615 0.09859856 0.10146091 0.09897705],\n",
      "    |     Bias [0.05307587 0.05289873 0.05301923 0.05292982 0.05304679]\n",
      "Iterate 88: Cost 0.00313185034564317,   \n",
      "  |    Weight  [0.09712281 0.10122993 0.09858256 0.10147758 0.09896547],\n",
      "    |     Bias [0.05356663 0.05338749 0.05350936 0.05341893 0.05353723]\n",
      "Iterate 89: Cost 0.003130648828687913,   \n",
      "  |    Weight  [0.09709039 0.1012437  0.09856657 0.10149424 0.0989539 ],\n",
      "    |     Bias [0.0540573  0.05387615 0.05399939 0.05390795 0.05402758]\n",
      "Iterate 90: Cost 0.0031294477930612504,   \n",
      "  |    Weight  [0.09705796 0.10125747 0.09855057 0.1015109  0.09894233],\n",
      "    |     Bias [0.05454787 0.05436471 0.05448933 0.05439686 0.05451783]\n",
      "Iterate 91: Cost 0.0031282472385703304,   \n",
      "  |    Weight  [0.09702555 0.10127123 0.09853458 0.10152756 0.09893077],\n",
      "    |     Bias [0.05503833 0.05485317 0.05497916 0.05488568 0.05500798]\n",
      "Iterate 92: Cost 0.0031270471650223794,   \n",
      "  |    Weight  [0.09699314 0.10128499 0.09851859 0.10154421 0.09891921],\n",
      "    |     Bias [0.0555287  0.05534153 0.0554689  0.0553744  0.05549803]\n",
      "Iterate 93: Cost 0.0031258475722247005,   \n",
      "  |    Weight  [0.09696074 0.10129874 0.09850261 0.10156086 0.09890766],\n",
      "    |     Bias [0.05601897 0.0558298  0.05595854 0.05586303 0.05598798]\n",
      "Iterate 94: Cost 0.003124648459984675,   \n",
      "  |    Weight  [0.09692834 0.10131249 0.09848662 0.10157751 0.09889611],\n",
      "    |     Bias [0.05650915 0.05631797 0.05644809 0.05635155 0.05647784]\n",
      "Iterate 95: Cost 0.00312344982810976,   \n",
      "  |    Weight  [0.09689595 0.10132624 0.09847064 0.10159416 0.09888456],\n",
      "    |     Bias [0.05699922 0.05680604 0.05693753 0.05683998 0.0569676 ]\n",
      "Iterate 96: Cost 0.0031222516764074907,   \n",
      "  |    Weight  [0.09686356 0.10133998 0.09845466 0.1016108  0.09887302],\n",
      "    |     Bias [0.0574892  0.05729402 0.05742688 0.05732831 0.05745726]\n",
      "Iterate 97: Cost 0.003121054004685479,   \n",
      "  |    Weight  [0.09683118 0.10135371 0.09843869 0.10162744 0.09886148],\n",
      "    |     Bias [0.05797908 0.05778189 0.05791613 0.05781654 0.05794682]\n",
      "Iterate 98: Cost 0.003119856812751414,   \n",
      "  |    Weight  [0.09679881 0.10136744 0.09842271 0.10164407 0.09884995],\n",
      "    |     Bias [0.05846886 0.05826967 0.05840528 0.05830468 0.05843628]\n",
      "Iterate 99: Cost 0.0031186601004130625,   \n",
      "  |    Weight  [0.09676644 0.10138117 0.09840674 0.10166071 0.09883842],\n",
      "    |     Bias [0.05895854 0.05875735 0.05889433 0.05879271 0.05892565]\n",
      "Iterate 100: Cost 0.0031174638674782667,   \n",
      "  |    Weight  [0.09673408 0.10139489 0.09839077 0.10167734 0.09882689],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |     Bias [0.05944812 0.05924494 0.05938329 0.05928065 0.05941492]\n",
      "Iterate 101: Cost 0.0031162681137549483,   \n",
      "  |    Weight  [0.09670172 0.10140861 0.09837481 0.10169397 0.09881537],\n",
      "    |     Bias [0.0599376  0.05973242 0.05987215 0.05976849 0.05990409]\n",
      "Iterate 102: Cost 0.003115072839051102,   \n",
      "  |    Weight  [0.09666937 0.10142232 0.09835884 0.10171059 0.09880386],\n",
      "    |     Bias [0.06042699 0.06021981 0.06036091 0.06025623 0.06039316]\n",
      "Iterate 103: Cost 0.003113878043174805,   \n",
      "  |    Weight  [0.09663703 0.10143603 0.09834288 0.10172722 0.09879234],\n",
      "    |     Bias [0.06091628 0.0607071  0.06084957 0.06074388 0.06088213]\n",
      "Iterate 104: Cost 0.0031126837259342053,   \n",
      "  |    Weight  [0.09660469 0.10144974 0.09832692 0.10174384 0.09878083],\n",
      "    |     Bias [0.06140547 0.06119429 0.06133813 0.06123143 0.06137101]\n",
      "Iterate 105: Cost 0.003111489887137533,   \n",
      "  |    Weight  [0.09657236 0.10146344 0.09831096 0.10176045 0.09876933],\n",
      "    |     Bias [0.06189456 0.06168139 0.0618266  0.06171888 0.06185979]\n",
      "Iterate 106: Cost 0.003110296526593091,   \n",
      "  |    Weight  [0.09654003 0.10147713 0.09829501 0.10177707 0.09875783],\n",
      "    |     Bias [0.06238355 0.06216839 0.06231497 0.06220623 0.06234847]\n",
      "Iterate 107: Cost 0.003109103644109262,   \n",
      "  |    Weight  [0.09650771 0.10149082 0.09827906 0.10179368 0.09874633],\n",
      "    |     Bias [0.06287245 0.06265529 0.06280324 0.06269349 0.06283705]\n",
      "Iterate 108: Cost 0.003107911239494504,   \n",
      "  |    Weight  [0.0964754  0.10150451 0.09826311 0.10181029 0.09873484],\n",
      "    |     Bias [0.06336124 0.06314209 0.06329141 0.06318064 0.06332553]\n",
      "Iterate 109: Cost 0.0031067193125573515,   \n",
      "  |    Weight  [0.09644309 0.10151819 0.09824716 0.10182689 0.09872335],\n",
      "    |     Bias [0.06384994 0.0636288  0.06377949 0.06366771 0.06381392]\n",
      "Iterate 110: Cost 0.0031055278631064174,   \n",
      "  |    Weight  [0.09641079 0.10153186 0.09823122 0.1018435  0.09871187],\n",
      "    |     Bias [0.06433854 0.0641154  0.06426746 0.06415467 0.06430221]\n",
      "Iterate 111: Cost 0.0031043368909503895,   \n",
      "  |    Weight  [0.09637849 0.10154554 0.09821528 0.1018601  0.09870039],\n",
      "    |     Bias [0.06482705 0.06460191 0.06475534 0.06464153 0.0647904 ]\n",
      "Iterate 112: Cost 0.0031031463958980324,   \n",
      "  |    Weight  [0.0963462  0.1015592  0.09819934 0.10187669 0.09868891],\n",
      "    |     Bias [0.06531545 0.06508833 0.06524313 0.0651283  0.0652785 ]\n",
      "Iterate 113: Cost 0.003101956377758187,   \n",
      "  |    Weight  [0.09631392 0.10157287 0.0981834  0.10189329 0.09867744],\n",
      "    |     Bias [0.06580376 0.06557464 0.06573081 0.06561497 0.06576649]\n",
      "Iterate 114: Cost 0.003100766836339774,   \n",
      "  |    Weight  [0.09628164 0.10158653 0.09816747 0.10190988 0.09866597],\n",
      "    |     Bias [0.06629196 0.06606086 0.0662184  0.06610154 0.06625439]\n",
      "Iterate 115: Cost 0.003099577771451786,   \n",
      "  |    Weight  [0.09624937 0.10160018 0.09815154 0.10192647 0.09865451],\n",
      "    |     Bias [0.06678007 0.06654698 0.06670589 0.06658802 0.06674219]\n",
      "Iterate 116: Cost 0.0030983891829032962,   \n",
      "  |    Weight  [0.0962171  0.10161383 0.09813561 0.10194305 0.09864305],\n",
      "    |     Bias [0.06726809 0.06703301 0.06719328 0.0670744  0.06722989]\n",
      "Iterate 117: Cost 0.003097201070503451,   \n",
      "  |    Weight  [0.09618484 0.10162747 0.09811968 0.10195964 0.09863159],\n",
      "    |     Bias [0.067756   0.06751893 0.06768058 0.06756068 0.0677175 ]\n",
      "Iterate 118: Cost 0.003096013434061476,   \n",
      "  |    Weight  [0.09615259 0.10164111 0.09810375 0.10197622 0.09862014],\n",
      "    |     Bias [0.06824382 0.06800476 0.06816777 0.06804686 0.06820501]\n",
      "Iterate 119: Cost 0.0030948262733866702,   \n",
      "  |    Weight  [0.09612034 0.10165475 0.09808783 0.10199279 0.0986087 ],\n",
      "    |     Bias [0.06873154 0.06849049 0.06865487 0.06853295 0.06869242]\n",
      "Iterate 120: Cost 0.0030936395882884124,   \n",
      "  |    Weight  [0.0960881  0.10166838 0.09807191 0.10200937 0.09859725],\n",
      "    |     Bias [0.06921916 0.06897613 0.06914187 0.06901894 0.06917973]\n",
      "Iterate 121: Cost 0.0030924533785761554,   \n",
      "  |    Weight  [0.09605586 0.10168201 0.098056   0.10202594 0.09858581],\n",
      "    |     Bias [0.06970668 0.06946166 0.06962878 0.06950483 0.06966695]\n",
      "Iterate 122: Cost 0.0030912676440594295,   \n",
      "  |    Weight  [0.09602363 0.10169563 0.09804008 0.10204251 0.09857438],\n",
      "    |     Bias [0.0701941  0.0699471  0.07011558 0.06999062 0.07015406]\n",
      "Iterate 123: Cost 0.0030900823845478403,   \n",
      "  |    Weight  [0.09599141 0.10170925 0.09802417 0.10205907 0.09856295],\n",
      "    |     Bias [0.07068143 0.07043245 0.07060229 0.07047632 0.07064108]\n",
      "Iterate 124: Cost 0.0030888975998510705,   \n",
      "  |    Weight  [0.09595919 0.10172286 0.09800826 0.10207564 0.09855152],\n",
      "    |     Bias [0.07116866 0.07091769 0.07108891 0.07096192 0.07112801]\n",
      "Iterate 125: Cost 0.0030877132897788795,   \n",
      "  |    Weight  [0.09592697 0.10173647 0.09799235 0.1020922  0.0985401 ],\n",
      "    |     Bias [0.07165579 0.07140284 0.07157542 0.07144742 0.07161483]\n",
      "Iterate 126: Cost 0.0030865294541411016,   \n",
      "  |    Weight  [0.09589477 0.10175008 0.09797645 0.10210876 0.09852868],\n",
      "    |     Bias [0.07214283 0.07188789 0.07206184 0.07193283 0.07210156]\n",
      "Iterate 127: Cost 0.003085346092747648,   \n",
      "  |    Weight  [0.09586257 0.10176367 0.09796055 0.10212531 0.09851727],\n",
      "    |     Bias [0.07262976 0.07237284 0.07254816 0.07241814 0.07258819]\n",
      "Iterate 128: Cost 0.0030841632054085066,   \n",
      "  |    Weight  [0.09583037 0.10177727 0.09794465 0.10214186 0.09850586],\n",
      "    |     Bias [0.0731166  0.0728577  0.07303438 0.07290335 0.07307472]\n",
      "Iterate 129: Cost 0.00308298079193374,   \n",
      "  |    Weight  [0.09579818 0.10179086 0.09792875 0.10215841 0.09849445],\n",
      "    |     Bias [0.07360334 0.07334246 0.07352051 0.07338846 0.07356116]\n",
      "Iterate 130: Cost 0.0030817988521334885,   \n",
      "  |    Weight  [0.095766   0.10180445 0.09791285 0.10217496 0.09848305],\n",
      "    |     Bias [0.07408998 0.07382712 0.07400653 0.07387348 0.0740475 ]\n",
      "Iterate 131: Cost 0.0030806173858179678,   \n",
      "  |    Weight  [0.09573382 0.10181803 0.09789696 0.1021915  0.09847165],\n",
      "    |     Bias [0.07457653 0.07431169 0.07449246 0.0743584  0.07453374]\n",
      "Iterate 132: Cost 0.0030794363927974682,   \n",
      "  |    Weight  [0.09570165 0.10183161 0.09788107 0.10220804 0.09846026],\n",
      "    |     Bias [0.07506297 0.07479616 0.0749783  0.07484322 0.07501988]\n",
      "Iterate 133: Cost 0.003078255872882359,   \n",
      "  |    Weight  [0.09566949 0.10184518 0.09786518 0.10222458 0.09844887],\n",
      "    |     Bias [0.07554932 0.07528053 0.07546403 0.07532795 0.07550593]\n",
      "Iterate 134: Cost 0.0030770758258830836,   \n",
      "  |    Weight  [0.09563733 0.10185875 0.0978493  0.10224111 0.09843748],\n",
      "    |     Bias [0.07603557 0.0757648  0.07594967 0.07581257 0.07599187]\n",
      "Iterate 135: Cost 0.003075896251610162,   \n",
      "  |    Weight  [0.09560517 0.10187231 0.09783342 0.10225764 0.0984261 ],\n",
      "    |     Bias [0.07652173 0.07624898 0.07643521 0.07629711 0.07647773]\n",
      "Iterate 136: Cost 0.0030747171498741867,   \n",
      "  |    Weight  [0.09557303 0.10188587 0.09781754 0.10227417 0.09841473],\n",
      "    |     Bias [0.07700778 0.07673306 0.07692066 0.07678154 0.07696348]\n",
      "Iterate 137: Cost 0.003073538520485834,   \n",
      "  |    Weight  [0.09554088 0.10189942 0.09780166 0.1022907  0.09840335],\n",
      "    |     Bias [0.07749374 0.07721705 0.07740601 0.07726588 0.07744914]\n",
      "Iterate 138: Cost 0.003072360363255847,   \n",
      "  |    Weight  [0.09550875 0.10191297 0.09778578 0.10230722 0.09839198],\n",
      "    |     Bias [0.07797961 0.07770093 0.07789126 0.07775012 0.0779347 ]\n",
      "Iterate 139: Cost 0.003071182677995051,   \n",
      "  |    Weight  [0.09547662 0.10192652 0.09776991 0.10232374 0.09838062],\n",
      "    |     Bias [0.07846537 0.07818472 0.07837641 0.07823426 0.07842016]\n",
      "Iterate 140: Cost 0.003070005464514344,   \n",
      "  |    Weight  [0.0954445  0.10194006 0.09775404 0.10234026 0.09836926],\n",
      "    |     Bias [0.07895104 0.07866842 0.07886147 0.07871831 0.07890552]\n",
      "Iterate 141: Cost 0.0030688287226247014,   \n",
      "  |    Weight  [0.09541238 0.1019536  0.09773817 0.10235678 0.0983579 ],\n",
      "    |     Bias [0.0794366  0.07915201 0.07934642 0.07920226 0.07939079]\n",
      "Iterate 142: Cost 0.0030676524521371733,   \n",
      "  |    Weight  [0.09538027 0.10196713 0.09772231 0.10237329 0.09834655],\n",
      "    |     Bias [0.07992208 0.07963551 0.07983129 0.07968611 0.07987596]\n",
      "Iterate 143: Cost 0.003066476652862885,   \n",
      "  |    Weight  [0.09534816 0.10198066 0.09770645 0.1023898  0.0983352 ],\n",
      "    |     Bias [0.08040745 0.08011891 0.08031605 0.08016987 0.08036104]\n",
      "Iterate 144: Cost 0.00306530132461304,   \n",
      "  |    Weight  [0.09531606 0.10199418 0.09769058 0.1024063  0.09832385],\n",
      "    |     Bias [0.08089273 0.08060222 0.08080072 0.08065353 0.08084601]\n",
      "Iterate 145: Cost 0.003064126467198914,   \n",
      "  |    Weight  [0.09528397 0.1020077  0.09767473 0.10242281 0.09831251],\n",
      "    |     Bias [0.0813779  0.08108543 0.08128529 0.08113709 0.08133089]\n",
      "Iterate 146: Cost 0.0030629520804318607,   \n",
      "  |    Weight  [0.09525188 0.10202121 0.09765887 0.10243931 0.09830118],\n",
      "    |     Bias [0.08186299 0.08156854 0.08176976 0.08162056 0.08181568]\n",
      "Iterate 147: Cost 0.0030617781641233094,   \n",
      "  |    Weight  [0.09521979 0.10203472 0.09764302 0.10245581 0.09828985],\n",
      "    |     Bias [0.08234797 0.08205155 0.08225414 0.08210392 0.08230036]\n",
      "Iterate 148: Cost 0.0030606047180847637,   \n",
      "  |    Weight  [0.09518772 0.10204822 0.09762717 0.1024723  0.09827852],\n",
      "    |     Bias [0.08283286 0.08253447 0.08273842 0.0825872  0.08278495]\n",
      "Iterate 149: Cost 0.0030594317421278033,   \n",
      "  |    Weight  [0.09515565 0.10206173 0.09761132 0.10248879 0.09826719],\n",
      "    |     Bias [0.08331765 0.0830173  0.0832226  0.08307037 0.08326944]\n",
      "Iterate 150: Cost 0.0030582592360640834,   \n",
      "  |    Weight  [0.09512358 0.10207522 0.09759547 0.10250528 0.09825587],\n",
      "    |     Bias [0.08380234 0.08350002 0.08370669 0.08355345 0.08375384]\n",
      "Iterate 151: Cost 0.003057087199705335,   \n",
      "  |    Weight  [0.09509152 0.10208871 0.09757963 0.10252177 0.09824456],\n",
      "    |     Bias [0.08428693 0.08398265 0.08419068 0.08403643 0.08423813]\n",
      "Iterate 152: Cost 0.0030559156328633635,   \n",
      "  |    Weight  [0.09505947 0.1021022  0.09756379 0.10253825 0.09823325],\n",
      "    |     Bias [0.08477143 0.08446518 0.08467457 0.08451932 0.08472233]\n",
      "Iterate 153: Cost 0.003054744535350051,   \n",
      "  |    Weight  [0.09502743 0.10211568 0.09754795 0.10255473 0.09822194],\n",
      "    |     Bias [0.08525583 0.08494762 0.08515837 0.08500211 0.08520644]\n",
      "Iterate 154: Cost 0.0030535739069773543,   \n",
      "  |    Weight  [0.09499538 0.10212916 0.09753212 0.10257121 0.09821063],\n",
      "    |     Bias [0.08574013 0.08542996 0.08564206 0.0854848  0.08569044]\n",
      "Iterate 155: Cost 0.0030524037475573055,   \n",
      "  |    Weight  [0.09496335 0.10214263 0.09751628 0.10258769 0.09819933],\n",
      "    |     Bias [0.08622434 0.0859122  0.08612567 0.08596739 0.08617435]\n",
      "Iterate 156: Cost 0.0030512340569020116,   \n",
      "  |    Weight  [0.09493132 0.1021561  0.09750045 0.10260416 0.09818804],\n",
      "    |     Bias [0.08670845 0.08639434 0.08660917 0.08644989 0.08665817]\n",
      "Iterate 157: Cost 0.0030500648348236567,   \n",
      "  |    Weight  [0.0948993  0.10216957 0.09748462 0.10262063 0.09817675],\n",
      "    |     Bias [0.08719246 0.08687639 0.08709258 0.08693229 0.08714188]\n",
      "Iterate 158: Cost 0.003048896081134498,   \n",
      "  |    Weight  [0.09486728 0.10218303 0.0974688  0.1026371  0.09816546],\n",
      "    |     Bias [0.08767637 0.08735834 0.08757589 0.0874146  0.0876255 ]\n",
      "Iterate 159: Cost 0.0030477277956468688,   \n",
      "  |    Weight  [0.09483527 0.10219648 0.09745297 0.10265356 0.09815418],\n",
      "    |     Bias [0.08816019 0.0878402  0.0880591  0.08789681 0.08810902]\n",
      "Iterate 160: Cost 0.003046559978173178,   \n",
      "  |    Weight  [0.09480326 0.10220993 0.09743715 0.10267002 0.0981429 ],\n",
      "    |     Bias [0.08864391 0.08832196 0.08854222 0.08837892 0.08859245]\n",
      "Iterate 161: Cost 0.003045392628525909,   \n",
      "  |    Weight  [0.09477126 0.10222338 0.09742133 0.10268648 0.09813162],\n",
      "    |     Bias [0.08912753 0.08880362 0.08902524 0.08886094 0.08907578]\n",
      "Iterate 162: Cost 0.00304422574651762,   \n",
      "  |    Weight  [0.09473927 0.10223682 0.09740552 0.10270294 0.09812035],\n",
      "    |     Bias [0.08961106 0.08928519 0.08950817 0.08934286 0.08955901]\n",
      "Iterate 163: Cost 0.003043059331960946,   \n",
      "  |    Weight  [0.09470728 0.10225026 0.0973897  0.10271939 0.09810908],\n",
      "    |     Bias [0.09009449 0.08976666 0.089991   0.08982468 0.09004215]\n",
      "Iterate 164: Cost 0.003041893384668596,   \n",
      "  |    Weight  [0.0946753  0.10226369 0.09737389 0.10273584 0.09809782],\n",
      "    |     Bias [0.09057782 0.09024803 0.09047373 0.09030641 0.09052519]\n",
      "Iterate 165: Cost 0.0030407279044533525,   \n",
      "  |    Weight  [0.09464332 0.10227712 0.09735808 0.10275229 0.09808656],\n",
      "    |     Bias [0.09106105 0.09072931 0.09095636 0.09078804 0.09100813]\n",
      "Iterate 166: Cost 0.003039562891128076,   \n",
      "  |    Weight  [0.09461135 0.10229054 0.09734228 0.10276873 0.09807531],\n",
      "    |     Bias [0.09154419 0.09121049 0.0914389  0.09126957 0.09149097]\n",
      "Iterate 167: Cost 0.0030383983445056995,   \n",
      "  |    Weight  [0.09457939 0.10230396 0.09732647 0.10278517 0.09806406],\n",
      "    |     Bias [0.09202723 0.09169158 0.09192134 0.09175101 0.09197372]\n",
      "Iterate 168: Cost 0.0030372342643992323,   \n",
      "  |    Weight  [0.09454743 0.10231738 0.09731067 0.10280161 0.09805281],\n",
      "    |     Bias [0.09251018 0.09217256 0.09240369 0.09223235 0.09245637]\n",
      "Iterate 169: Cost 0.0030360706506217584,   \n",
      "  |    Weight  [0.09451548 0.10233079 0.09729487 0.10281805 0.09804157],\n",
      "    |     Bias [0.09299302 0.09265346 0.09288593 0.09271359 0.09293893]\n",
      "Iterate 170: Cost 0.003034907502986436,   \n",
      "  |    Weight  [0.09448353 0.10234419 0.09727907 0.10283448 0.09803033],\n",
      "    |     Bias [0.09347577 0.09313425 0.09336809 0.09319474 0.09342139]\n",
      "Iterate 171: Cost 0.0030337448213065,   \n",
      "  |    Weight  [0.09445159 0.1023576  0.09726328 0.10285091 0.0980191 ],\n",
      "    |     Bias [0.09395842 0.09361495 0.09385014 0.09367579 0.09390375]\n",
      "Iterate 172: Cost 0.0030325826053952567,   \n",
      "  |    Weight  [0.09441966 0.10237099 0.09724749 0.10286734 0.09800787],\n",
      "    |     Bias [0.09444098 0.09409555 0.0943321  0.09415675 0.09438602]\n",
      "Iterate 173: Cost 0.003031420855066092,   \n",
      "  |    Weight  [0.09438773 0.10238438 0.0972317  0.10288376 0.09799664],\n",
      "    |     Bias [0.09492344 0.09457606 0.09481396 0.09463761 0.09486818]\n",
      "Iterate 174: Cost 0.0030302595701324616,   \n",
      "  |    Weight  [0.0943558  0.10239777 0.09721591 0.10290018 0.09798542],\n",
      "    |     Bias [0.0954058  0.09505647 0.09529573 0.09511837 0.09535026]\n",
      "Iterate 175: Cost 0.0030290987504079,   \n",
      "  |    Weight  [0.09432389 0.10241116 0.09720013 0.1029166  0.0979742 ],\n",
      "    |     Bias [0.09588807 0.09553679 0.0957774  0.09559904 0.09583223]\n",
      "Iterate 176: Cost 0.0030279383957060135,   \n",
      "  |    Weight  [0.09429198 0.10242454 0.09718434 0.10293302 0.09796298],\n",
      "    |     Bias [0.09637023 0.096017   0.09625897 0.09607961 0.09631411]\n",
      "Iterate 177: Cost 0.0030267785058404845,   \n",
      "  |    Weight  [0.09426007 0.10243791 0.09716856 0.10294943 0.09795177],\n",
      "    |     Bias [0.09685231 0.09649713 0.09674045 0.09656008 0.0967959 ]\n",
      "Iterate 178: Cost 0.0030256190806250706,   \n",
      "  |    Weight  [0.09422817 0.10245128 0.09715279 0.10296584 0.09794057],\n",
      "    |     Bias [0.09733428 0.09697715 0.09722183 0.09704046 0.09727758]\n",
      "Iterate 179: Cost 0.003024460119873602,   \n",
      "  |    Weight  [0.09419628 0.10246465 0.09713701 0.10298225 0.09792937],\n",
      "    |     Bias [0.09781616 0.09745708 0.09770311 0.09752074 0.09775917]\n",
      "Iterate 180: Cost 0.003023301623399985,   \n",
      "  |    Weight  [0.09416439 0.10247801 0.09712124 0.10299866 0.09791817],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |     Bias [0.09829794 0.09793692 0.0981843  0.09800093 0.09824067]\n",
      "Iterate 181: Cost 0.003022143591018201,   \n",
      "  |    Weight  [0.09413251 0.10249136 0.09710547 0.10301506 0.09790698],\n",
      "    |     Bias [0.09877963 0.09841665 0.09866539 0.09848102 0.09872206]\n",
      "Iterate 182: Cost 0.003020986022542304,   \n",
      "  |    Weight  [0.09410063 0.10250472 0.0970897  0.10303146 0.09789579],\n",
      "    |     Bias [0.09926121 0.09889629 0.09914638 0.09896101 0.09920336]\n",
      "Iterate 183: Cost 0.003019828917786425,   \n",
      "  |    Weight  [0.09406876 0.10251806 0.09707394 0.10304786 0.0978846 ],\n",
      "    |     Bias [0.0997427  0.09937584 0.09962728 0.09944091 0.09968457]\n",
      "Iterate 184: Cost 0.0030186722765647663,   \n",
      "  |    Weight  [0.0940369  0.10253141 0.09705818 0.10306425 0.09787342],\n",
      "    |     Bias [0.1002241  0.09985529 0.10010809 0.09992071 0.10016568]\n",
      "Iterate 185: Cost 0.0030175160986916083,   \n",
      "  |    Weight  [0.09400504 0.10254475 0.09704242 0.10308064 0.09786224],\n",
      "    |     Bias [0.1007054  0.10033464 0.10058879 0.10040042 0.10064669]\n",
      "Iterate 186: Cost 0.0030163603839813025,   \n",
      "  |    Weight  [0.09397319 0.10255808 0.09702666 0.10309703 0.09785107],\n",
      "    |     Bias [0.1011866  0.1008139  0.1010694  0.10088003 0.10112761]\n",
      "Iterate 187: Cost 0.0030152051322482765,   \n",
      "  |    Weight  [0.09394134 0.10257141 0.0970109  0.10311341 0.0978399 ],\n",
      "    |     Bias [0.1016677  0.10129306 0.10154992 0.10135954 0.10160843]\n",
      "Iterate 188: Cost 0.003014050343307033,   \n",
      "  |    Weight  [0.0939095  0.10258474 0.09699515 0.1031298  0.09782873],\n",
      "    |     Bias [0.10214871 0.10177213 0.10203033 0.10183896 0.10208915]\n",
      "Iterate 189: Cost 0.003012896016972147,   \n",
      "  |    Weight  [0.09387766 0.10259806 0.0969794  0.10314618 0.09781757],\n",
      "    |     Bias [0.10262962 0.1022511  0.10251065 0.10231828 0.10256978]\n",
      "Iterate 190: Cost 0.0030117421530582687,   \n",
      "  |    Weight  [0.09384583 0.10261137 0.09696365 0.10316255 0.09780641],\n",
      "    |     Bias [0.10311044 0.10272997 0.10299088 0.1027975  0.10305031]\n",
      "Iterate 191: Cost 0.0030105887513801233,   \n",
      "  |    Weight  [0.09381401 0.10262468 0.0969479  0.10317893 0.09779526],\n",
      "    |     Bias [0.10359115 0.10320875 0.10347101 0.10327663 0.10353074]\n",
      "Iterate 192: Cost 0.003009435811752509,   \n",
      "  |    Weight  [0.09378219 0.10263799 0.09693216 0.1031953  0.09778411],\n",
      "    |     Bias [0.10407178 0.10368743 0.10395104 0.10375567 0.10401108]\n",
      "Iterate 193: Cost 0.003008283333990299,   \n",
      "  |    Weight  [0.09375038 0.1026513  0.09691642 0.10321167 0.09777297],\n",
      "    |     Bias [0.1045523  0.10416602 0.10443098 0.10423461 0.10449132]\n",
      "Iterate 194: Cost 0.0030071313179084406,   \n",
      "  |    Weight  [0.09371858 0.10266459 0.09690068 0.10322803 0.09776183],\n",
      "    |     Bias [0.10503273 0.10464451 0.10491082 0.10471345 0.10497147]\n",
      "Iterate 195: Cost 0.003005979763321955,   \n",
      "  |    Weight  [0.09368678 0.10267789 0.09688495 0.1032444  0.09775069],\n",
      "    |     Bias [0.10551306 0.1051229  0.10539056 0.10519219 0.10545152]\n",
      "Iterate 196: Cost 0.0030048286700459378,   \n",
      "  |    Weight  [0.09365498 0.10269118 0.09686921 0.10326076 0.09773956],\n",
      "    |     Bias [0.1059933  0.1056012  0.10587021 0.10567084 0.10593147]\n",
      "Iterate 197: Cost 0.0030036780378955583,   \n",
      "  |    Weight  [0.09362319 0.10270446 0.09685348 0.10327711 0.09772843],\n",
      "    |     Bias [0.10647344 0.1060794  0.10634977 0.1061494  0.10641133]\n",
      "Iterate 198: Cost 0.0030025278666860602,   \n",
      "  |    Weight  [0.09359141 0.10271774 0.09683775 0.10329347 0.0977173 ],\n",
      "    |     Bias [0.10695348 0.10655751 0.10682922 0.10662786 0.10689109]\n",
      "Iterate 199: Cost 0.003001378156232761,   \n",
      "  |    Weight  [0.09355964 0.10273102 0.09682203 0.10330982 0.09770618],\n",
      "    |     Bias [0.10743343 0.10703552 0.10730858 0.10710622 0.10737076]\n",
      "Iterate 200: Cost 0.003000228906351052,   \n",
      "  |    Weight  [0.09352787 0.10274429 0.0968063  0.10332617 0.09769506],\n",
      "    |     Bias [0.10791328 0.10751344 0.10778785 0.10758449 0.10785033]\n",
      "Iterate 201: Cost 0.002999080116856399,   \n",
      "  |    Weight  [0.0934961  0.10275756 0.09679058 0.10334251 0.09768395],\n",
      "    |     Bias [0.10839303 0.10799126 0.10826702 0.10806266 0.1083298 ]\n",
      "Iterate 202: Cost 0.0029979317875643424,   \n",
      "  |    Weight  [0.09346434 0.10277082 0.09677486 0.10335886 0.09767284],\n",
      "    |     Bias [0.10887269 0.10846898 0.10874609 0.10854073 0.10880918]\n",
      "Iterate 203: Cost 0.0029967839182904943,   \n",
      "  |    Weight  [0.09343259 0.10278408 0.09675915 0.1033752  0.09766174],\n",
      "    |     Bias [0.10935225 0.10894661 0.10922507 0.10901871 0.10928846]\n",
      "Iterate 204: Cost 0.0029956365088505427,   \n",
      "  |    Weight  [0.09340084 0.10279733 0.09674343 0.10339154 0.09765064],\n",
      "    |     Bias [0.10983172 0.10942414 0.10970395 0.1094966  0.10976765]\n",
      "Iterate 205: Cost 0.002994489559060248,   \n",
      "  |    Weight  [0.0933691  0.10281058 0.09672772 0.10340787 0.09763954],\n",
      "    |     Bias [0.11031109 0.10990158 0.11018273 0.10997439 0.11024674]\n",
      "Iterate 206: Cost 0.0029933430687354465,   \n",
      "  |    Weight  [0.09333737 0.10282383 0.09671201 0.1034242  0.09762845],\n",
      "    |     Bias [0.11079036 0.11037892 0.11066142 0.11045208 0.11072573]\n",
      "Iterate 207: Cost 0.002992197037692046,   \n",
      "  |    Weight  [0.09330564 0.10283707 0.09669631 0.10344053 0.09761736],\n",
      "    |     Bias [0.11126954 0.11085617 0.11114002 0.11092968 0.11120463]\n",
      "Iterate 208: Cost 0.002991051465746028,   \n",
      "  |    Weight  [0.09327391 0.10285031 0.0966806  0.10345686 0.09760628],\n",
      "    |     Bias [0.11174862 0.11133332 0.11161852 0.11140718 0.11168343]\n",
      "Iterate 209: Cost 0.00298990635271345,   \n",
      "  |    Weight  [0.09324219 0.10286354 0.0966649  0.10347318 0.0975952 ],\n",
      "    |     Bias [0.1122276  0.11181037 0.11209692 0.11188458 0.11216214]\n",
      "Iterate 210: Cost 0.0029887616984104427,   \n",
      "  |    Weight  [0.09321048 0.10287677 0.0966492  0.1034895  0.09758412],\n",
      "    |     Bias [0.11270649 0.11228733 0.11257522 0.11236189 0.11264075]\n",
      "Iterate 211: Cost 0.002987617502653208,   \n",
      "  |    Weight  [0.09317878 0.10288999 0.0966335  0.10350582 0.09757305],\n",
      "    |     Bias [0.11318528 0.11276419 0.11305343 0.11283911 0.11311926]\n",
      "Iterate 212: Cost 0.0029864737652580244,   \n",
      "  |    Weight  [0.09314708 0.10290321 0.09661781 0.10352214 0.09756198],\n",
      "    |     Bias [0.11366398 0.11324096 0.11353155 0.11331623 0.11359768]\n",
      "Iterate 213: Cost 0.002985330486041241,   \n",
      "  |    Weight  [0.09311538 0.10291642 0.09660212 0.10353845 0.09755091],\n",
      "    |     Bias [0.11414257 0.11371764 0.11400957 0.11379325 0.114076  ]\n",
      "Iterate 214: Cost 0.002984187664819285,   \n",
      "  |    Weight  [0.09308369 0.10292963 0.09658643 0.10355476 0.09753985],\n",
      "    |     Bias [0.11462108 0.11419421 0.11448749 0.11427018 0.11455423]\n",
      "Iterate 215: Cost 0.0029830453014086517,   \n",
      "  |    Weight  [0.09305201 0.10294284 0.09657074 0.10357107 0.0975288 ],\n",
      "    |     Bias [0.11509949 0.1146707  0.11496532 0.11474701 0.11503236]\n",
      "Iterate 216: Cost 0.0029819033956259137,   \n",
      "  |    Weight  [0.09302033 0.10295604 0.09655505 0.10358737 0.09751775],\n",
      "    |     Bias [0.1155778  0.11514708 0.11544305 0.11522375 0.1155104 ]\n",
      "Iterate 217: Cost 0.0029807619472877168,   \n",
      "  |    Weight  [0.09298866 0.10296923 0.09653937 0.10360367 0.0975067 ],\n",
      "    |     Bias [0.11605601 0.11562337 0.11592069 0.11570039 0.11598834]\n",
      "Iterate 218: Cost 0.002979620956210779,   \n",
      "  |    Weight  [0.092957   0.10298242 0.09652369 0.10361997 0.09749565],\n",
      "    |     Bias [0.11653413 0.11609957 0.11639823 0.11617694 0.11646618]\n",
      "Iterate 219: Cost 0.002978480422211891,   \n",
      "  |    Weight  [0.09292534 0.10299561 0.09650801 0.10363627 0.09748461],\n",
      "    |     Bias [0.11701215 0.11657567 0.11687568 0.11665339 0.11694393]\n",
      "Iterate 220: Cost 0.002977340345107919,   \n",
      "  |    Weight  [0.09289368 0.10300879 0.09649234 0.10365256 0.09747358],\n",
      "    |     Bias [0.11749008 0.11705167 0.11735303 0.11712975 0.11742158]\n",
      "Iterate 221: Cost 0.0029762007247158026,   \n",
      "  |    Weight  [0.09286204 0.10302197 0.09647667 0.10366885 0.09746254],\n",
      "    |     Bias [0.11796791 0.11752758 0.11783028 0.11760601 0.11789914]\n",
      "Iterate 222: Cost 0.002975061560852552,   \n",
      "  |    Weight  [0.09283039 0.10303515 0.096461   0.10368514 0.09745152],\n",
      "    |     Bias [0.11844565 0.1180034  0.11830744 0.11808217 0.1183766 ]\n",
      "Iterate 223: Cost 0.0029739228533352544,   \n",
      "  |    Weight  [0.09279876 0.10304832 0.09644533 0.10370143 0.09744049],\n",
      "    |     Bias [0.11892329 0.11847912 0.1187845  0.11855824 0.11885397]\n",
      "Iterate 224: Cost 0.0029727846019810666,   \n",
      "  |    Weight  [0.09276713 0.10306148 0.09642966 0.10371771 0.09742947],\n",
      "    |     Bias [0.11940083 0.11895474 0.11926147 0.11903422 0.11933124]\n",
      "Iterate 225: Cost 0.0029716468066072216,   \n",
      "  |    Weight  [0.0927355  0.10307464 0.096414   0.10373399 0.09741846],\n",
      "    |     Bias [0.11987828 0.11943027 0.11973834 0.11951009 0.11980842]\n",
      "Iterate 226: Cost 0.0029705094670310237,   \n",
      "  |    Weight  [0.09270388 0.1030878  0.09639834 0.10375026 0.09740745],\n",
      "    |     Bias [0.12035563 0.1199057  0.12021512 0.11998588 0.1202855 ]\n",
      "Iterate 227: Cost 0.002969372583069853,   \n",
      "  |    Weight  [0.09267227 0.10310095 0.09638268 0.10376654 0.09739644],\n",
      "    |     Bias [0.12083289 0.12038104 0.1206918  0.12046157 0.12076248]\n",
      "Iterate 228: Cost 0.0029682361545411598,   \n",
      "  |    Weight  [0.09264066 0.1031141  0.09636702 0.10378281 0.09738543],\n",
      "    |     Bias [0.12131005 0.12085629 0.12116839 0.12093716 0.12123937]\n",
      "Iterate 229: Cost 0.002967100181262468,   \n",
      "  |    Weight  [0.09260906 0.10312724 0.09635137 0.10379908 0.09737443],\n",
      "    |     Bias [0.12178711 0.12133143 0.12164488 0.12141266 0.12171616]\n",
      "Iterate 230: Cost 0.0029659646630513766,   \n",
      "  |    Weight  [0.09257747 0.10314038 0.09633572 0.10381534 0.09736344],\n",
      "    |     Bias [0.12226408 0.12180649 0.12212127 0.12188806 0.12219286]\n",
      "Iterate 231: Cost 0.002964829599725556,   \n",
      "  |    Weight  [0.09254588 0.10315351 0.09632007 0.1038316  0.09735245],\n",
      "    |     Bias [0.12274095 0.12228144 0.12259757 0.12236337 0.12266946]\n",
      "Iterate 232: Cost 0.00296369499110275,   \n",
      "  |    Weight  [0.09251429 0.10316664 0.09630442 0.10384786 0.09734146],\n",
      "    |     Bias [0.12321773 0.12275631 0.12307378 0.12283858 0.12314597]\n",
      "Iterate 233: Cost 0.002962560837000776,   \n",
      "  |    Weight  [0.09248272 0.10317977 0.09628878 0.10386412 0.09733047],\n",
      "    |     Bias [0.12369441 0.12323107 0.12354989 0.1233137  0.12362238]\n",
      "Iterate 234: Cost 0.0029614271372375225,   \n",
      "  |    Weight  [0.09245114 0.10319289 0.09627314 0.10388037 0.09731949],\n",
      "    |     Bias [0.124171   0.12370575 0.1240259  0.12378872 0.1240987 ]\n",
      "Iterate 235: Cost 0.002960293891630954,   \n",
      "  |    Weight  [0.09241958 0.10320601 0.0962575  0.10389663 0.09730852],\n",
      "    |     Bias [0.12464749 0.12418032 0.12450182 0.12426365 0.12457492]\n",
      "Iterate 236: Cost 0.002959161099999106,   \n",
      "  |    Weight  [0.09238802 0.10321912 0.09624186 0.10391288 0.09729755],\n",
      "    |     Bias [0.12512388 0.12465481 0.12497764 0.12473848 0.12505105]\n",
      "Iterate 237: Cost 0.002958028762160086,   \n",
      "  |    Weight  [0.09235646 0.10323222 0.09622623 0.10392912 0.09728658],\n",
      "    |     Bias [0.12560018 0.12512919 0.12545337 0.12521322 0.12552708]\n",
      "Iterate 238: Cost 0.002956896877932077,   \n",
      "  |    Weight  [0.09232491 0.10324533 0.0962106  0.10394536 0.09727562],\n",
      "    |     Bias [0.12607638 0.12560349 0.125929   0.12568786 0.12600301]\n",
      "Iterate 239: Cost 0.002955765447133332,   \n",
      "  |    Weight  [0.09229337 0.10325843 0.09619497 0.1039616  0.09726466],\n",
      "    |     Bias [0.12655249 0.12607768 0.12640454 0.12616241 0.12647885]\n",
      "Iterate 240: Cost 0.0029546344695821803,   \n",
      "  |    Weight  [0.09226183 0.10327152 0.09617934 0.10397784 0.0972537 ],\n",
      "    |     Bias [0.1270285  0.12655179 0.12687998 0.12663686 0.12695459]\n",
      "Iterate 241: Cost 0.00295350394509702,   \n",
      "  |    Weight  [0.0922303  0.10328461 0.09616372 0.10399408 0.09724275],\n",
      "    |     Bias [0.12750442 0.12702579 0.12735533 0.12711122 0.12743024]\n",
      "Iterate 242: Cost 0.002952373873496325,   \n",
      "  |    Weight  [0.09219878 0.1032977  0.09614809 0.10401031 0.0972318 ],\n",
      "    |     Bias [0.12798024 0.12749971 0.12783058 0.12758548 0.1279058 ]\n",
      "Iterate 243: Cost 0.0029512442545986403,   \n",
      "  |    Weight  [0.09216726 0.10331078 0.09613247 0.10402654 0.09722086],\n",
      "    |     Bias [0.12845597 0.12797352 0.12830574 0.12805965 0.12838126]\n",
      "Iterate 244: Cost 0.0029501150882225847,   \n",
      "  |    Weight  [0.09213574 0.10332385 0.09611686 0.10404277 0.09720992],\n",
      "    |     Bias [0.1289316  0.12844725 0.1287808  0.12853372 0.12885662]\n",
      "Iterate 245: Cost 0.002948986374186849,   \n",
      "  |    Weight  [0.09210423 0.10333693 0.09610124 0.10405899 0.09719898],\n",
      "    |     Bias [0.12940713 0.12892087 0.12925577 0.1290077  0.12933189]\n",
      "Iterate 246: Cost 0.002947858112310196,   \n",
      "  |    Weight  [0.09207273 0.10334999 0.09608563 0.10407521 0.09718805],\n",
      "    |     Bias [0.12988257 0.12939441 0.12973064 0.12948158 0.12980706]\n",
      "Iterate 247: Cost 0.0029467303024114625,   \n",
      "  |    Weight  [0.09204123 0.10336306 0.09607002 0.10409143 0.09717712],\n",
      "    |     Bias [0.13035791 0.12986785 0.13020542 0.12995537 0.13028214]\n",
      "Iterate 248: Cost 0.002945602944309558,   \n",
      "  |    Weight  [0.09200974 0.10337612 0.09605441 0.10410764 0.0971662 ],\n",
      "    |     Bias [0.13083316 0.13034119 0.1306801  0.13042906 0.13075712]\n",
      "Iterate 249: Cost 0.0029444760378234624,   \n",
      "  |    Weight  [0.09197826 0.10338917 0.09603881 0.10412386 0.09715528],\n",
      "    |     Bias [0.13130831 0.13081444 0.13115469 0.13090266 0.13123201]\n",
      "Iterate 250: Cost 0.0029433495827722303,   \n",
      "  |    Weight  [0.09194678 0.10340222 0.0960232  0.10414007 0.09714436],\n",
      "    |     Bias [0.13178337 0.13128759 0.13162918 0.13137616 0.1317068 ]\n",
      "Iterate 251: Cost 0.002942223578974988,   \n",
      "  |    Weight  [0.09191531 0.10341527 0.0960076  0.10415627 0.09713345],\n",
      "    |     Bias [0.13225833 0.13176065 0.13210358 0.13184957 0.1321815 ]\n",
      "Iterate 252: Cost 0.002941098026250934,   \n",
      "  |    Weight  [0.09188384 0.10342831 0.095992   0.10417248 0.09712254],\n",
      "    |     Bias [0.1327332  0.13223361 0.13257788 0.13232289 0.13265611]\n",
      "Iterate 253: Cost 0.00293997292441934,   \n",
      "  |    Weight  [0.09185238 0.10344134 0.09597641 0.10418868 0.09711164],\n",
      "    |     Bias [0.13320797 0.13270648 0.13305209 0.1327961  0.13313061]\n",
      "Iterate 254: Cost 0.00293884827329955,   \n",
      "  |    Weight  [0.09182092 0.10345438 0.09596081 0.10420488 0.09710074],\n",
      "    |     Bias [0.13368264 0.13317926 0.1335262  0.13326923 0.13360503]\n",
      "Iterate 255: Cost 0.0029377240727109792,   \n",
      "  |    Weight  [0.09178947 0.1034674  0.09594522 0.10422107 0.09708985],\n",
      "    |     Bias [0.13415722 0.13365194 0.13400021 0.13374226 0.13407934]\n",
      "Iterate 256: Cost 0.0029366003224731165,   \n",
      "  |    Weight  [0.09175803 0.10348043 0.09592963 0.10423727 0.09707895],\n",
      "    |     Bias [0.13463171 0.13412452 0.13447414 0.13421519 0.13455357]\n",
      "Iterate 257: Cost 0.002935477022405522,   \n",
      "  |    Weight  [0.09172659 0.10349345 0.09591405 0.10425346 0.09706807],\n",
      "    |     Bias [0.1351061  0.13459702 0.13494796 0.13468803 0.1350277 ]\n",
      "Iterate 258: Cost 0.0029343541723278292,   \n",
      "  |    Weight  [0.09169515 0.10350646 0.09589846 0.10426965 0.09705718],\n",
      "    |     Bias [0.13558039 0.13506941 0.1354217  0.13516078 0.13550173]\n",
      "Iterate 259: Cost 0.0029332317720597444,   \n",
      "  |    Weight  [0.09166373 0.10351947 0.09588288 0.10428583 0.0970463 ],\n",
      "    |     Bias [0.13605459 0.13554171 0.13589533 0.13563343 0.13597567]\n",
      "Iterate 260: Cost 0.002932109821421044,   \n",
      "  |    Weight  [0.09163231 0.10353248 0.0958673  0.10430201 0.09703543],\n",
      "    |     Bias [0.1365287  0.13601392 0.13636888 0.13610599 0.13644951]\n",
      "Iterate 261: Cost 0.0029309883202315776,   \n",
      "  |    Weight  [0.09160089 0.10354548 0.09585173 0.10431819 0.09702456],\n",
      "    |     Bias [0.13700271 0.13648603 0.13684233 0.13657845 0.13692326]\n",
      "Iterate 262: Cost 0.0029298672683112674,   \n",
      "  |    Weight  [0.09156948 0.10355848 0.09583615 0.10433437 0.09701369],\n",
      "    |     Bias [0.13747662 0.13695805 0.13731568 0.13705082 0.13739691]\n",
      "Iterate 263: Cost 0.0029287466654801075,   \n",
      "  |    Weight  [0.09153808 0.10357147 0.09582058 0.10435054 0.09700282],\n",
      "    |     Bias [0.13795044 0.13742998 0.13778894 0.13752309 0.13787047]\n",
      "Iterate 264: Cost 0.0029276265115581643,   \n",
      "  |    Weight  [0.09150668 0.10358446 0.09580501 0.10436671 0.09699196],\n",
      "    |     Bias [0.13842416 0.1379018  0.1382621  0.13799527 0.13834393]\n",
      "Iterate 265: Cost 0.002926506806365576,   \n",
      "  |    Weight  [0.09147529 0.10359744 0.09578945 0.10438288 0.09698111],\n",
      "    |     Bias [0.13889779 0.13837354 0.13873517 0.13846735 0.1388173 ]\n",
      "Iterate 266: Cost 0.0029253875497225533,   \n",
      "  |    Weight  [0.0914439  0.10361042 0.09577388 0.10439905 0.09697026],\n",
      "    |     Bias [0.13937132 0.13884518 0.13920815 0.13893934 0.13929058]\n",
      "Iterate 267: Cost 0.0029242687414493774,   \n",
      "  |    Weight  [0.09141252 0.1036234  0.09575832 0.10441521 0.09695941],\n",
      "    |     Bias [0.13984476 0.13931673 0.13968103 0.13941123 0.13976376]\n",
      "Iterate 268: Cost 0.0029231503813664044,   \n",
      "  |    Weight  [0.09138114 0.10363637 0.09574276 0.10443137 0.09694857],\n",
      "    |     Bias [0.14031811 0.13978818 0.14015381 0.13988303 0.14023684]\n",
      "Iterate 269: Cost 0.002922032469294059,   \n",
      "  |    Weight  [0.09134977 0.10364934 0.0957272  0.10444753 0.09693773],\n",
      "    |     Bias [0.14079135 0.14025953 0.1406265  0.14035474 0.14070983]\n",
      "Iterate 270: Cost 0.002920915005052841,   \n",
      "  |    Weight  [0.09131841 0.1036623  0.09571165 0.10446368 0.09692689],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |     Bias [0.14126451 0.1407308  0.1410991  0.14082635 0.14118273]\n",
      "Iterate 271: Cost 0.0029197979884633195,   \n",
      "  |    Weight  [0.09128705 0.10367525 0.09569609 0.10447984 0.09691606],\n",
      "    |     Bias [0.14173757 0.14120196 0.1415716  0.14129787 0.14165553]\n",
      "Iterate 272: Cost 0.002918681419346138,   \n",
      "  |    Weight  [0.0912557  0.10368821 0.09568054 0.10449598 0.09690523],\n",
      "    |     Bias [0.14221053 0.14167304 0.142044   0.14176929 0.14212824]\n",
      "Iterate 273: Cost 0.0029175652975220088,   \n",
      "  |    Weight  [0.09122435 0.10370116 0.095665   0.10451213 0.09689441],\n",
      "    |     Bias [0.1426834  0.14214402 0.14251632 0.14224062 0.14260085]\n",
      "Iterate 274: Cost 0.002916449622811719,   \n",
      "  |    Weight  [0.09119301 0.1037141  0.09564945 0.10452827 0.09688359],\n",
      "    |     Bias [0.14315617 0.1426149  0.14298853 0.14271185 0.14307337]\n",
      "Iterate 275: Cost 0.002915334395036126,   \n",
      "  |    Weight  [0.09116168 0.10372704 0.09563391 0.10454442 0.09687277],\n",
      "    |     Bias [0.14362885 0.14308569 0.14346066 0.14318299 0.14354579]\n",
      "Iterate 276: Cost 0.0029142196140161587,   \n",
      "  |    Weight  [0.09113035 0.10373998 0.09561837 0.10456055 0.09686196],\n",
      "    |     Bias [0.14410143 0.14355639 0.14393269 0.14365403 0.14401812]\n",
      "Iterate 277: Cost 0.002913105279572818,   \n",
      "  |    Weight  [0.09109903 0.10375291 0.09560283 0.10457669 0.09685115],\n",
      "    |     Bias [0.14457392 0.14402699 0.14440462 0.14412498 0.14449035]\n",
      "Iterate 278: Cost 0.0029119913915271792,   \n",
      "  |    Weight  [0.09106771 0.10376584 0.09558729 0.10459282 0.09684035],\n",
      "    |     Bias [0.14504631 0.1444975  0.14487646 0.14459584 0.14496249]\n",
      "Iterate 279: Cost 0.002910877949700384,   \n",
      "  |    Weight  [0.0910364  0.10377876 0.09557176 0.10460895 0.09682955],\n",
      "    |     Bias [0.14551861 0.14496791 0.14534821 0.1450666  0.14543453]\n",
      "Iterate 280: Cost 0.0029097649539136495,   \n",
      "  |    Weight  [0.09100509 0.10379168 0.09555623 0.10462508 0.09681875],\n",
      "    |     Bias [0.14599082 0.14543823 0.14581986 0.14553727 0.14590648]\n",
      "Iterate 281: Cost 0.0029086524039882637,   \n",
      "  |    Weight  [0.09097379 0.10380459 0.0955407  0.1046412  0.09680796],\n",
      "    |     Bias [0.14646293 0.14590846 0.14629141 0.14600784 0.14637834]\n",
      "Iterate 282: Cost 0.0029075402997455874,   \n",
      "  |    Weight  [0.0909425  0.1038175  0.09552517 0.10465733 0.09679717],\n",
      "    |     Bias [0.14693494 0.14637859 0.14676287 0.14647832 0.1468501 ]\n",
      "Iterate 283: Cost 0.00290642864100705,   \n",
      "  |    Weight  [0.09091121 0.1038304  0.09550965 0.10467344 0.09678639],\n",
      "    |     Bias [0.14740686 0.14684863 0.14723424 0.14694871 0.14732176]\n",
      "Iterate 284: Cost 0.0029053174275941542,   \n",
      "  |    Weight  [0.09087992 0.10384331 0.09549413 0.10468956 0.09677561],\n",
      "    |     Bias [0.14787869 0.14731857 0.14770552 0.147419   0.14779334]\n",
      "Iterate 285: Cost 0.0029042066593284745,   \n",
      "  |    Weight  [0.09084865 0.1038562  0.09547861 0.10470567 0.09676483],\n",
      "    |     Bias [0.14835042 0.14778842 0.14817669 0.1478892  0.14826481]\n",
      "Iterate 286: Cost 0.002903096336031657,   \n",
      "  |    Weight  [0.09081738 0.10386909 0.09546309 0.10472178 0.09675406],\n",
      "    |     Bias [0.14882205 0.14825817 0.14864778 0.1483593  0.1487362 ]\n",
      "Iterate 287: Cost 0.002901986457525418,   \n",
      "  |    Weight  [0.09078611 0.10388198 0.09544758 0.10473789 0.09674329],\n",
      "    |     Bias [0.14929359 0.14872783 0.14911877 0.14882931 0.14920749]\n",
      "Iterate 288: Cost 0.002900877023631546,   \n",
      "  |    Weight  [0.09075485 0.10389486 0.09543207 0.104754   0.09673253],\n",
      "    |     Bias [0.14976504 0.1491974  0.14958967 0.14929922 0.14967868]\n",
      "Iterate 289: Cost 0.002899768034171902,   \n",
      "  |    Weight  [0.0907236  0.10390774 0.09541656 0.1047701  0.09672177],\n",
      "    |     Bias [0.15023639 0.14966687 0.15006047 0.14976904 0.15014978]\n",
      "Iterate 290: Cost 0.0028986594889684157,   \n",
      "  |    Weight  [0.09069235 0.10392062 0.09540105 0.1047862  0.09671101],\n",
      "    |     Bias [0.15070765 0.15013625 0.15053117 0.15023877 0.15062079]\n",
      "Iterate 291: Cost 0.002897551387843091,   \n",
      "  |    Weight  [0.0906611  0.10393349 0.09538554 0.1048023  0.09670026],\n",
      "    |     Bias [0.15117881 0.15060554 0.15100179 0.1507084  0.1510917 ]\n",
      "Iterate 292: Cost 0.0028964437306180004,   \n",
      "  |    Weight  [0.09062987 0.10394635 0.09537004 0.10481839 0.09668951],\n",
      "    |     Bias [0.15164988 0.15107473 0.15147231 0.15117794 0.15156252]\n",
      "Iterate 293: Cost 0.0028953365171152916,   \n",
      "  |    Weight  [0.09059864 0.10395921 0.09535454 0.10483448 0.09667877],\n",
      "    |     Bias [0.15212085 0.15154382 0.15194273 0.15164739 0.15203324]\n",
      "Iterate 294: Cost 0.0028942297471571793,   \n",
      "  |    Weight  [0.09056741 0.10397207 0.09533904 0.10485057 0.09666803],\n",
      "    |     Bias [0.15259173 0.15201283 0.15241306 0.15211674 0.15250387]\n",
      "Iterate 295: Cost 0.0028931234205659506,   \n",
      "  |    Weight  [0.09053619 0.10398492 0.09532355 0.10486666 0.09665729],\n",
      "    |     Bias [0.15306251 0.15248174 0.1528833  0.15258599 0.1529744 ]\n",
      "Iterate 296: Cost 0.002892017537163966,   \n",
      "  |    Weight  [0.09050498 0.10399777 0.09530806 0.10488274 0.09664656],\n",
      "    |     Bias [0.1535332  0.15295055 0.15335344 0.15305516 0.15344484]\n",
      "Iterate 297: Cost 0.0028909120967736545,   \n",
      "  |    Weight  [0.09047377 0.10401061 0.09529257 0.10489882 0.09663583],\n",
      "    |     Bias [0.1540038  0.15341927 0.15382349 0.15352422 0.15391519]\n",
      "Iterate 298: Cost 0.0028898070992175178,   \n",
      "  |    Weight  [0.09044257 0.10402345 0.09527708 0.1049149  0.0966251 ],\n",
      "    |     Bias [0.1544743  0.1538879  0.15429345 0.1539932  0.15438544]\n",
      "Iterate 299: Cost 0.0028887025443181287,   \n",
      "  |    Weight  [0.09041137 0.10403629 0.09526159 0.10493097 0.09661438],\n",
      "    |     Bias [0.1549447  0.15435643 0.15476331 0.15446208 0.1548556 ]\n",
      "Iterate 300: Cost 0.002887598431898131,   \n",
      "  |    Weight  [0.09038018 0.10404912 0.09524611 0.10494704 0.09660367],\n",
      "    |     Bias [0.15541501 0.15482487 0.15523307 0.15493087 0.15532566]\n",
      "Iterate 301: Cost 0.0028864947617802373,   \n",
      "  |    Weight  [0.09034899 0.10406195 0.09523063 0.10496311 0.09659295],\n",
      "    |     Bias [0.15588523 0.15529322 0.15570274 0.15539956 0.15579563]\n",
      "Iterate 302: Cost 0.002885391533787235,   \n",
      "  |    Weight  [0.09031781 0.10407477 0.09521515 0.10497918 0.09658225],\n",
      "    |     Bias [0.15635535 0.15576147 0.15617232 0.15586816 0.15626551]\n",
      "Iterate 303: Cost 0.0028842887477419795,   \n",
      "  |    Weight  [0.09028664 0.10408759 0.09519967 0.10499524 0.09657154],\n",
      "    |     Bias [0.15682538 0.15622963 0.15664181 0.15633667 0.15673529]\n",
      "Iterate 304: Cost 0.002883186403467399,   \n",
      "  |    Weight  [0.09025547 0.1041004  0.0951842  0.10501131 0.09656084],\n",
      "    |     Bias [0.15729532 0.15669769 0.1571112  0.15680508 0.15720498]\n",
      "Iterate 305: Cost 0.0028820845007864917,   \n",
      "  |    Weight  [0.09022431 0.10411321 0.09516873 0.10502736 0.09655014],\n",
      "    |     Bias [0.15776516 0.15716566 0.15758049 0.15727339 0.15767457]\n",
      "Iterate 306: Cost 0.002880983039522327,   \n",
      "  |    Weight  [0.09019315 0.10412601 0.09515326 0.10504342 0.09653945],\n",
      "    |     Bias [0.1582349  0.15763354 0.1580497  0.15774162 0.15814407]\n",
      "Iterate 307: Cost 0.0028798820194980454,   \n",
      "  |    Weight  [0.090162   0.10413881 0.09513779 0.10505947 0.09652876],\n",
      "    |     Bias [0.15870455 0.15810132 0.1585188  0.15820975 0.15861348]\n",
      "Iterate 308: Cost 0.002878781440536858,   \n",
      "  |    Weight  [0.09013086 0.10415161 0.09512233 0.10507552 0.09651808],\n",
      "    |     Bias [0.15917411 0.15856901 0.15898782 0.15867779 0.15908279]\n",
      "Iterate 309: Cost 0.002877681302462047,   \n",
      "  |    Weight  [0.09009972 0.1041644  0.09510686 0.10509157 0.0965074 ],\n",
      "    |     Bias [0.15964357 0.15903661 0.15945674 0.15914573 0.159552  ]\n",
      "Iterate 310: Cost 0.0028765816050969647,   \n",
      "  |    Weight  [0.09006858 0.10417719 0.09509141 0.10510762 0.09649672],\n",
      "    |     Bias [0.16011294 0.15950411 0.15992557 0.15961358 0.16002113]\n",
      "Iterate 311: Cost 0.0028754823482650353,   \n",
      "  |    Weight  [0.09003746 0.10418997 0.09507595 0.10512366 0.09648605],\n",
      "    |     Bias [0.16058221 0.15997152 0.1603943  0.16008133 0.16049016]\n",
      "Iterate 312: Cost 0.0028743835317897523,   \n",
      "  |    Weight  [0.09000633 0.10420275 0.09506049 0.1051397  0.09647538],\n",
      "    |     Bias [0.16105139 0.16043884 0.16086294 0.160549   0.16095909]\n",
      "Iterate 313: Cost 0.002873285155494682,   \n",
      "  |    Weight  [0.08997522 0.10421552 0.09504504 0.10515573 0.09646471],\n",
      "    |     Bias [0.16152048 0.16090606 0.16133148 0.16101657 0.16142794]\n",
      "Iterate 314: Cost 0.002872187219203458,   \n",
      "  |    Weight  [0.08994411 0.10422829 0.09502959 0.10517177 0.09645405],\n",
      "    |     Bias [0.16198947 0.16137319 0.16179993 0.16148404 0.16189668]\n",
      "Iterate 315: Cost 0.0028710897227397893,   \n",
      "  |    Weight  [0.089913   0.10424106 0.09501414 0.1051878  0.09644339],\n",
      "    |     Bias [0.16245837 0.16184022 0.16226829 0.16195142 0.16236534]\n",
      "Iterate 316: Cost 0.002869992665927451,   \n",
      "  |    Weight  [0.0898819  0.10425382 0.0949987  0.10520383 0.09643274],\n",
      "    |     Bias [0.16292717 0.16230716 0.16273656 0.16241871 0.1628339 ]\n",
      "Iterate 317: Cost 0.0028688960485902908,   \n",
      "  |    Weight  [0.08985081 0.10426657 0.09498325 0.10521985 0.09642209],\n",
      "    |     Bias [0.16339588 0.16277401 0.16320473 0.1628859  0.16330237]\n",
      "Iterate 318: Cost 0.0028677998705522283,   \n",
      "  |    Weight  [0.08981972 0.10427933 0.09496781 0.10523588 0.09641145],\n",
      "    |     Bias [0.16386449 0.16324076 0.1636728  0.163353   0.16377074]\n",
      "Iterate 319: Cost 0.0028667041316372504,   \n",
      "  |    Weight  [0.08978864 0.10429207 0.09495238 0.1052519  0.0964008 ],\n",
      "    |     Bias [0.16433302 0.16370742 0.16414079 0.16382001 0.16423902]\n",
      "Iterate 320: Cost 0.0028656088316694186,   \n",
      "  |    Weight  [0.08975756 0.10430482 0.09493694 0.10526791 0.09639017],\n",
      "    |     Bias [0.16480144 0.16417399 0.16460868 0.16428693 0.1647072 ]\n",
      "Iterate 321: Cost 0.002864513970472861,   \n",
      "  |    Weight  [0.08972649 0.10431756 0.09492151 0.10528393 0.09637953],\n",
      "    |     Bias [0.16526978 0.16464046 0.16507647 0.16475375 0.1651753 ]\n",
      "Iterate 322: Cost 0.002863419547871778,   \n",
      "  |    Weight  [0.08969543 0.10433029 0.09490607 0.10529994 0.0963689 ],\n",
      "    |     Bias [0.16573801 0.16510685 0.16554417 0.16522047 0.16564329]\n",
      "Iterate 323: Cost 0.0028623255636904417,   \n",
      "  |    Weight  [0.08966437 0.10434302 0.09489065 0.10531595 0.09635828],\n",
      "    |     Bias [0.16620616 0.16557313 0.16601178 0.16568711 0.1661112 ]\n",
      "Iterate 324: Cost 0.0028612320177531913,   \n",
      "  |    Weight  [0.08963331 0.10435575 0.09487522 0.10533196 0.09634766],\n",
      "    |     Bias [0.16667421 0.16603933 0.1664793  0.16615365 0.16657901]\n",
      "Iterate 325: Cost 0.002860138909884439,   \n",
      "  |    Weight  [0.08960227 0.10436847 0.0948598  0.10534796 0.09633704],\n",
      "    |     Bias [0.16714217 0.16650543 0.16694672 0.16662009 0.16704673]\n",
      "Iterate 326: Cost 0.0028590462399086672,   \n",
      "  |    Weight  [0.08957122 0.10438119 0.09484437 0.10536396 0.09632642],\n",
      "    |     Bias [0.16761003 0.16697143 0.16741405 0.16708645 0.16751435]\n",
      "Iterate 327: Cost 0.0028579540076504274,   \n",
      "  |    Weight  [0.08954019 0.1043939  0.09482895 0.10537996 0.09631582],\n",
      "    |     Bias [0.1680778  0.16743735 0.16788128 0.1675527  0.16798188]\n",
      "Iterate 328: Cost 0.0028568622129343424,   \n",
      "  |    Weight  [0.08950916 0.10440661 0.09481354 0.10539596 0.09630521],\n",
      "    |     Bias [0.16854547 0.16790317 0.16834842 0.16801887 0.16844931]\n",
      "Iterate 329: Cost 0.002855770855585104,   \n",
      "  |    Weight  [0.08947813 0.10441931 0.09479812 0.10541195 0.09629461],\n",
      "    |     Bias [0.16901305 0.16836889 0.16881547 0.16848494 0.16891666]\n",
      "Iterate 330: Cost 0.002854679935427477,   \n",
      "  |    Weight  [0.08944711 0.10443201 0.09478271 0.10542794 0.09628401],\n",
      "    |     Bias [0.16948054 0.16883453 0.16928242 0.16895092 0.16938391]\n",
      "Iterate 331: Cost 0.002853589452286293,   \n",
      "  |    Weight  [0.0894161  0.10444471 0.0947673  0.10544393 0.09627341],\n",
      "    |     Bias [0.16994793 0.16930007 0.16974928 0.16941681 0.16985106]\n",
      "Iterate 332: Cost 0.0028524994059864555,   \n",
      "  |    Weight  [0.08938509 0.1044574  0.09475189 0.10545991 0.09626282],\n",
      "    |     Bias [0.17041523 0.16976551 0.17021605 0.1698826  0.17031812]\n",
      "Iterate 333: Cost 0.0028514097963529385,   \n",
      "  |    Weight  [0.08935409 0.10447009 0.09473649 0.10547589 0.09625224],\n",
      "    |     Bias [0.17088244 0.17023087 0.17068272 0.1703483  0.17078509]\n",
      "Iterate 334: Cost 0.002850320623210786,   \n",
      "  |    Weight  [0.08932309 0.10448277 0.09472109 0.10549187 0.09624166],\n",
      "    |     Bias [0.17134955 0.17069613 0.1711493  0.17081391 0.17125197]\n",
      "Iterate 335: Cost 0.002849231886385111,   \n",
      "  |    Weight  [0.0892921  0.10449545 0.09470569 0.10550785 0.09623108],\n",
      "    |     Bias [0.17181657 0.1711613  0.17161579 0.17127942 0.17171875]\n",
      "Iterate 336: Cost 0.002848143585701097,   \n",
      "  |    Weight  [0.08926111 0.10450812 0.09469029 0.10552382 0.0962205 ],\n",
      "    |     Bias [0.17228349 0.17162637 0.17208218 0.17174485 0.17218544]\n",
      "Iterate 337: Cost 0.0028470557209839984,   \n",
      "  |    Weight  [0.08923014 0.10452079 0.09467489 0.10553979 0.09620993],\n",
      "    |     Bias [0.17275032 0.17209135 0.17254848 0.17221017 0.17265203]\n",
      "Iterate 338: Cost 0.0028459682920591394,   \n",
      "  |    Weight  [0.08919916 0.10453346 0.0946595  0.10555576 0.09619937],\n",
      "    |     Bias [0.17321706 0.17255624 0.17301469 0.17267541 0.17311853]\n",
      "Iterate 339: Cost 0.0028448812987519135,   \n",
      "  |    Weight  [0.08916819 0.10454612 0.09464411 0.10557173 0.0961888 ],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |     Bias [0.1736837  0.17302104 0.1734808  0.17314055 0.17358494]\n",
      "Iterate 340: Cost 0.0028437947408877836,   \n",
      "  |    Weight  [0.08913723 0.10455877 0.09462872 0.10558769 0.09617824],\n",
      "    |     Bias [0.17415025 0.17348574 0.17394682 0.1736056  0.17405125]\n",
      "Iterate 341: Cost 0.0028427086182922856,   \n",
      "  |    Weight  [0.08910627 0.10457143 0.09461333 0.10560365 0.09616769],\n",
      "    |     Bias [0.17461671 0.17395035 0.17441274 0.17407055 0.17451748]\n",
      "Iterate 342: Cost 0.0028416229307910218,   \n",
      "  |    Weight  [0.08907532 0.10458407 0.09459795 0.10561961 0.09615714],\n",
      "    |     Bias [0.17508307 0.17441486 0.17487858 0.17453541 0.1749836 ]\n",
      "Iterate 343: Cost 0.0028405376782096653,   \n",
      "  |    Weight  [0.08904438 0.10459672 0.09458257 0.10563556 0.09614659],\n",
      "    |     Bias [0.17554934 0.17487929 0.17534432 0.17500018 0.17544964]\n",
      "Iterate 344: Cost 0.0028394528603739593,   \n",
      "  |    Weight  [0.08901344 0.10460936 0.09456719 0.10565152 0.09613605],\n",
      "    |     Bias [0.17601551 0.17534362 0.17580996 0.17546486 0.17591558]\n",
      "Iterate 345: Cost 0.0028383684771097185,   \n",
      "  |    Weight  [0.0889825  0.10462199 0.09455181 0.10566747 0.09612551],\n",
      "    |     Bias [0.17648159 0.17580785 0.17627552 0.17592944 0.17638143]\n",
      "Iterate 346: Cost 0.0028372845282428247,   \n",
      "  |    Weight  [0.08895158 0.10463462 0.09453644 0.10568341 0.09611497],\n",
      "    |     Bias [0.17694758 0.176272   0.17674098 0.17639393 0.17684718]\n",
      "Iterate 347: Cost 0.0028362010135992307,   \n",
      "  |    Weight  [0.08892065 0.10464725 0.09452106 0.10569936 0.09610444],\n",
      "    |     Bias [0.17741348 0.17673605 0.17720635 0.17685832 0.17731284]\n",
      "Iterate 348: Cost 0.00283511793300496,   \n",
      "  |    Weight  [0.08888974 0.10465987 0.0945057  0.1057153  0.09609392],\n",
      "    |     Bias [0.17787928 0.17720001 0.17767162 0.17732263 0.17777841]\n",
      "Iterate 349: Cost 0.0028340352862861037,   \n",
      "  |    Weight  [0.08885883 0.10467249 0.09449033 0.10573124 0.09608339],\n",
      "    |     Bias [0.17834498 0.17766387 0.1781368  0.17778684 0.17824389]\n",
      "Iterate 350: Cost 0.0028329530732688238,   \n",
      "  |    Weight  [0.08882792 0.1046851  0.09447496 0.10574717 0.09607287],\n",
      "    |     Bias [0.1788106  0.17812764 0.17860189 0.17825096 0.17870927]\n",
      "Iterate 351: Cost 0.0028318712937793517,   \n",
      "  |    Weight  [0.08879702 0.10469771 0.0944596  0.10576311 0.09606236],\n",
      "    |     Bias [0.17927612 0.17859132 0.17906688 0.17871498 0.17917456]\n",
      "Iterate 352: Cost 0.002830789947643989,   \n",
      "  |    Weight  [0.08876613 0.10471032 0.09444424 0.10577904 0.09605185],\n",
      "    |     Bias [0.17974154 0.17905491 0.17953178 0.17917891 0.17963975]\n",
      "Iterate 353: Cost 0.0028297090346891068,   \n",
      "  |    Weight  [0.08873524 0.10472292 0.09442888 0.10579496 0.09604134],\n",
      "    |     Bias [0.18020688 0.1795184  0.17999659 0.17964275 0.18010486]\n",
      "Iterate 354: Cost 0.0028286285547411438,   \n",
      "  |    Weight  [0.08870435 0.10473551 0.09441353 0.10581089 0.09603083],\n",
      "    |     Bias [0.18067212 0.1799818  0.18046131 0.1801065  0.18056987]\n",
      "Iterate 355: Cost 0.002827548507626612,   \n",
      "  |    Weight  [0.08867348 0.1047481  0.09439817 0.10582681 0.09602033],\n",
      "    |     Bias [0.18113726 0.18044511 0.18092593 0.18057015 0.18103478]\n",
      "Iterate 356: Cost 0.0028264688931720888,   \n",
      "  |    Weight  [0.08864261 0.10476069 0.09438282 0.10584273 0.09600984],\n",
      "    |     Bias [0.18160231 0.18090833 0.18139046 0.18103371 0.1814996 ]\n",
      "Iterate 357: Cost 0.002825389711204224,   \n",
      "  |    Weight  [0.08861174 0.10477327 0.09436747 0.10585865 0.09599935],\n",
      "    |     Bias [0.18206727 0.18137145 0.1818549  0.18149718 0.18196433]\n",
      "Iterate 358: Cost 0.002824310961549736,   \n",
      "  |    Weight  [0.08858088 0.10478585 0.09435213 0.10587456 0.09598886],\n",
      "    |     Bias [0.18253214 0.18183448 0.18231924 0.18196056 0.18242897]\n",
      "Iterate 359: Cost 0.002823232644035413,   \n",
      "  |    Weight  [0.08855003 0.10479843 0.09433678 0.10589047 0.09597837],\n",
      "    |     Bias [0.18299691 0.18229742 0.18278349 0.18242384 0.18289352]\n",
      "Iterate 360: Cost 0.00282215475848811,   \n",
      "  |    Weight  [0.08851918 0.104811   0.09432144 0.10590638 0.09596789],\n",
      "    |     Bias [0.18346159 0.18276026 0.18324765 0.18288703 0.18335797]\n",
      "Iterate 361: Cost 0.0028210773047347556,   \n",
      "  |    Weight  [0.08848833 0.10482356 0.0943061  0.10592229 0.09595742],\n",
      "    |     Bias [0.18392618 0.18322301 0.18371171 0.18335012 0.18382232]\n",
      "Iterate 362: Cost 0.002820000282602345,   \n",
      "  |    Weight  [0.0884575  0.10483613 0.09429077 0.10593819 0.09594694],\n",
      "    |     Bias [0.18439067 0.18368567 0.18417569 0.18381313 0.18428659]\n",
      "Iterate 363: Cost 0.002818923691917943,   \n",
      "  |    Weight  [0.08842666 0.10484868 0.09427543 0.10595409 0.09593648],\n",
      "    |     Bias [0.18485507 0.18414824 0.18463956 0.18427604 0.18475076]\n",
      "Iterate 364: Cost 0.0028178475325086848,   \n",
      "  |    Weight  [0.08839584 0.10486124 0.0942601  0.10596999 0.09592601],\n",
      "    |     Bias [0.18531938 0.18461071 0.18510335 0.18473886 0.18521484]\n",
      "Iterate 365: Cost 0.0028167718042017738,   \n",
      "  |    Weight  [0.08836502 0.10487378 0.09424477 0.10598588 0.09591555],\n",
      "    |     Bias [0.18578359 0.1850731  0.18556704 0.18520158 0.18567883]\n",
      "Iterate 366: Cost 0.0028156965068244816,   \n",
      "  |    Weight  [0.0883342  0.10488633 0.09422944 0.10600178 0.09590509],\n",
      "    |     Bias [0.18624771 0.18553538 0.18603064 0.18566422 0.18614272]\n",
      "Iterate 367: Cost 0.002814621640204152,   \n",
      "  |    Weight  [0.08830339 0.10489887 0.09421412 0.10601767 0.09589464],\n",
      "    |     Bias [0.18671174 0.18599758 0.18649415 0.18612676 0.18660652]\n",
      "Iterate 368: Cost 0.0028135472041681967,   \n",
      "  |    Weight  [0.08827259 0.1049114  0.0941988  0.10603355 0.09588419],\n",
      "    |     Bias [0.18717567 0.18645968 0.18695757 0.18658921 0.18707023]\n",
      "Iterate 369: Cost 0.0028124731985440946,   \n",
      "  |    Weight  [0.08824179 0.10492394 0.09418347 0.10604944 0.09587375],\n",
      "    |     Bias [0.18763951 0.18692169 0.18742089 0.18705156 0.18753385]\n",
      "Iterate 370: Cost 0.002811399623159396,   \n",
      "  |    Weight  [0.088211   0.10493646 0.09416816 0.10606532 0.0958633 ],\n",
      "    |     Bias [0.18810326 0.18738361 0.18788412 0.18751382 0.18799737]\n",
      "Iterate 371: Cost 0.0028103264778417195,   \n",
      "  |    Weight  [0.08818021 0.10494899 0.09415284 0.1060812  0.09585287],\n",
      "    |     Bias [0.18856691 0.18784544 0.18834726 0.187976   0.1884608 ]\n",
      "Iterate 372: Cost 0.0028092537624187534,   \n",
      "  |    Weight  [0.08814943 0.1049615  0.09413753 0.10609708 0.09584243],\n",
      "    |     Bias [0.18903048 0.18830717 0.1888103  0.18843807 0.18892413]\n",
      "Iterate 373: Cost 0.002808181476718254,   \n",
      "  |    Weight  [0.08811866 0.10497402 0.09412222 0.10611295 0.095832  ],\n",
      "    |     Bias [0.18949394 0.18876881 0.18927325 0.18890006 0.18938738]\n",
      "Iterate 374: Cost 0.0028071096205680474,   \n",
      "  |    Weight  [0.08808789 0.10498653 0.09410691 0.10612882 0.09582158],\n",
      "    |     Bias [0.18995732 0.18923036 0.18973611 0.18936195 0.18985053]\n",
      "Iterate 375: Cost 0.0028060381937960273,   \n",
      "  |    Weight  [0.08805712 0.10499903 0.0940916  0.10614469 0.09581116],\n",
      "    |     Bias [0.1904206  0.18969182 0.19019888 0.18982375 0.19031359]\n",
      "Iterate 376: Cost 0.002804967196230159,   \n",
      "  |    Weight  [0.08802637 0.10501154 0.0940763  0.10616055 0.09580074],\n",
      "    |     Bias [0.19088379 0.19015318 0.19066155 0.19028546 0.19077655]\n",
      "Iterate 377: Cost 0.002803896627698474,   \n",
      "  |    Weight  [0.08799561 0.10502403 0.094061   0.10617642 0.09579033],\n",
      "    |     Bias [0.19134689 0.19061445 0.19112413 0.19074708 0.19123943]\n",
      "Iterate 378: Cost 0.0028028264880290755,   \n",
      "  |    Weight  [0.08796487 0.10503653 0.0940457  0.10619228 0.09577992],\n",
      "    |     Bias [0.19180989 0.19107563 0.19158662 0.1912086  0.19170221]\n",
      "Iterate 379: Cost 0.002801756777050133,   \n",
      "  |    Weight  [0.08793412 0.10504901 0.0940304  0.10620813 0.09576951],\n",
      "    |     Bias [0.1922728  0.19153672 0.19204901 0.19167003 0.19216489]\n",
      "Iterate 380: Cost 0.0028006874945898847,   \n",
      "  |    Weight  [0.08790339 0.1050615  0.09401511 0.10622399 0.09575911],\n",
      "    |     Bias [0.19273562 0.19199771 0.19251132 0.19213137 0.19262749]\n",
      "Iterate 381: Cost 0.0027996186404766394,   \n",
      "  |    Weight  [0.08787266 0.10507398 0.09399981 0.10623984 0.09574871],\n",
      "    |     Bias [0.19319834 0.19245862 0.19297353 0.19259261 0.19308999]\n",
      "Iterate 382: Cost 0.0027985502145387755,   \n",
      "  |    Weight  [0.08784193 0.10508645 0.09398452 0.10625569 0.09573831],\n",
      "    |     Bias [0.19366097 0.19291943 0.19343564 0.19305377 0.1935524 ]\n",
      "Iterate 383: Cost 0.0027974822166047363,   \n",
      "  |    Weight  [0.08781122 0.10509892 0.09396924 0.10627154 0.09572792],\n",
      "    |     Bias [0.19412351 0.19338014 0.19389767 0.19351483 0.19401472]\n",
      "Iterate 384: Cost 0.0027964146465030383,   \n",
      "  |    Weight  [0.0877805  0.10511139 0.09395395 0.10628738 0.09571754],\n",
      "    |     Bias [0.19458596 0.19384077 0.1943596  0.1939758  0.19447694]\n",
      "Iterate 385: Cost 0.002795347504062264,   \n",
      "  |    Weight  [0.08774979 0.10512385 0.09393867 0.10630322 0.09570715],\n",
      "    |     Bias [0.19504831 0.1943013  0.19482144 0.19443668 0.19493908]\n",
      "Iterate 386: Cost 0.002794280789111065,   \n",
      "  |    Weight  [0.08771909 0.10513631 0.09392339 0.10631906 0.09569677],\n",
      "    |     Bias [0.19551057 0.19476174 0.19528319 0.19489746 0.19540112]\n",
      "Iterate 387: Cost 0.0027932145014781602,   \n",
      "  |    Weight  [0.0876884  0.10514877 0.09390811 0.1063349  0.0956864 ],\n",
      "    |     Bias [0.19597274 0.19522209 0.19574485 0.19535815 0.19586306]\n",
      "Iterate 388: Cost 0.002792148640992342,   \n",
      "  |    Weight  [0.08765771 0.10516122 0.09389283 0.10635073 0.09567603],\n",
      "    |     Bias [0.19643481 0.19568235 0.19620641 0.19581875 0.19632492]\n",
      "Iterate 389: Cost 0.002791083207482465,   \n",
      "  |    Weight  [0.08762702 0.10517366 0.09387756 0.10636656 0.09566566],\n",
      "    |     Bias [0.19689679 0.19614251 0.19666788 0.19627926 0.19678668]\n",
      "Iterate 390: Cost 0.002790018200777458,   \n",
      "  |    Weight  [0.08759634 0.1051861  0.09386229 0.10638239 0.0956553 ],\n",
      "    |     Bias [0.19735868 0.19660258 0.19712926 0.19673968 0.19724835]\n",
      "Iterate 391: Cost 0.0027889536207063134,   \n",
      "  |    Weight  [0.08756567 0.10519854 0.09384702 0.10639821 0.09564494],\n",
      "    |     Bias [0.19782048 0.19706256 0.19759055 0.1972     0.19770993]\n",
      "Iterate 392: Cost 0.002787889467098097,   \n",
      "  |    Weight  [0.087535   0.10521097 0.09383175 0.10641403 0.09563458],\n",
      "    |     Bias [0.19828218 0.19752245 0.19805174 0.19766023 0.19817141]\n",
      "Iterate 393: Cost 0.002786825739781939,   \n",
      "  |    Weight  [0.08750434 0.1052234  0.09381649 0.10642985 0.09562423],\n",
      "    |     Bias [0.19874379 0.19798225 0.19851284 0.19812037 0.1986328 ]\n",
      "Iterate 394: Cost 0.0027857624385870393,   \n",
      "  |    Weight  [0.08747368 0.10523582 0.09380123 0.10644567 0.09561388],\n",
      "    |     Bias [0.19920531 0.19844195 0.19897385 0.19858042 0.19909411]\n",
      "Iterate 395: Cost 0.0027846995633426675,   \n",
      "  |    Weight  [0.08744303 0.10524824 0.09378597 0.10646149 0.09560354],\n",
      "    |     Bias [0.19966673 0.19890156 0.19943477 0.19904037 0.19955531]\n",
      "Iterate 396: Cost 0.00278363711387816,   \n",
      "  |    Weight  [0.08741238 0.10526066 0.09377071 0.1064773  0.0955932 ],\n",
      "    |     Bias [0.20012807 0.19936108 0.19989559 0.19950024 0.20001643]\n",
      "Iterate 397: Cost 0.0027825750900229234,   \n",
      "  |    Weight  [0.08738174 0.10527307 0.09375546 0.10649311 0.09558286],\n",
      "    |     Bias [0.20058931 0.19982051 0.20035633 0.19996001 0.20047745]\n",
      "Iterate 398: Cost 0.0027815134916064307,   \n",
      "  |    Weight  [0.08735111 0.10528548 0.0937402  0.10650891 0.09557253],\n",
      "    |     Bias [0.20105045 0.20027985 0.20081697 0.20041969 0.20093838]\n",
      "Iterate 399: Cost 0.0027804523184582243,   \n",
      "  |    Weight  [0.08732048 0.10529788 0.09372495 0.10652472 0.0955622 ],\n",
      "    |     Bias [0.20151151 0.20073909 0.20127751 0.20087927 0.20139922]\n",
      "Iterate 400: Cost 0.0027793915704079153,   \n",
      "  |    Weight  [0.08728986 0.10531028 0.09370971 0.10654052 0.09555188],\n",
      "    |     Bias [0.20197247 0.20119824 0.20173797 0.20133877 0.20185997]\n"
     ]
    }
   ],
   "source": [
    "y1 = y_train.iloc[:,1:2].values.reshape(-1,1)\n",
    "equation2 =  gradient_descent(x,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterate 1: Cost 0.37116024769621436,   \n",
      "  |    Weight  [0.09964797 0.10013634 0.09981547 0.10013208 0.09973174],\n",
      "    |     Bias [0.01512058 0.01511851 0.01511991 0.01511887 0.01512023]\n",
      "Iterate 2: Cost 0.371028942292998,   \n",
      "  |    Weight  [0.09929601 0.10027263 0.09963096 0.10026413 0.09946353],\n",
      "    |     Bias [0.02024013 0.020236   0.02023879 0.02023672 0.02023943]\n",
      "Iterate 3: Cost 0.37089768949236895,   \n",
      "  |    Weight  [0.0989441  0.10040887 0.09944648 0.10039615 0.09919536],\n",
      "    |     Bias [0.02535865 0.02535247 0.02535665 0.02535355 0.02535761]\n",
      "Iterate 4: Cost 0.3707664892732514,   \n",
      "  |    Weight  [0.09859226 0.10054507 0.09926202 0.10052814 0.09892724],\n",
      "    |     Bias [0.03047615 0.03046791 0.03047349 0.03046935 0.03047476]\n",
      "Iterate 5: Cost 0.3706353416145778,   \n",
      "  |    Weight  [0.09824049 0.10068122 0.09907759 0.1006601  0.09865916],\n",
      "    |     Bias [0.03559261 0.03558232 0.0355893  0.03558412 0.03559089]\n",
      "Iterate 6: Cost 0.370504246495289,   \n",
      "  |    Weight  [0.09788877 0.10081732 0.09889319 0.10079204 0.09839113],\n",
      "    |     Bias [0.04070805 0.04069571 0.04070408 0.04069787 0.04070599]\n",
      "Iterate 7: Cost 0.3703732038943343,   \n",
      "  |    Weight  [0.09753712 0.10095337 0.09870881 0.10092394 0.09812314],\n",
      "    |     Bias [0.04582247 0.04580808 0.04581785 0.0458106  0.04582006]\n",
      "Iterate 8: Cost 0.37024221379067146,   \n",
      "  |    Weight  [0.09718553 0.10108937 0.09852446 0.10105581 0.0978552 ],\n",
      "    |     Bias [0.05093585 0.05091943 0.05093059 0.05092231 0.05093311]\n",
      "Iterate 9: Cost 0.37011127616326667,   \n",
      "  |    Weight  [0.096834   0.10122533 0.09834013 0.10118766 0.0975873 ],\n",
      "    |     Bias [0.05604821 0.05602975 0.0560423  0.05603299 0.05604514]\n",
      "Iterate 10: Cost 0.36998039099109464,   \n",
      "  |    Weight  [0.09648253 0.10136124 0.09815583 0.10131947 0.09731945],\n",
      "    |     Bias [0.06115954 0.06113904 0.06115299 0.06114265 0.06115614]\n",
      "Iterate 11: Cost 0.36984955825313826,   \n",
      "  |    Weight  [0.09613113 0.1014971  0.09797155 0.10145126 0.09705164],\n",
      "    |     Bias [0.06626985 0.06624732 0.06626266 0.06625129 0.06626611]\n",
      "Iterate 12: Cost 0.369718777928389,   \n",
      "  |    Weight  [0.09577979 0.10163292 0.09778731 0.10158301 0.09678388],\n",
      "    |     Bias [0.07137913 0.07135457 0.07137131 0.0713589  0.07137506]\n",
      "Iterate 13: Cost 0.3695880499958467,   \n",
      "  |    Weight  [0.09542851 0.10176869 0.09760308 0.10171474 0.09651616],\n",
      "    |     Bias [0.07648738 0.0764608  0.07647893 0.0764655  0.07648299]\n",
      "Iterate 14: Cost 0.3694573744345197,   \n",
      "  |    Weight  [0.0950773  0.10190441 0.09741889 0.10184644 0.09624849],\n",
      "    |     Bias [0.08159461 0.081566   0.08158553 0.08157107 0.0815899 ]\n",
      "Iterate 15: Cost 0.3693267512234247,   \n",
      "  |    Weight  [0.09472614 0.10204008 0.09723472 0.10197811 0.09598086],\n",
      "    |     Bias [0.08670081 0.08667019 0.08669111 0.08667562 0.08669578]\n",
      "Iterate 16: Cost 0.3691961803415869,   \n",
      "  |    Weight  [0.09437505 0.1021757  0.09705057 0.10210974 0.09571328],\n",
      "    |     Bias [0.09180599 0.09177335 0.09179567 0.09177914 0.09180063]\n",
      "Iterate 17: Cost 0.36906566176803957,   \n",
      "  |    Weight  [0.09402403 0.10231128 0.09686645 0.10224135 0.09544574],\n",
      "    |     Bias [0.09691014 0.09687549 0.09689921 0.09688165 0.09690447]\n",
      "Iterate 18: Cost 0.36893519548182485,   \n",
      "  |    Weight  [0.09367306 0.10244681 0.09668236 0.10237293 0.09517825],\n",
      "    |     Bias [0.10201327 0.1019766  0.10200172 0.10198313 0.10200728]\n",
      "Iterate 19: Cost 0.3688047814619929,   \n",
      "  |    Weight  [0.09332216 0.10258229 0.09649829 0.10250449 0.0949108 ],\n",
      "    |     Bias [0.10711537 0.1070767  0.10710321 0.1070836  0.10710907]\n",
      "Iterate 20: Cost 0.3686744196876024,   \n",
      "  |    Weight  [0.09297131 0.10271773 0.09631425 0.10263601 0.0946434 ],\n",
      "    |     Bias [0.11221645 0.11217578 0.11220368 0.11218304 0.11220983]\n",
      "Iterate 21: Cost 0.3685441101377206,   \n",
      "  |    Weight  [0.09262054 0.10285311 0.09613024 0.1027675  0.09437604],\n",
      "    |     Bias [0.1173165  0.11727383 0.11730313 0.11728146 0.11730958]\n",
      "Iterate 22: Cost 0.36841385279142286,   \n",
      "  |    Weight  [0.09226982 0.10298845 0.09594625 0.10289896 0.09410873],\n",
      "    |     Bias [0.12241553 0.12237086 0.12240156 0.12237886 0.1224083 ]\n",
      "Iterate 23: Cost 0.3682836476277929,   \n",
      "  |    Weight  [0.09191916 0.10312374 0.09576229 0.1030304  0.09384146],\n",
      "    |     Bias [0.12751354 0.12746688 0.12749897 0.12747524 0.127506  ]\n",
      "Iterate 24: Cost 0.3681534946259234,   \n",
      "  |    Weight  [0.09156857 0.10325899 0.09557835 0.1031618  0.09357424],\n",
      "    |     Bias [0.13261052 0.13256187 0.13259536 0.1325706  0.13260268]\n",
      "Iterate 25: Cost 0.3680233937649145,   \n",
      "  |    Weight  [0.09121804 0.10339419 0.09539444 0.10329318 0.09330706],\n",
      "    |     Bias [0.13770648 0.13765584 0.13769073 0.13766495 0.13769833]\n",
      "Iterate 26: Cost 0.3678933450238754,   \n",
      "  |    Weight  [0.09086758 0.10352934 0.09521055 0.10342452 0.09303993],\n",
      "    |     Bias [0.14280141 0.14274879 0.14278507 0.14275827 0.14279297]\n",
      "Iterate 27: Cost 0.3677633483819234,   \n",
      "  |    Weight  [0.09051717 0.10366444 0.09502669 0.10355584 0.09277284],\n",
      "    |     Bias [0.14789532 0.14784073 0.1478784  0.14785057 0.14788658]\n",
      "Iterate 28: Cost 0.3676334038181844,   \n",
      "  |    Weight  [0.09016683 0.10379949 0.09484286 0.10368713 0.0925058 ],\n",
      "    |     Bias [0.15298821 0.15293164 0.15297071 0.15294185 0.15297918]\n",
      "Iterate 29: Cost 0.3675035113117923,   \n",
      "  |    Weight  [0.08981655 0.1039345  0.09465905 0.10381838 0.0922388 ],\n",
      "    |     Bias [0.15808008 0.15802153 0.158062   0.15803212 0.15807075]\n",
      "Iterate 30: Cost 0.3673736708418897,   \n",
      "  |    Weight  [0.08946633 0.10406946 0.09447527 0.10394961 0.09197185],\n",
      "    |     Bias [0.16317093 0.16311041 0.16315227 0.16312136 0.1631613 ]\n",
      "Iterate 31: Cost 0.3672438823876272,   \n",
      "  |    Weight  [0.08911617 0.10420437 0.09429151 0.10408081 0.09170494],\n",
      "    |     Bias [0.16826075 0.16819826 0.16824152 0.16820959 0.16825083]\n",
      "Iterate 32: Cost 0.36711414592816416,   \n",
      "  |    Weight  [0.08876608 0.10433924 0.09410778 0.10421198 0.09143808],\n",
      "    |     Bias [0.17334955 0.1732851  0.17332976 0.1732968  0.17333934]\n",
      "Iterate 33: Cost 0.36698446144266805,   \n",
      "  |    Weight  [0.08841604 0.10447406 0.09392408 0.10434313 0.09117126],\n",
      "    |     Bias [0.17843733 0.17837092 0.17841697 0.17838299 0.17842683]\n",
      "Iterate 34: Cost 0.3668548289103146,   \n",
      "  |    Weight  [0.08806607 0.10460883 0.0937404  0.10447424 0.09090449],\n",
      "    |     Bias [0.18352408 0.18345572 0.18350316 0.18346816 0.18351331]\n",
      "Iterate 35: Cost 0.36672524831028824,   \n",
      "  |    Weight  [0.08771617 0.10474355 0.09355675 0.10460532 0.09063776],\n",
      "    |     Bias [0.18860982 0.1885395  0.18858834 0.18855232 0.18859876]\n",
      "Iterate 36: Cost 0.3665957196217813,   \n",
      "  |    Weight  [0.08736632 0.10487823 0.09337312 0.10473637 0.09037108],\n",
      "    |     Bias [0.19369453 0.19362226 0.1936725  0.19363546 0.19368319]\n",
      "Iterate 37: Cost 0.3664662428239948,   \n",
      "  |    Weight  [0.08701654 0.10501286 0.09318952 0.1048674  0.09010444],\n",
      "    |     Bias [0.19877822 0.19870401 0.19875564 0.19871758 0.19876661]\n",
      "Iterate 38: Cost 0.3663368178961379,   \n",
      "  |    Weight  [0.08666682 0.10514744 0.09300594 0.10499839 0.08983784],\n",
      "    |     Bias [0.2038609  0.20378473 0.20383777 0.20379868 0.203849  ]\n",
      "Iterate 39: Cost 0.3662074448174282,   \n",
      "  |    Weight  [0.08631716 0.10528197 0.09282239 0.10512936 0.0895713 ],\n",
      "    |     Bias [0.20894255 0.20886444 0.20891887 0.20887877 0.20893038]\n",
      "Iterate 40: Cost 0.36607812356709146,   \n",
      "  |    Weight  [0.08596756 0.10541646 0.09263887 0.1052603  0.08930479],\n",
      "    |     Bias [0.21402318 0.21394314 0.21399896 0.21395783 0.21401074]\n",
      "Iterate 41: Cost 0.365948854124362,   \n",
      "  |    Weight  [0.08561803 0.1055509  0.09245537 0.1053912  0.08903833],\n",
      "    |     Bias [0.21910279 0.21902081 0.21907804 0.21903589 0.21909008]\n",
      "Iterate 42: Cost 0.3658196364684822,   \n",
      "  |    Weight  [0.08526855 0.10568529 0.0922719  0.10552208 0.08877192],\n",
      "    |     Bias [0.22418138 0.22409747 0.22415609 0.22411292 0.2241684 ]\n",
      "Iterate 43: Cost 0.3656904705787029,   \n",
      "  |    Weight  [0.08491914 0.10581963 0.09208845 0.10565293 0.08850555],\n",
      "    |     Bias [0.22925895 0.22917312 0.22923313 0.22918894 0.2292457 ]\n",
      "Iterate 44: Cost 0.3655613564342834,   \n",
      "  |    Weight  [0.08456979 0.10595393 0.09190503 0.10578375 0.08823922],\n",
      "    |     Bias [0.2343355  0.23424774 0.23430916 0.23426395 0.23432199]\n",
      "Iterate 45: Cost 0.36543229401449107,   \n",
      "  |    Weight  [0.08422051 0.10608818 0.09172164 0.10591454 0.08797294],\n",
      "    |     Bias [0.23941104 0.23932135 0.23938416 0.23933794 0.23939726]\n",
      "Iterate 46: Cost 0.3653032832986016,   \n",
      "  |    Weight  [0.08387128 0.10622238 0.09153827 0.10604531 0.08770671],\n",
      "    |     Bias [0.24448555 0.24439395 0.24445816 0.24441091 0.24447151]\n",
      "Iterate 47: Cost 0.3651743242658993,   \n",
      "  |    Weight  [0.08352212 0.10635654 0.09135492 0.10617604 0.08744051],\n",
      "    |     Bias [0.24955904 0.24946553 0.24953113 0.24948287 0.24954475]\n",
      "Iterate 48: Cost 0.3650454168956762,   \n",
      "  |    Weight  [0.08317302 0.10649065 0.09117161 0.10630674 0.08717437],\n",
      "    |     Bias [0.25463152 0.25453609 0.25460309 0.25455381 0.25461696]\n",
      "Iterate 49: Cost 0.3649165611672332,   \n",
      "  |    Weight  [0.08282398 0.10662471 0.09098831 0.10643742 0.08690827],\n",
      "    |     Bias [0.25970297 0.25960564 0.25967404 0.25962374 0.25968817]\n",
      "Iterate 50: Cost 0.36478775705987904,   \n",
      "  |    Weight  [0.082475   0.10675872 0.09080505 0.10656806 0.08664221],\n",
      "    |     Bias [0.26477341 0.26467417 0.26474397 0.26469265 0.26475835]\n",
      "Iterate 51: Cost 0.3646590045529312,   \n",
      "  |    Weight  [0.08212609 0.10689269 0.09062181 0.10669868 0.0863762 ],\n",
      "    |     Bias [0.26984283 0.26974169 0.26981288 0.26976055 0.26982752]\n",
      "Iterate 52: Cost 0.36453030362571504,   \n",
      "  |    Weight  [0.08177723 0.10702661 0.09043859 0.10682927 0.08611023],\n",
      "    |     Bias [0.27491124 0.27480819 0.27488078 0.27482744 0.27489567]\n",
      "Iterate 53: Cost 0.3644016542575646,   \n",
      "  |    Weight  [0.08142844 0.10716048 0.09025541 0.10695982 0.08584431],\n",
      "    |     Bias [0.27997862 0.27987368 0.27994767 0.27989331 0.27996281]\n",
      "Iterate 54: Cost 0.3642730564278218,   \n",
      "  |    Weight  [0.08107971 0.10729431 0.09007224 0.10709035 0.08557843],\n",
      "    |     Bias [0.28504499 0.28493816 0.28501354 0.28495816 0.28502893]\n",
      "Iterate 55: Cost 0.364144510115837,   \n",
      "  |    Weight  [0.08073105 0.10742809 0.0898891  0.10722085 0.0853126 ],\n",
      "    |     Bias [0.29011034 0.29000162 0.2900784  0.290022   0.29009404]\n",
      "Iterate 56: Cost 0.36401601530096894,   \n",
      "  |    Weight  [0.08038244 0.10756182 0.08970599 0.10735132 0.08504681],\n",
      "    |     Bias [0.29517467 0.29506406 0.29514224 0.29508483 0.29515813]\n",
      "Iterate 57: Cost 0.3638875719625845,   \n",
      "  |    Weight  [0.0800339  0.1076955  0.08952291 0.10748177 0.08478106],\n",
      "    |     Bias [0.30023799 0.3001255  0.30020507 0.30014665 0.3002212 ]\n",
      "Iterate 58: Cost 0.3637591800800588,   \n",
      "  |    Weight  [0.07968542 0.10782914 0.08933985 0.10761218 0.08451537],\n",
      "    |     Bias [0.30530028 0.30518592 0.30526688 0.30520745 0.30528327]\n",
      "Iterate 59: Cost 0.3636308396327753,   \n",
      "  |    Weight  [0.079337   0.10796273 0.08915681 0.10774256 0.08424971],\n",
      "    |     Bias [0.31036157 0.31024532 0.31032769 0.31026724 0.31034431]\n",
      "Iterate 60: Cost 0.3635025506001259,   \n",
      "  |    Weight  [0.07898864 0.10809627 0.0889738  0.10787292 0.0839841 ],\n",
      "    |     Bias [0.31542183 0.31530372 0.31538748 0.31532602 0.31540435]\n",
      "Iterate 61: Cost 0.36337431296151035,   \n",
      "  |    Weight  [0.07864034 0.10822977 0.08879082 0.10800324 0.08371853],\n",
      "    |     Bias [0.32048108 0.3203611  0.32044625 0.32038379 0.32046336]\n",
      "Iterate 62: Cost 0.36324612669633694,   \n",
      "  |    Weight  [0.07829211 0.10836322 0.08860786 0.10813354 0.08345301],\n",
      "    |     Bias [0.32553932 0.32541746 0.32550402 0.32544054 0.32552137]\n",
      "Iterate 63: Cost 0.36311799178402215,   \n",
      "  |    Weight  [0.07794394 0.10849662 0.08842493 0.10826381 0.08318754],\n",
      "    |     Bias [0.33059654 0.33047282 0.33056077 0.33049628 0.33057836]\n",
      "Iterate 64: Cost 0.36298990820399074,   \n",
      "  |    Weight  [0.07759583 0.10862997 0.08824203 0.10839404 0.08292211],\n",
      "    |     Bias [0.33565274 0.33552716 0.33561651 0.33555101 0.33563433]\n",
      "Iterate 65: Cost 0.3628618759356756,   \n",
      "  |    Weight  [0.07724778 0.10876328 0.08805915 0.10852425 0.08265672],\n",
      "    |     Bias [0.34070793 0.34058049 0.34067124 0.34060472 0.3406893 ]\n",
      "Iterate 66: Cost 0.36273389495851793,   \n",
      "  |    Weight  [0.07689979 0.10889654 0.08787629 0.10865443 0.08239138],\n",
      "    |     Bias [0.3457621  0.34563281 0.34572495 0.34565743 0.34574325]\n",
      "Iterate 67: Cost 0.3626059652519673,   \n",
      "  |    Weight  [0.07655186 0.10902975 0.08769346 0.10878458 0.08212608],\n",
      "    |     Bias [0.35081526 0.35068412 0.35077766 0.35070912 0.35079619]\n",
      "Iterate 68: Cost 0.3624780867954811,   \n",
      "  |    Weight  [0.076204   0.10916292 0.08751066 0.10891471 0.08186083],\n",
      "    |     Bias [0.3558674  0.35573441 0.35582935 0.35575981 0.35584811]\n",
      "Iterate 69: Cost 0.36235025956852557,   \n",
      "  |    Weight  [0.0758562  0.10929604 0.08732788 0.1090448  0.08159562],\n",
      "    |     Bias [0.36091853 0.3607837  0.36088003 0.36080948 0.36089902]\n",
      "Iterate 70: Cost 0.3622224835505747,   \n",
      "  |    Weight  [0.07550846 0.10942911 0.08714513 0.10917486 0.08133045],\n",
      "    |     Bias [0.36596864 0.36583197 0.3659297  0.36585814 0.36594892]\n",
      "Iterate 71: Cost 0.36209475872111074,   \n",
      "  |    Weight  [0.07516078 0.10956213 0.0869624  0.1093049  0.08106533],\n",
      "    |     Bias [0.37101774 0.37087923 0.37097836 0.37090579 0.37099781]\n",
      "Iterate 72: Cost 0.3619670850596244,   \n",
      "  |    Weight  [0.07481316 0.10969511 0.0867797  0.10943491 0.08080026],\n",
      "    |     Bias [0.37606583 0.37592549 0.37602601 0.37595243 0.37604569]\n",
      "Iterate 73: Cost 0.3618394625456144,   \n",
      "  |    Weight  [0.07446561 0.10982804 0.08659703 0.10956488 0.08053523],\n",
      "    |     Bias [0.3811129  0.38097073 0.38107265 0.38099807 0.38109255]\n",
      "Iterate 74: Cost 0.36171189115858776,   \n",
      "  |    Weight  [0.07411811 0.10996093 0.08641438 0.10969483 0.08027024],\n",
      "    |     Bias [0.38615896 0.38601496 0.38611828 0.38604269 0.3861384 ]\n",
      "Iterate 75: Cost 0.3615843708780598,   \n",
      "  |    Weight  [0.07377068 0.11009376 0.08623175 0.10982475 0.0800053 ],\n",
      "    |     Bias [0.39120401 0.39105818 0.3911629  0.3910863  0.39118324]\n",
      "Iterate 76: Cost 0.3614569016835538,   \n",
      "  |    Weight  [0.07342331 0.11022655 0.08604915 0.10995464 0.0797404 ],\n",
      "    |     Bias [0.39624804 0.39610039 0.39620651 0.3961289  0.39622707]\n",
      "Iterate 77: Cost 0.36132948355460154,   \n",
      "  |    Weight  [0.073076   0.1103593  0.08586658 0.1100845  0.07947555],\n",
      "    |     Bias [0.40129106 0.40114159 0.40124911 0.40117049 0.40126989]\n",
      "Iterate 78: Cost 0.3612021164707428,   \n",
      "  |    Weight  [0.07272876 0.11049199 0.08568403 0.11021433 0.07921074],\n",
      "    |     Bias [0.40633307 0.40618178 0.4062907  0.40621108 0.4063117 ]\n",
      "Iterate 79: Cost 0.36107480041152545,   \n",
      "  |    Weight  [0.07238157 0.11062464 0.08550151 0.11034414 0.07894598],\n",
      "    |     Bias [0.41137406 0.41122097 0.41133128 0.41125065 0.4113525 ]\n",
      "Iterate 80: Cost 0.3609475353565059,   \n",
      "  |    Weight  [0.07203445 0.11075725 0.08531902 0.11047391 0.07868126],\n",
      "    |     Bias [0.41641405 0.41625914 0.41637085 0.41628922 0.41639229]\n",
      "Iterate 81: Cost 0.3608203212852486,   \n",
      "  |    Weight  [0.07168739 0.1108898  0.08513655 0.11060366 0.07841658],\n",
      "    |     Bias [0.42145302 0.42129631 0.42140941 0.42132678 0.42143106]\n",
      "Iterate 82: Cost 0.36069315817732595,   \n",
      "  |    Weight  [0.07134039 0.11102231 0.0849541  0.11073337 0.07815195],\n",
      "    |     Bias [0.42649098 0.42633246 0.42644696 0.42636333 0.42646883]\n",
      "Iterate 83: Cost 0.36056604601231884,   \n",
      "  |    Weight  [0.07099345 0.11115477 0.08477168 0.11086306 0.07788737],\n",
      "    |     Bias [0.43152792 0.43136761 0.43148351 0.43139887 0.43150559]\n",
      "Iterate 84: Cost 0.36043898476981634,   \n",
      "  |    Weight  [0.07064657 0.11128719 0.08458929 0.11099272 0.07762282],\n",
      "    |     Bias [0.43656386 0.43640175 0.43651905 0.4364334  0.43654134]\n",
      "Iterate 85: Cost 0.3603119744294154,   \n",
      "  |    Weight  [0.07029976 0.11141955 0.08440692 0.11112235 0.07735833],\n",
      "    |     Bias [0.44159879 0.44143488 0.44155357 0.44146693 0.44157608]\n",
      "Iterate 86: Cost 0.36018501497072153,   \n",
      "  |    Weight  [0.069953   0.11155188 0.08422458 0.11125195 0.07709387],\n",
      "    |     Bias [0.4466327  0.44646701 0.4465871  0.44649945 0.44660981]\n",
      "Iterate 87: Cost 0.3600581063733481,   \n",
      "  |    Weight  [0.06960631 0.11168415 0.08404226 0.11138152 0.07682947],\n",
      "    |     Bias [0.4516656  0.45149812 0.45161961 0.45153096 0.45164253]\n",
      "Iterate 88: Cost 0.3599312486169169,   \n",
      "  |    Weight  [0.06925968 0.11181638 0.08385997 0.11151107 0.0765651 ],\n",
      "    |     Bias [0.45669749 0.45652823 0.45665112 0.45656147 0.45667424]\n",
      "Iterate 89: Cost 0.3598044416810576,   \n",
      "  |    Weight  [0.06891311 0.11194856 0.08367771 0.11164058 0.07630078],\n",
      "    |     Bias [0.46172838 0.46155733 0.46168162 0.46159096 0.46170494]\n",
      "Iterate 90: Cost 0.3596776855454082,   \n",
      "  |    Weight  [0.0685666  0.11208069 0.08349547 0.11177007 0.07603651],\n",
      "    |     Bias [0.46675825 0.46658543 0.46671111 0.46661946 0.46673464]\n",
      "Iterate 91: Cost 0.3595509801896149,   \n",
      "  |    Weight  [0.06822015 0.11221278 0.08331325 0.11189952 0.07577228],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |     Bias [0.47178711 0.47161252 0.47173959 0.47164694 0.47176333]\n",
      "Iterate 92: Cost 0.3594243255933321,   \n",
      "  |    Weight  [0.06787377 0.11234482 0.08313106 0.11202895 0.07550809],\n",
      "    |     Bias [0.47681496 0.4766386  0.47676707 0.47667342 0.47679101]\n",
      "Iterate 93: Cost 0.35929772173622204,   \n",
      "  |    Weight  [0.06752744 0.11247681 0.0829489  0.11215835 0.07524395],\n",
      "    |     Bias [0.4818418  0.48166367 0.48179354 0.48169889 0.48181768]\n",
      "Iterate 94: Cost 0.35917116859795556,   \n",
      "  |    Weight  [0.06718118 0.11260876 0.08276676 0.11228772 0.07497985],\n",
      "    |     Bias [0.48686764 0.48668774 0.48681901 0.48672336 0.48684334]\n",
      "Iterate 95: Cost 0.3590446661582113,   \n",
      "  |    Weight  [0.06683498 0.11274066 0.08258465 0.11241706 0.0747158 ],\n",
      "    |     Bias [0.49189246 0.4917108  0.49184347 0.49174682 0.491868  ]\n",
      "Iterate 96: Cost 0.35891821439667604,   \n",
      "  |    Weight  [0.06648884 0.11287251 0.08240256 0.11254637 0.07445179],\n",
      "    |     Bias [0.49691628 0.49673286 0.49686693 0.49676928 0.49689165]\n",
      "Iterate 97: Cost 0.358791813293045,   \n",
      "  |    Weight  [0.06614276 0.11300432 0.0822205  0.11267565 0.07418782],\n",
      "    |     Bias [0.50193908 0.50175391 0.50188937 0.50179073 0.50191429]\n",
      "Iterate 98: Cost 0.3586654628270211,   \n",
      "  |    Weight  [0.06579674 0.11313608 0.08203847 0.11280491 0.0739239 ],\n",
      "    |     Bias [0.50696088 0.50677396 0.50691082 0.50681117 0.50693593]\n",
      "Iterate 99: Cost 0.3585391629783159,   \n",
      "  |    Weight  [0.06545079 0.11326779 0.08185646 0.11293413 0.07366002],\n",
      "    |     Bias [0.51198167 0.511793   0.51193126 0.51183061 0.51195656]\n",
      "Iterate 100: Cost 0.3584129137266487,   \n",
      "  |    Weight  [0.06510489 0.11339946 0.08167447 0.11306333 0.07339619],\n",
      "    |     Bias [0.51700145 0.51681103 0.51695069 0.51684905 0.51697618]\n",
      "Iterate 101: Cost 0.35828671505174703,   \n",
      "  |    Weight  [0.06475906 0.11353108 0.08149251 0.1131925  0.0731324 ],\n",
      "    |     Bias [0.52202022 0.52182806 0.52196912 0.52186648 0.5219948 ]\n",
      "Iterate 102: Cost 0.35816056693334675,   \n",
      "  |    Weight  [0.06441329 0.11366265 0.08131058 0.11332164 0.07286866],\n",
      "    |     Bias [0.52703799 0.52684409 0.52698654 0.52688291 0.52701241]\n",
      "Iterate 103: Cost 0.35803446935119126,   \n",
      "  |    Weight  [0.06406758 0.11379417 0.08112867 0.11345075 0.07260496],\n",
      "    |     Bias [0.53205474 0.53185911 0.53200296 0.53189833 0.53202902]\n",
      "Iterate 104: Cost 0.35790842228503283,   \n",
      "  |    Weight  [0.06372193 0.11392565 0.08094679 0.11357983 0.07234131],\n",
      "    |     Bias [0.53707049 0.53687313 0.53701838 0.53691275 0.53704462]\n",
      "Iterate 105: Cost 0.3577824257146314,   \n",
      "  |    Weight  [0.06337634 0.11405709 0.08076493 0.11370888 0.07207769],\n",
      "    |     Bias [0.54208524 0.54188614 0.54203279 0.54192617 0.54205922]\n",
      "Iterate 106: Cost 0.357656479619755,   \n",
      "  |    Weight  [0.06303082 0.11418847 0.0805831  0.11383791 0.07181413],\n",
      "    |     Bias [0.54709897 0.54689815 0.5470462  0.54693858 0.54707281]\n",
      "Iterate 107: Cost 0.3575305839801799,   \n",
      "  |    Weight  [0.06268535 0.11431981 0.08040129 0.1139669  0.07155061],\n",
      "    |     Bias [0.5521117  0.55190916 0.5520586  0.55194999 0.55208539]\n",
      "Iterate 108: Cost 0.35740473877569046,   \n",
      "  |    Weight  [0.06233995 0.1144511  0.08021951 0.11409587 0.07128713],\n",
      "    |     Bias [0.55712343 0.55691916 0.55707    0.5569604  0.55709697]\n",
      "Iterate 109: Cost 0.3572789439860792,   \n",
      "  |    Weight  [0.06199461 0.11458235 0.08003775 0.11422481 0.07102369],\n",
      "    |     Bias [0.56213414 0.56192816 0.5620804  0.56196981 0.56210755]\n",
      "Iterate 110: Cost 0.35715319959114655,   \n",
      "  |    Weight  [0.06164932 0.11471355 0.07985602 0.11435371 0.0707603 ],\n",
      "    |     Bias [0.56714385 0.56693616 0.56708979 0.56697821 0.56711712]\n",
      "Iterate 111: Cost 0.3570275055707012,   \n",
      "  |    Weight  [0.0613041  0.1148447  0.07967432 0.11448259 0.07049696],\n",
      "    |     Bias [0.57215256 0.57194315 0.57209819 0.57198561 0.57212569]\n",
      "Iterate 112: Cost 0.35690186190455975,   \n",
      "  |    Weight  [0.06095895 0.11497581 0.07949264 0.11461145 0.07023366],\n",
      "    |     Bias [0.57716025 0.57694914 0.57710557 0.576992   0.57713325]\n",
      "Iterate 113: Cost 0.35677626857254713,   \n",
      "  |    Weight  [0.06061385 0.11510687 0.07931099 0.11474027 0.0699704 ],\n",
      "    |     Bias [0.58216695 0.58195413 0.58211196 0.5819974  0.58213982]\n",
      "Iterate 114: Cost 0.3566507255544963,   \n",
      "  |    Weight  [0.06026881 0.11523788 0.07912936 0.11486906 0.06970719],\n",
      "    |     Bias [0.58717263 0.58695812 0.58711735 0.58700179 0.58714537]\n",
      "Iterate 115: Cost 0.35652523283024806,   \n",
      "  |    Weight  [0.05992384 0.11536885 0.07894775 0.11499783 0.06944402],\n",
      "    |     Bias [0.59217732 0.5919611  0.59212173 0.59200518 0.59214993]\n",
      "Iterate 116: Cost 0.3563997903796516,   \n",
      "  |    Weight  [0.05957892 0.11549977 0.07876618 0.11512656 0.06918089],\n",
      "    |     Bias [0.59718099 0.59696309 0.59712511 0.59700757 0.59715348]\n",
      "Iterate 117: Cost 0.3562743981825638,   \n",
      "  |    Weight  [0.05923407 0.11563064 0.07858462 0.11525527 0.06891781],\n",
      "    |     Bias [0.60218367 0.60196407 0.60212749 0.60200896 0.60215603]\n",
      "Iterate 118: Cost 0.3561490562188502,   \n",
      "  |    Weight  [0.05888928 0.11576147 0.0784031  0.11538395 0.06865477],\n",
      "    |     Bias [0.60718534 0.60696405 0.60712887 0.60700935 0.60715757]\n",
      "Iterate 119: Cost 0.35602376446838374,   \n",
      "  |    Weight  [0.05854455 0.11589225 0.0782216  0.1155126  0.06839178],\n",
      "    |     Bias [0.612186   0.61196303 0.61212924 0.61200874 0.61215811]\n",
      "Iterate 120: Cost 0.35589852291104596,   \n",
      "  |    Weight  [0.05819988 0.11602298 0.07804012 0.11564122 0.06812883],\n",
      "    |     Bias [0.61718566 0.61696101 0.61712862 0.61700713 0.61715765]\n",
      "Iterate 121: Cost 0.35577333152672613,   \n",
      "  |    Weight  [0.05785527 0.11615367 0.07785867 0.11576981 0.06786593],\n",
      "    |     Bias [0.62218432 0.62195798 0.62212699 0.62200451 0.62215619]\n",
      "Iterate 122: Cost 0.3556481902953217,   \n",
      "  |    Weight  [0.05751072 0.11628431 0.07767725 0.11589838 0.06760307],\n",
      "    |     Bias [0.62718197 0.62695396 0.62712437 0.6270009  0.62715373]\n",
      "Iterate 123: Cost 0.3555230991967383,   \n",
      "  |    Weight  [0.05716623 0.1164149  0.07749585 0.11602691 0.06734025],\n",
      "    |     Bias [0.63217862 0.63194894 0.63212074 0.63199628 0.63215027]\n",
      "Iterate 124: Cost 0.3553980582108894,   \n",
      "  |    Weight  [0.05682181 0.11654545 0.07731447 0.11615542 0.06707748],\n",
      "    |     Bias [0.63717426 0.63694291 0.63711612 0.63699067 0.6371458 ]\n",
      "Iterate 125: Cost 0.3552730673176964,   \n",
      "  |    Weight  [0.05647744 0.11667595 0.07713312 0.1162839  0.06681475],\n",
      "    |     Bias [0.6421689  0.64193589 0.64211049 0.64198406 0.64214033]\n",
      "Iterate 126: Cost 0.35514812649708916,   \n",
      "  |    Weight  [0.05613314 0.11680641 0.0769518  0.11641235 0.06655207],\n",
      "    |     Bias [0.64716254 0.64692786 0.64710387 0.64697645 0.64713386]\n",
      "Iterate 127: Cost 0.35502323572900546,   \n",
      "  |    Weight  [0.0557889  0.11693681 0.0767705  0.11654077 0.06628943],\n",
      "    |     Bias [0.65215518 0.65191884 0.65209624 0.65196783 0.65212639]\n",
      "Iterate 128: Cost 0.3548983949933907,   \n",
      "  |    Weight  [0.05544472 0.11706718 0.07658923 0.11666916 0.06602683],\n",
      "    |     Bias [0.65714681 0.65690882 0.65708762 0.65695822 0.65711792]\n",
      "Iterate 129: Cost 0.3547736042701989,   \n",
      "  |    Weight  [0.0551006  0.11719749 0.07640798 0.11679752 0.06576428],\n",
      "    |     Bias [0.66213744 0.6618978  0.66207799 0.66194761 0.66210845]\n",
      "Iterate 130: Cost 0.3546488635393917,   \n",
      "  |    Weight  [0.05475654 0.11732776 0.07622676 0.11692586 0.06550177],\n",
      "    |     Bias [0.66712707 0.66688578 0.66706737 0.66693601 0.66709798]\n",
      "Iterate 131: Cost 0.35452417278093906,   \n",
      "  |    Weight  [0.05441254 0.11745798 0.07604556 0.11705416 0.06523931],\n",
      "    |     Bias [0.6721157  0.67187276 0.67205575 0.6719234  0.67208651]\n",
      "Iterate 132: Cost 0.3543995319748186,   \n",
      "  |    Weight  [0.0540686  0.11758816 0.07586439 0.11718244 0.06497689],\n",
      "    |     Bias [0.67710333 0.67685874 0.67704313 0.6769098  0.67707404]\n",
      "Iterate 133: Cost 0.3542749411010164,   \n",
      "  |    Weight  [0.05372473 0.11771829 0.07568324 0.11731069 0.06471451],\n",
      "    |     Bias [0.68208995 0.68184372 0.68202951 0.68189519 0.68206057]\n",
      "Iterate 134: Cost 0.35415040013952626,   \n",
      "  |    Weight  [0.05338091 0.11784837 0.07550212 0.11743891 0.06445218],\n",
      "    |     Bias [0.68707557 0.68682771 0.68701489 0.68687959 0.6870461 ]\n",
      "Iterate 135: Cost 0.35402590907035014,   \n",
      "  |    Weight  [0.05303716 0.11797841 0.07532103 0.1175671  0.06418989],\n",
      "    |     Bias [0.6920602  0.69181069 0.69199928 0.69186299 0.69203063]\n",
      "Iterate 136: Cost 0.35390146787349785,   \n",
      "  |    Weight  [0.05269346 0.1181084  0.07513996 0.11769526 0.06392765],\n",
      "    |     Bias [0.69704382 0.69679268 0.69698267 0.6968454  0.69701416]\n",
      "Iterate 137: Cost 0.3537770765289872,   \n",
      "  |    Weight  [0.05234983 0.11823834 0.07495891 0.1178234  0.06366545],\n",
      "    |     Bias [0.70202644 0.70177368 0.70196506 0.70182681 0.7019967 ]\n",
      "Iterate 138: Cost 0.3536527350168444,   \n",
      "  |    Weight  [0.05200626 0.11836824 0.07477789 0.1179515  0.06340329],\n",
      "    |     Bias [0.70700806 0.70675367 0.70694645 0.70680722 0.70697823]\n",
      "Iterate 139: Cost 0.3535284433171032,   \n",
      "  |    Weight  [0.05166275 0.11849809 0.0745969  0.11807958 0.06314118],\n",
      "    |     Bias [0.71198868 0.71173267 0.71192684 0.71178663 0.71195877]\n",
      "Iterate 140: Cost 0.35340420140980555,   \n",
      "  |    Weight  [0.0513193  0.1186279  0.07441593 0.11820763 0.06287911],\n",
      "    |     Bias [0.71696829 0.71671067 0.71690624 0.71676505 0.71693831]\n",
      "Iterate 141: Cost 0.3532800092750016,   \n",
      "  |    Weight  [0.05097591 0.11875766 0.07423499 0.11833565 0.06261709],\n",
      "    |     Bias [0.72194691 0.72168767 0.72188464 0.72174247 0.72191685]\n",
      "Iterate 142: Cost 0.35315586689274886,   \n",
      "  |    Weight  [0.05063258 0.11888737 0.07405407 0.11846364 0.06235511],\n",
      "    |     Bias [0.72692453 0.72666368 0.72686205 0.72671889 0.72689439]\n",
      "Iterate 143: Cost 0.3530317742431135,   \n",
      "  |    Weight  [0.05028931 0.11901703 0.07387317 0.1185916  0.06209317],\n",
      "    |     Bias [0.73190115 0.73163869 0.73183846 0.73169432 0.73187093]\n",
      "Iterate 144: Cost 0.3529077313061694,   \n",
      "  |    Weight  [0.0499461  0.11914665 0.07369231 0.11871953 0.06183128],\n",
      "    |     Bias [0.73687677 0.7366127  0.73681387 0.73666876 0.73684648]\n",
      "Iterate 145: Cost 0.3527837380619984,   \n",
      "  |    Weight  [0.04960296 0.11927623 0.07351146 0.11884744 0.06156943],\n",
      "    |     Bias [0.7418514  0.74158572 0.74178829 0.74164219 0.74182103]\n",
      "Iterate 146: Cost 0.35265979449069035,   \n",
      "  |    Weight  [0.04925987 0.11940575 0.07333065 0.11897531 0.06130762],\n",
      "    |     Bias [0.74682502 0.74655775 0.74676171 0.74661464 0.74679458]\n",
      "Iterate 147: Cost 0.3525359005723431,   \n",
      "  |    Weight  [0.04891685 0.11953523 0.07314985 0.11910316 0.06104586],\n",
      "    |     Bias [0.75179764 0.75152877 0.75173413 0.75158608 0.75176714]\n",
      "Iterate 148: Cost 0.35241205628706246,   \n",
      "  |    Weight  [0.04857389 0.11966467 0.07296909 0.11923098 0.06078415],\n",
      "    |     Bias [0.75676927 0.7564988  0.75670556 0.75655653 0.7567387 ]\n",
      "Iterate 149: Cost 0.35228826161496224,   \n",
      "  |    Weight  [0.04823098 0.11979406 0.07278835 0.11935877 0.06052247],\n",
      "    |     Bias [0.7617399  0.76146784 0.761676   0.76152599 0.76170926]\n",
      "Iterate 150: Cost 0.3521645165361642,   \n",
      "  |    Weight  [0.04788814 0.1199234  0.07260763 0.11948654 0.06026084],\n",
      "    |     Bias [0.76670952 0.76643588 0.76664544 0.76649445 0.76667883]\n",
      "Iterate 151: Cost 0.352040821030798,   \n",
      "  |    Weight  [0.04754536 0.1200527  0.07242694 0.11961427 0.05999926],\n",
      "    |     Bias [0.77167816 0.77140293 0.77161388 0.77146192 0.7716474 ]\n",
      "Iterate 152: Cost 0.3519171750790013,   \n",
      "  |    Weight  [0.04720264 0.12018194 0.07224627 0.11974198 0.05973772],\n",
      "    |     Bias [0.77664579 0.77636898 0.77658133 0.7764284  0.77661497]\n",
      "Iterate 153: Cost 0.35179357866091976,   \n",
      "  |    Weight  [0.04685998 0.12031115 0.07206563 0.11986965 0.05947622],\n",
      "    |     Bias [0.78161243 0.78133404 0.78154779 0.78139388 0.78158155]\n",
      "Iterate 154: Cost 0.351670031756707,   \n",
      "  |    Weight  [0.04651738 0.12044031 0.07188502 0.1199973  0.05921476],\n",
      "    |     Bias [0.78657806 0.7862981  0.78651325 0.78635836 0.78654713]\n",
      "Iterate 155: Cost 0.35154653434652466,   \n",
      "  |    Weight  [0.04617484 0.12056942 0.07170443 0.12012492 0.05895335],\n",
      "    |     Bias [0.79154271 0.79126117 0.79147772 0.79132185 0.79151172]\n",
      "Iterate 156: Cost 0.35142308641054204,   \n",
      "  |    Weight  [0.04583236 0.12069848 0.07152386 0.12025251 0.05869199],\n",
      "    |     Bias [0.79650635 0.79622325 0.79644119 0.79628435 0.79647532]\n",
      "Iterate 157: Cost 0.3512996879289367,   \n",
      "  |    Weight  [0.04548995 0.1208275  0.07134332 0.12038008 0.05843066],\n",
      "    |     Bias [0.801469   0.80118433 0.80140367 0.80124586 0.80143791]\n",
      "Iterate 158: Cost 0.3511763388818939,   \n",
      "  |    Weight  [0.04514759 0.12095647 0.07116281 0.12050761 0.05816938],\n",
      "    |     Bias [0.80643065 0.80614442 0.80636516 0.80620637 0.80639952]\n",
      "Iterate 159: Cost 0.35105303924960707,   \n",
      "  |    Weight  [0.04480529 0.1210854  0.07098232 0.12063512 0.05790815],\n",
      "    |     Bias [0.8113913  0.81110352 0.81132565 0.81116589 0.81136013]\n",
      "Iterate 160: Cost 0.35092978901227745,   \n",
      "  |    Weight  [0.04446306 0.12121428 0.07080185 0.12076259 0.05764696],\n",
      "    |     Bias [0.81635096 0.81606162 0.81628515 0.81612442 0.81631974]\n",
      "Iterate 161: Cost 0.3508065881501141,   \n",
      "  |    Weight  [0.04412088 0.12134311 0.07062142 0.12089004 0.05738581],\n",
      "    |     Bias [0.82130963 0.82101873 0.82124366 0.82108196 0.82127836]\n",
      "Iterate 162: Cost 0.3506834366433343,   \n",
      "  |    Weight  [0.04377877 0.1214719  0.070441   0.12101746 0.05712471],\n",
      "    |     Bias [0.82626729 0.82597485 0.82620118 0.8260385  0.82623599]\n",
      "Iterate 163: Cost 0.3505603344721631,   \n",
      "  |    Weight  [0.04343672 0.12160064 0.07026061 0.12114486 0.05686365],\n",
      "    |     Bias [0.83122397 0.83092997 0.8311577  0.83099405 0.83119262]\n",
      "Iterate 164: Cost 0.3504372816168333,   \n",
      "  |    Weight  [0.04309472 0.12172934 0.07008025 0.12127222 0.05660263],\n",
      "    |     Bias [0.83617964 0.83588411 0.83611323 0.83594861 0.83614826]\n",
      "Iterate 165: Cost 0.3503142780575859,   \n",
      "  |    Weight  [0.04275279 0.12185799 0.06989991 0.12139955 0.05634166],\n",
      "    |     Bias [0.84113432 0.84083725 0.84106777 0.84090218 0.84110291]\n",
      "Iterate 166: Cost 0.35019132377466977,   \n",
      "  |    Weight  [0.04241092 0.12198659 0.0697196  0.12152686 0.05608073],\n",
      "    |     Bias [0.84608801 0.8457894  0.84602132 0.84585475 0.84605656]\n",
      "Iterate 167: Cost 0.3500684187483414,   \n",
      "  |    Weight  [0.04206911 0.12211515 0.06953931 0.12165414 0.05581984],\n",
      "    |     Bias [0.8510407  0.85074055 0.85097387 0.85080634 0.85100923]\n",
      "Iterate 168: Cost 0.3499455629588656,   \n",
      "  |    Weight  [0.04172736 0.12224366 0.06935905 0.12178139 0.055559  ],\n",
      "    |     Bias [0.8559924  0.85569072 0.85592544 0.85575693 0.85596089]\n",
      "Iterate 169: Cost 0.3498227563865149,   \n",
      "  |    Weight  [0.04138567 0.12237212 0.06917881 0.12190861 0.0552982 ],\n",
      "    |     Bias [0.8609431  0.8606399  0.86087601 0.86070653 0.86091157]\n",
      "Iterate 170: Cost 0.34969999901156956,   \n",
      "  |    Weight  [0.04104404 0.12250054 0.0689986  0.1220358  0.05503745],\n",
      "    |     Bias [0.86589281 0.86558808 0.86582559 0.86565515 0.86586125]\n",
      "Iterate 171: Cost 0.34957729081431815,   \n",
      "  |    Weight  [0.04070247 0.12262892 0.06881841 0.12216297 0.05477674],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |     Bias [0.87084153 0.87053527 0.87077418 0.87060277 0.87080995]\n",
      "Iterate 172: Cost 0.3494546317750568,   \n",
      "  |    Weight  [0.04036096 0.12275724 0.06863825 0.1222901  0.05451607],\n",
      "    |     Bias [0.87578925 0.87548148 0.87572179 0.8755494  0.87575765]\n",
      "Iterate 173: Cost 0.34933202187408974,   \n",
      "  |    Weight  [0.04001951 0.12288552 0.06845811 0.12241721 0.05425544],\n",
      "    |     Bias [0.88073598 0.88042669 0.8806684  0.88049504 0.88070435]\n",
      "Iterate 174: Cost 0.34920946109172873,   \n",
      "  |    Weight  [0.03967812 0.12301376 0.068278   0.12254429 0.05399486],\n",
      "    |     Bias [0.88568171 0.88537091 0.88561402 0.88543969 0.88565007]\n",
      "Iterate 175: Cost 0.34908694940829393,   \n",
      "  |    Weight  [0.03933679 0.12314195 0.06809791 0.12267134 0.05373433],\n",
      "    |     Bias [0.89062645 0.89031414 0.89055865 0.89038336 0.8905948 ]\n",
      "Iterate 176: Cost 0.34896448680411307,   \n",
      "  |    Weight  [0.03899553 0.12327009 0.06791785 0.12279836 0.05347384],\n",
      "    |     Bias [0.8955702  0.89525638 0.89550229 0.89532603 0.89553853]\n",
      "Iterate 177: Cost 0.3488420732595217,   \n",
      "  |    Weight  [0.03865432 0.12339819 0.06773782 0.12292536 0.05321339],\n",
      "    |     Bias [0.90051296 0.90019764 0.90044494 0.90026771 0.90048127]\n",
      "Iterate 178: Cost 0.34871970875486363,   \n",
      "  |    Weight  [0.03831317 0.12352624 0.0675578  0.12305232 0.05295298],\n",
      "    |     Bias [0.90545472 0.9051379  0.9053866  0.90520841 0.90542303]\n",
      "Iterate 179: Cost 0.34859739327049016,   \n",
      "  |    Weight  [0.03797209 0.12365424 0.06737782 0.12317926 0.05269262],\n",
      "    |     Bias [0.91039549 0.91007717 0.91032727 0.91014811 0.91036379]\n",
      "Iterate 180: Cost 0.34847512678676057,   \n",
      "  |    Weight  [0.03763106 0.1237822  0.06719786 0.12330617 0.0524323 ],\n",
      "    |     Bias [0.91533527 0.91501546 0.91526695 0.91508683 0.91530356]\n",
      "Iterate 181: Cost 0.348352909284042,   \n",
      "  |    Weight  [0.0372901  0.12391012 0.06701792 0.12343305 0.05217203],\n",
      "    |     Bias [0.92027406 0.91995276 0.92020565 0.92002456 0.92024234]\n",
      "Iterate 182: Cost 0.3482307407427095,   \n",
      "  |    Weight  [0.03694919 0.12403798 0.06683801 0.1235599  0.0519118 ],\n",
      "    |     Bias [0.92521185 0.92488906 0.92514335 0.9249613  0.92518013]\n",
      "Iterate 183: Cost 0.3481086211431461,   \n",
      "  |    Weight  [0.03660835 0.1241658  0.06665812 0.12368673 0.05165161],\n",
      "    |     Bias [0.93014865 0.92982438 0.93008007 0.92989705 0.93011694]\n",
      "Iterate 184: Cost 0.34798655046574256,   \n",
      "  |    Weight  [0.03626757 0.12429358 0.06647826 0.12381352 0.05139146],\n",
      "    |     Bias [0.93508447 0.93475871 0.9350158  0.93483182 0.93505275]\n",
      "Iterate 185: Cost 0.34786452869089723,   \n",
      "  |    Weight  [0.03592684 0.12442131 0.06629843 0.12394029 0.05113136],\n",
      "    |     Bias [0.94001929 0.93969206 0.93995054 0.93976559 0.93998757]\n",
      "Iterate 186: Cost 0.3477425557990169,   \n",
      "  |    Weight  [0.03558618 0.12454899 0.06611862 0.12406703 0.05087131],\n",
      "    |     Bias [0.94495312 0.94462441 0.94488429 0.94469838 0.94492141]\n",
      "Iterate 187: Cost 0.3476206317705157,   \n",
      "  |    Weight  [0.03524558 0.12467663 0.06593883 0.12419374 0.05061129],\n",
      "    |     Bias [0.94988596 0.94955578 0.94981706 0.94963019 0.94985425]\n",
      "Iterate 188: Cost 0.3474987565858159,   \n",
      "  |    Weight  [0.03490503 0.12480422 0.06575907 0.12432042 0.05035132],\n",
      "    |     Bias [0.95481781 0.95448616 0.95474883 0.954561   0.95478611]\n",
      "Iterate 189: Cost 0.3473769302253475,   \n",
      "  |    Weight  [0.03456455 0.12493177 0.06557934 0.12444707 0.0500914 ],\n",
      "    |     Bias [0.95974867 0.95941555 0.95967962 0.95949083 0.95971698]\n",
      "Iterate 190: Cost 0.34725515266954843,   \n",
      "  |    Weight  [0.03422413 0.12505927 0.06539963 0.1245737  0.04983151],\n",
      "    |     Bias [0.96467853 0.96434396 0.96460943 0.96441967 0.96464686]\n",
      "Iterate 191: Cost 0.34713342389886415,   \n",
      "  |    Weight  [0.03388377 0.12518672 0.06521994 0.1247003  0.04957167],\n",
      "    |     Bias [0.96960741 0.96927138 0.96953824 0.96934753 0.96957575]\n",
      "Iterate 192: Cost 0.34701174389374845,   \n",
      "  |    Weight  [0.03354346 0.12531413 0.06504028 0.12482687 0.04931188],\n",
      "    |     Bias [0.9745353  0.97419781 0.97446607 0.9742744  0.97450366]\n",
      "Iterate 193: Cost 0.3468901126346625,   \n",
      "  |    Weight  [0.03320322 0.12544149 0.06486064 0.12495341 0.04905213],\n",
      "    |     Bias [0.9794622  0.97912326 0.97939292 0.97920028 0.97943057]\n",
      "Iterate 194: Cost 0.34676853010207564,   \n",
      "  |    Weight  [0.03286304 0.12556881 0.06468103 0.12507992 0.04879242],\n",
      "    |     Bias [0.98438811 0.98404771 0.98431878 0.98412518 0.9843565 ]\n",
      "Iterate 195: Cost 0.3466469962764648,   \n",
      "  |    Weight  [0.03252292 0.12569608 0.06450145 0.1252064  0.04853275],\n",
      "    |     Bias [0.98931303 0.98897119 0.98924365 0.98904909 0.98928144]\n",
      "Iterate 196: Cost 0.3465255111383148,   \n",
      "  |    Weight  [0.03218286 0.1258233  0.06432189 0.12533286 0.04827313],\n",
      "    |     Bias [0.99423696 0.99389368 0.99416753 0.99397201 0.9942054 ]\n",
      "Iterate 197: Cost 0.34640407466811834,   \n",
      "  |    Weight  [0.03184286 0.12595048 0.06414235 0.12545929 0.04801355],\n",
      "    |     Bias [0.99915991 0.99881518 0.99909043 0.99889396 0.99912837]\n",
      "Iterate 198: Cost 0.34628268684637586,   \n",
      "  |    Weight  [0.03150292 0.12607762 0.06396284 0.12558569 0.04775401],\n",
      "    |     Bias [1.00408186 1.0037357  1.00401235 1.00381491 1.00405035]\n",
      "Iterate 199: Cost 0.3461613476535958,   \n",
      "  |    Weight  [0.03116304 0.1262047  0.06378336 0.12571206 0.04749452],\n",
      "    |     Bias [1.00900283 1.00865523 1.00893328 1.00873488 1.00897134]\n",
      "Iterate 200: Cost 0.34604005707029406,   \n",
      "  |    Weight  [0.03082322 0.12633174 0.0636039  0.1258384  0.04723507],\n",
      "    |     Bias [1.01392281 1.01357377 1.01385322 1.01365387 1.01389135]\n",
      "Iterate 201: Cost 0.3459188150769946,   \n",
      "  |    Weight  [0.03048346 0.12645874 0.06342446 0.12596471 0.04697567],\n",
      "    |     Bias [1.0188418  1.01849133 1.01877218 1.01857187 1.01881037]\n",
      "Iterate 202: Cost 0.3457976216542291,   \n",
      "  |    Weight  [0.03014376 0.12658569 0.06324505 0.126091   0.04671631],\n",
      "    |     Bias [1.0237598  1.02340791 1.02369015 1.02348889 1.02372841]\n",
      "Iterate 203: Cost 0.3456764767825371,   \n",
      "  |    Weight  [0.02980412 0.12671259 0.06306567 0.12621726 0.04645699],\n",
      "    |     Bias [1.02867681 1.0283235  1.02860714 1.02840492 1.02864546]\n",
      "Iterate 204: Cost 0.3455553804424659,   \n",
      "  |    Weight  [0.02946454 0.12683945 0.06288631 0.12634349 0.04619771],\n",
      "    |     Bias [1.03359284 1.03323811 1.03352315 1.03331997 1.03356152]\n",
      "Iterate 205: Cost 0.3454343326145706,   \n",
      "  |    Weight  [0.02912502 0.12696627 0.06270697 0.12646969 0.04593848],\n",
      "    |     Bias [1.03850788 1.03815174 1.03843817 1.03823404 1.0384766 ]\n",
      "Iterate 206: Cost 0.34531333327941416,   \n",
      "  |    Weight  [0.02878556 0.12709303 0.06252766 0.12659586 0.04567929],\n",
      "    |     Bias [1.04342194 1.04306438 1.04335221 1.04314712 1.0433907 ]\n",
      "Iterate 207: Cost 0.3451923824175671,   \n",
      "  |    Weight  [0.02844616 0.12721976 0.06234838 0.12672201 0.04542015],\n",
      "    |     Bias [1.048335   1.04797603 1.04826526 1.04805922 1.04830381]\n",
      "Iterate 208: Cost 0.3450714800096081,   \n",
      "  |    Weight  [0.02810682 0.12734643 0.06216912 0.12684813 0.04516105],\n",
      "    |     Bias [1.05324708 1.05288671 1.05317733 1.05297033 1.05321593]\n",
      "Iterate 209: Cost 0.34495062603612303,   \n",
      "  |    Weight  [0.02776754 0.12747306 0.06198988 0.12697421 0.04490199],\n",
      "    |     Bias [1.05815818 1.0577964  1.05808842 1.05788047 1.05812707]\n",
      "Iterate 210: Cost 0.34482982047770633,   \n",
      "  |    Weight  [0.02742832 0.12759965 0.06181067 0.12710027 0.04464298],\n",
      "    |     Bias [1.06306828 1.0627051  1.06299852 1.06278962 1.06303723]\n",
      "Iterate 211: Cost 0.3447090633149596,   \n",
      "  |    Weight  [0.02708916 0.12772618 0.06163148 0.12722631 0.044384  ],\n",
      "    |     Bias [1.06797741 1.06761283 1.06790765 1.06769778 1.0679464 ]\n",
      "Iterate 212: Cost 0.34458835452849235,   \n",
      "  |    Weight  [0.02675006 0.12785268 0.06145232 0.12735231 0.04412508],\n",
      "    |     Bias [1.07288554 1.07251957 1.07281578 1.07260497 1.07285459]\n",
      "Iterate 213: Cost 0.34446769409892203,   \n",
      "  |    Weight  [0.02641102 0.12797912 0.06127319 0.12747829 0.04386619],\n",
      "    |     Bias [1.07779269 1.07742533 1.07772294 1.07751117 1.07776179]\n",
      "Iterate 214: Cost 0.34434708200687364,   \n",
      "  |    Weight  [0.02607204 0.12810553 0.06109408 0.12760423 0.04360735],\n",
      "    |     Bias [1.08269886 1.0823301  1.08262911 1.08241639 1.08266801]\n",
      "Iterate 215: Cost 0.34422651823298017,   \n",
      "  |    Weight  [0.02573312 0.12823188 0.06091499 0.12773015 0.04334855],\n",
      "    |     Bias [1.08760404 1.0872339  1.08753431 1.08732063 1.08757325]\n",
      "Iterate 216: Cost 0.34410600275788217,   \n",
      "  |    Weight  [0.02539426 0.12835819 0.06073593 0.12785605 0.0430898 ],\n",
      "    |     Bias [1.09250823 1.09213671 1.09243851 1.09222389 1.09247751]\n",
      "Iterate 217: Cost 0.34398553556222794,   \n",
      "  |    Weight  [0.02505546 0.12848446 0.06055689 0.12798191 0.04283108],\n",
      "    |     Bias [1.09741144 1.09703854 1.09734174 1.09712617 1.09738078]\n",
      "Iterate 218: Cost 0.34386511662667385,   \n",
      "  |    Weight  [0.02471672 0.12861068 0.06037788 0.12810774 0.04257242],\n",
      "    |     Bias [1.10231367 1.10193939 1.10224399 1.10202746 1.10228306]\n",
      "Iterate 219: Cost 0.34374474593188353,   \n",
      "  |    Weight  [0.02437804 0.12873685 0.0601989  0.12823355 0.04231379],\n",
      "    |     Bias [1.10721491 1.10683926 1.10714525 1.10692778 1.10718437]\n",
      "Iterate 220: Cost 0.3436244234585287,   \n",
      "  |    Weight  [0.02403942 0.12886298 0.06001994 0.12835933 0.04205521],\n",
      "    |     Bias [1.11211517 1.11173814 1.11204554 1.11182711 1.11208469]\n",
      "Iterate 221: Cost 0.34350414918728883,   \n",
      "  |    Weight  [0.02370086 0.12898906 0.059841   0.12848508 0.04179667],\n",
      "    |     Bias [1.11701444 1.11663605 1.11694484 1.11672546 1.11698404]\n",
      "Iterate 222: Cost 0.343383923098851,   \n",
      "  |    Weight  [0.02336236 0.1291151  0.05966209 0.1286108  0.04153817],\n",
      "    |     Bias [1.12191273 1.12153297 1.12184316 1.12162284 1.1218824 ]\n",
      "Iterate 223: Cost 0.34326374517391,   \n",
      "  |    Weight  [0.02302392 0.12924109 0.0594832  0.1287365  0.04127972],\n",
      "    |     Bias [1.12681003 1.12642892 1.12674051 1.12651923 1.12677977]\n",
      "Iterate 224: Cost 0.3431436153931685,   \n",
      "  |    Weight  [0.02268554 0.12936704 0.05930434 0.12886216 0.04102131],\n",
      "    |     Bias [1.13170636 1.13132388 1.13163687 1.13141464 1.13167617]\n",
      "Iterate 225: Cost 0.3430235337373368,   \n",
      "  |    Weight  [0.02234722 0.12949294 0.0591255  0.1289878  0.04076295],\n",
      "    |     Bias [1.13660169 1.13621787 1.13653225 1.13630908 1.13657158]\n",
      "Iterate 226: Cost 0.3429035001871329,   \n",
      "  |    Weight  [0.02200896 0.12961879 0.05894669 0.12911341 0.04050462],\n",
      "    |     Bias [1.14149605 1.14111087 1.14142665 1.14120253 1.14146602]\n",
      "Iterate 227: Cost 0.34278351472328267,   \n",
      "  |    Weight  [0.02167076 0.1297446  0.0587679  0.12923899 0.04024634],\n",
      "    |     Bias [1.14638942 1.1460029  1.14632007 1.146095   1.14635947]\n",
      "Iterate 228: Cost 0.3426635773265196,   \n",
      "  |    Weight  [0.02133262 0.12987036 0.05858914 0.12936455 0.03998811],\n",
      "    |     Bias [1.15128181 1.15089394 1.15121251 1.1509865  1.15125194]\n",
      "Iterate 229: Cost 0.34254368797758467,   \n",
      "  |    Weight  [0.02099453 0.12999608 0.0584104  0.12949007 0.03972991],\n",
      "    |     Bias [1.15617322 1.15578401 1.15610397 1.15587701 1.15614343]\n",
      "Iterate 230: Cost 0.34242384665722725,   \n",
      "  |    Weight  [0.02065651 0.13012175 0.05823169 0.12961557 0.03947176],\n",
      "    |     Bias [1.16106365 1.16067309 1.16099446 1.16076655 1.16103394]\n",
      "Iterate 231: Cost 0.34230405334620356,   \n",
      "  |    Weight  [0.02031855 0.13024738 0.058053   0.12974104 0.03921366],\n",
      "    |     Bias [1.16595309 1.1655612  1.16588396 1.16565511 1.16592347]\n",
      "Iterate 232: Cost 0.34218430802527827,   \n",
      "  |    Weight  [0.01998065 0.13037296 0.05787434 0.12986648 0.03895559],\n",
      "    |     Bias [1.17084155 1.17044833 1.17077249 1.17054269 1.17081202]\n",
      "Iterate 233: Cost 0.34206461067522337,   \n",
      "  |    Weight  [0.01964281 0.1304985  0.0576957  0.1299919  0.03869757],\n",
      "    |     Bias [1.17572903 1.17533448 1.17566004 1.17542929 1.1756996 ]\n",
      "Iterate 234: Cost 0.3419449612768185,   \n",
      "  |    Weight  [0.01930502 0.13062399 0.05751709 0.13011728 0.03843959],\n",
      "    |     Bias [1.18061553 1.18021965 1.1805466  1.18031492 1.18058619]\n",
      "Iterate 235: Cost 0.3418253598108513,   \n",
      "  |    Weight  [0.0189673  0.13074944 0.0573385  0.13024264 0.03818166],\n",
      "    |     Bias [1.18550105 1.18510384 1.18543219 1.18519956 1.1854718 ]\n",
      "Iterate 236: Cost 0.34170580625811686,   \n",
      "  |    Weight  [0.01862964 0.13087484 0.05715994 0.13036797 0.03792377],\n",
      "    |     Bias [1.19038559 1.18998706 1.19031681 1.19008323 1.19035643]\n",
      "Iterate 237: Cost 0.3415863005994181,   \n",
      "  |    Weight  [0.01829203 0.13100019 0.0569814  0.13049327 0.03766592],\n",
      "    |     Bias [1.19526914 1.1948693  1.19520044 1.19496592 1.19524008]\n",
      "Iterate 238: Cost 0.34146684281556544,   \n",
      "  |    Weight  [0.01795449 0.1311255  0.05680288 0.13061854 0.03740811],\n",
      "    |     Bias [1.20015172 1.19975056 1.2000831  1.19984764 1.20012276]\n",
      "Iterate 239: Cost 0.34134743288737734,   \n",
      "  |    Weight  [0.017617   0.13125076 0.0566244  0.13074379 0.03715035],\n",
      "    |     Bias [1.20503331 1.20463084 1.20496478 1.20472837 1.20500446]\n",
      "Iterate 240: Cost 0.34122807079567946,   \n",
      "  |    Weight  [0.01727958 0.13137598 0.05644593 0.13086901 0.03689263],\n",
      "    |     Bias [1.20991393 1.20951015 1.20984548 1.20960813 1.20988517]\n",
      "Iterate 241: Cost 0.3411087565213056,   \n",
      "  |    Weight  [0.01694222 0.13150115 0.05626749 0.13099419 0.03663496],\n",
      "    |     Bias [1.21479356 1.21438848 1.21472521 1.21448692 1.21476491]\n",
      "Iterate 242: Cost 0.34098949004509704,   \n",
      "  |    Weight  [0.01660491 0.13162628 0.05608908 0.13111936 0.03637732],\n",
      "    |     Bias [1.21967222 1.21926583 1.21960395 1.21936472 1.21964367]\n",
      "Iterate 243: Cost 0.34087027134790276,   \n",
      "  |    Weight  [0.01626766 0.13175136 0.05591069 0.13124449 0.03611973],\n",
      "    |     Bias [1.22454989 1.2241422  1.22448173 1.22424155 1.22452146]\n",
      "Iterate 244: Cost 0.3407511004105793,   \n",
      "  |    Weight  [0.01593048 0.1318764  0.05573232 0.13136959 0.03586219],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |     Bias [1.22942659 1.2290176  1.22935852 1.22911741 1.22939826]\n",
      "Iterate 245: Cost 0.340631977213991,   \n",
      "  |    Weight  [0.01559335 0.13200139 0.05555398 0.13149467 0.03560468],\n",
      "    |     Bias [1.23430231 1.23389202 1.23423434 1.23399229 1.23427409]\n",
      "Iterate 246: Cost 0.34051290173901,   \n",
      "  |    Weight  [0.01525629 0.13212634 0.05537567 0.13161972 0.03534722],\n",
      "    |     Bias [1.23917704 1.23876547 1.23910918 1.23886619 1.23914894]\n",
      "Iterate 247: Cost 0.34039387396651577,   \n",
      "  |    Weight  [0.01491928 0.13225124 0.05519738 0.13174474 0.0350898 ],\n",
      "    |     Bias [1.2440508  1.24363794 1.24398305 1.24373912 1.24402282]\n",
      "Iterate 248: Cost 0.34027489387739557,   \n",
      "  |    Weight  [0.01458233 0.13237609 0.05501911 0.13186973 0.03483243],\n",
      "    |     Bias [1.24892358 1.24850944 1.24885594 1.24861107 1.24889571]\n",
      "Iterate 249: Cost 0.3401559614525446,   \n",
      "  |    Weight  [0.01424544 0.1325009  0.05484087 0.1319947  0.0345751 ],\n",
      "    |     Bias [1.25379538 1.25337996 1.25372786 1.25348205 1.25376763]\n",
      "Iterate 250: Cost 0.34003707667286526,   \n",
      "  |    Weight  [0.01390861 0.13262567 0.05466265 0.13211964 0.03431781],\n",
      "    |     Bias [1.25866621 1.2582495  1.2585988  1.25835205 1.25863858]\n",
      "Iterate 251: Cost 0.33991823951926786,   \n",
      "  |    Weight  [0.01357184 0.13275039 0.05448446 0.13224455 0.03406056],\n",
      "    |     Bias [1.26353605 1.26311807 1.26346877 1.26322108 1.26350855]\n",
      "Iterate 252: Cost 0.33979944997267036,   \n",
      "  |    Weight  [0.01323513 0.13287506 0.05430629 0.13236943 0.03380336],\n",
      "    |     Bias [1.26840492 1.26798567 1.26833776 1.26808913 1.26837754]\n",
      "Iterate 253: Cost 0.3396807080139983,   \n",
      "  |    Weight  [0.01289848 0.13299969 0.05412815 0.13249428 0.0335462 ],\n",
      "    |     Bias [1.27327281 1.27285229 1.27320578 1.27295621 1.27324555]\n",
      "Iterate 254: Cost 0.3395620136241849,   \n",
      "  |    Weight  [0.01256189 0.13312428 0.05395003 0.13261911 0.03328908],\n",
      "    |     Bias [1.27813972 1.27771793 1.27807282 1.27782232 1.27811259]\n",
      "Iterate 255: Cost 0.3394433667841711,   \n",
      "  |    Weight  [0.01222536 0.13324881 0.05377194 0.1327439  0.03303201],\n",
      "    |     Bias [1.28300566 1.2825826  1.28293888 1.28268745 1.28297866]\n",
      "Iterate 256: Cost 0.33932476747490514,   \n",
      "  |    Weight  [0.01188889 0.13337331 0.05359387 0.13286867 0.03277498],\n",
      "    |     Bias [1.28787061 1.2874463  1.28780398 1.28755161 1.28784375]\n",
      "Iterate 257: Cost 0.3392062156773433,   \n",
      "  |    Weight  [0.01155248 0.13349776 0.05341583 0.13299341 0.03251799],\n",
      "    |     Bias [1.29273459 1.29230902 1.2926681  1.29241479 1.29270786]\n",
      "Iterate 258: Cost 0.33908771137244936,   \n",
      "  |    Weight  [0.01121613 0.13362216 0.05323781 0.13311813 0.03226104],\n",
      "    |     Bias [1.2975976  1.29717077 1.29753124 1.297277   1.297571  ]\n",
      "Iterate 259: Cost 0.33896925454119464,   \n",
      "  |    Weight  [0.01087983 0.13374652 0.05305982 0.13324281 0.03200414],\n",
      "    |     Bias [1.30245962 1.30203155 1.30239342 1.30213824 1.30243317]\n",
      "Iterate 260: Cost 0.33885084516455805,   \n",
      "  |    Weight  [0.0105436  0.13387083 0.05288185 0.13336747 0.03174728],\n",
      "    |     Bias [1.30732068 1.30689135 1.30725462 1.3069985  1.30729436]\n",
      "Iterate 261: Cost 0.3387324832235263,   \n",
      "  |    Weight  [0.01020743 0.13399509 0.0527039  0.1334921  0.03149046],\n",
      "    |     Bias [1.31218075 1.31175018 1.31211484 1.31185779 1.31215457]\n",
      "Iterate 262: Cost 0.33861416869909367,   \n",
      "  |    Weight  [0.00987131 0.13411932 0.05252598 0.1336167  0.03123369],\n",
      "    |     Bias [1.31703985 1.31660804 1.31697409 1.31671611 1.31701381]\n",
      "Iterate 263: Cost 0.33849590157226184,   \n",
      "  |    Weight  [0.00953525 0.13424349 0.05234809 0.13374128 0.03097696],\n",
      "    |     Bias [1.32189797 1.32146493 1.32183238 1.32157346 1.32187208]\n",
      "Iterate 264: Cost 0.33837768182404054,   \n",
      "  |    Weight  [0.00919926 0.13436762 0.05217022 0.13386582 0.03072027],\n",
      "    |     Bias [1.32675512 1.32632084 1.32668968 1.32642983 1.32672937]\n",
      "Iterate 265: Cost 0.3382595094354465,   \n",
      "  |    Weight  [0.00886332 0.13449171 0.05199237 0.13399034 0.03046363],\n",
      "    |     Bias [1.33161129 1.33117578 1.33154602 1.33128524 1.33158569]\n",
      "Iterate 266: Cost 0.3381413843875047,   \n",
      "  |    Weight  [0.00852744 0.13461575 0.05181455 0.13411483 0.03020702],\n",
      "    |     Bias [1.33646649 1.33602974 1.33640138 1.33613967 1.33644104]\n",
      "Iterate 267: Cost 0.33802330666124714,   \n",
      "  |    Weight  [0.00819163 0.13473975 0.05163675 0.13423929 0.02995046],\n",
      "    |     Bias [1.34132071 1.34088274 1.34125577 1.34099313 1.34129542]\n",
      "Iterate 268: Cost 0.337905276237714,   \n",
      "  |    Weight  [0.00785587 0.1348637  0.05145898 0.13436373 0.02969395],\n",
      "    |     Bias [1.34617396 1.34573476 1.34610919 1.34584562 1.34614882]\n",
      "Iterate 269: Cost 0.3377872930979525,   \n",
      "  |    Weight  [0.00752017 0.1349876  0.05128123 0.13448814 0.02943747],\n",
      "    |     Bias [1.35102623 1.35058582 1.35096164 1.35069713 1.35100124]\n",
      "Iterate 270: Cost 0.337669357223018,   \n",
      "  |    Weight  [0.00718453 0.13511146 0.05110351 0.13461251 0.02918104],\n",
      "    |     Bias [1.35587753 1.3554359  1.35581312 1.35554768 1.3558527 ]\n",
      "Iterate 271: Cost 0.33755146859397284,   \n",
      "  |    Weight  [0.00684895 0.13523528 0.05092581 0.13473687 0.02892465],\n",
      "    |     Bias [1.36072786 1.36028501 1.36066362 1.36039725 1.36070318]\n",
      "Iterate 272: Cost 0.3374336271918875,   \n",
      "  |    Weight  [0.00651342 0.13535905 0.05074814 0.13486119 0.02866831],\n",
      "    |     Bias [1.36557721 1.36513315 1.36551316 1.36524586 1.36555269]\n",
      "Iterate 273: Cost 0.3373158329978397,   \n",
      "  |    Weight  [0.00617796 0.13548278 0.05057049 0.13498548 0.02841201],\n",
      "    |     Bias [1.37042559 1.36998031 1.37036172 1.37009349 1.37040123]\n",
      "Iterate 274: Cost 0.3371980859929148,   \n",
      "  |    Weight  [0.00584256 0.13560646 0.05039287 0.13510975 0.02815575],\n",
      "    |     Bias [1.37527299 1.37482651 1.37520932 1.37494016 1.3752488 ]\n",
      "Iterate 275: Cost 0.3370803861582059,   \n",
      "  |    Weight  [0.00550722 0.13573009 0.05021527 0.13523399 0.02789953],\n",
      "    |     Bias [1.38011942 1.37967174 1.38005594 1.37978585 1.3800954 ]\n",
      "Iterate 276: Cost 0.33696273347481354,   \n",
      "  |    Weight  [0.00517193 0.13585368 0.05003769 0.1353582  0.02764335],\n",
      "    |     Bias [1.38496488 1.384516   1.38490159 1.38463057 1.38494102]\n",
      "Iterate 277: Cost 0.3368451279238458,   \n",
      "  |    Weight  [0.00483671 0.13597723 0.04986014 0.13548239 0.02738722],\n",
      "    |     Bias [1.38980936 1.38935928 1.38974627 1.38947433 1.38978567]\n",
      "Iterate 278: Cost 0.3367275694864186,   \n",
      "  |    Weight  [0.00450154 0.13610073 0.04968262 0.13560654 0.02713113],\n",
      "    |     Bias [1.39465287 1.3942016  1.39458999 1.39431711 1.39462936]\n",
      "Iterate 279: Cost 0.3366100581436549,   \n",
      "  |    Weight  [0.00416643 0.13622418 0.04950512 0.13573067 0.02687509],\n",
      "    |     Bias [1.39949541 1.39904295 1.39943273 1.39915893 1.39947207]\n",
      "Iterate 280: Cost 0.3364925938766858,   \n",
      "  |    Weight  [0.00383138 0.13634759 0.04932764 0.13585477 0.02661908],\n",
      "    |     Bias [1.40433697 1.40388333 1.4042745  1.40399978 1.40431381]\n",
      "Iterate 281: Cost 0.3363751766666495,   \n",
      "  |    Weight  [0.0034964  0.13647095 0.04915019 0.13597885 0.02636312],\n",
      "    |     Bias [1.40917757 1.40872274 1.40911531 1.40883966 1.40915458]\n",
      "Iterate 282: Cost 0.33625780649469217,   \n",
      "  |    Weight  [0.00316147 0.13659427 0.04897276 0.13610289 0.02610721],\n",
      "    |     Bias [1.41401719 1.41356118 1.41395514 1.41367856 1.41399438]\n",
      "Iterate 283: Cost 0.3361404833419671,   \n",
      "  |    Weight  [0.0028266  0.13671755 0.04879536 0.13622691 0.02585133],\n",
      "    |     Bias [1.41885584 1.41839865 1.41879401 1.41851651 1.41883321]\n",
      "Iterate 284: Cost 0.3360232071896355,   \n",
      "  |    Weight  [0.00249178 0.13684078 0.04861798 0.1363509  0.0255955 ],\n",
      "    |     Bias [1.42369352 1.42323515 1.42363191 1.42335348 1.42367107]\n",
      "Iterate 285: Cost 0.335905978018866,   \n",
      "  |    Weight  [0.00215703 0.13696396 0.04844063 0.13647486 0.02533971],\n",
      "    |     Bias [1.42853023 1.42807068 1.42846884 1.42818948 1.42850796]\n",
      "Iterate 286: Cost 0.3357887958108347,   \n",
      "  |    Weight  [0.00182234 0.1370871  0.0482633  0.13659879 0.02508396],\n",
      "    |     Bias [1.43336596 1.43290525 1.4333048  1.43302452 1.43334388]\n",
      "Iterate 287: Cost 0.3356716605467252,   \n",
      "  |    Weight  [0.00148771 0.1372102  0.04808599 0.1367227  0.02482826],\n",
      "    |     Bias [1.43820073 1.43773885 1.43813979 1.43785859 1.43817883]\n",
      "Iterate 288: Cost 0.33555457220772883,   \n",
      "  |    Weight  [0.00115313 0.13733325 0.04790872 0.13684658 0.02457259],\n",
      "    |     Bias [1.44303452 1.44257148 1.44297382 1.44269169 1.44301281]\n",
      "Iterate 289: Cost 0.3354375307750444,   \n",
      "  |    Weight  [0.00081862 0.13745625 0.04773146 0.13697043 0.02431698],\n",
      "    |     Bias [1.44786734 1.44740314 1.44780688 1.44752382 1.44784583]\n",
      "Iterate 290: Cost 0.33532053622987823,   \n",
      "  |    Weight  [0.00048416 0.13757921 0.04755423 0.13709425 0.0240614 ],\n",
      "    |     Bias [1.4526992  1.45223384 1.45263897 1.45235499 1.45267787]\n",
      "Iterate 291: Cost 0.335203588553444,   \n",
      "  |    Weight  [0.00014976 0.13770213 0.04737702 0.13721805 0.02380586],\n",
      "    |     Bias [1.45753008 1.45706357 1.45747009 1.45718519 1.45750895]\n",
      "Iterate 292: Cost 0.33508668772696315,   \n",
      "  |    Weight  [-0.00018458  0.137825    0.04719984  0.13734181  0.02355037],\n",
      "    |     Bias [1.46235999 1.46189233 1.46230024 1.46201443 1.46233906]\n",
      "Iterate 293: Cost 0.33496983373166467,   \n",
      "  |    Weight  [-0.00051886  0.13794782  0.04702269  0.13746555  0.02329492],\n",
      "    |     Bias [1.46718893 1.46672012 1.46712943 1.46684269 1.4671682 ]\n",
      "Iterate 294: Cost 0.3348530265487849,   \n",
      "  |    Weight  [-0.00085308  0.1380706   0.04684555  0.13758926  0.02303952],\n",
      "    |     Bias [1.47201691 1.47154695 1.47195766 1.47166999 1.47199637]\n",
      "Iterate 295: Cost 0.3347362661595677,   \n",
      "  |    Weight  [-0.00118724  0.13819334  0.04666845  0.13771295  0.02278415],\n",
      "    |     Bias [1.47684391 1.47637281 1.47678491 1.47649633 1.47682357]\n",
      "Iterate 296: Cost 0.33461955254526454,   \n",
      "  |    Weight  [-0.00152134  0.13831603  0.04649136  0.13783661  0.02252883],\n",
      "    |     Bias [1.48166994 1.4811977  1.4816112  1.4813217  1.48164981]\n",
      "Iterate 297: Cost 0.3345028856871345,   \n",
      "  |    Weight  [-0.00185538  0.13843868  0.0463143   0.13796023  0.02227356],\n",
      "    |     Bias [1.48649501 1.48602163 1.48643652 1.4861461  1.48647508]\n",
      "Iterate 298: Cost 0.3343862655664438,   \n",
      "  |    Weight  [-0.00218937  0.13856128  0.04613727  0.13808384  0.02201832],\n",
      "    |     Bias [1.4913191  1.49084459 1.49126088 1.49096954 1.49129938]\n",
      "Iterate 299: Cost 0.33426969216446667,   \n",
      "  |    Weight  [-0.00252329  0.13868383  0.04596026  0.13820741  0.02176313],\n",
      "    |     Bias [1.49614223 1.49566659 1.49608427 1.49579201 1.49612272]\n",
      "Iterate 300: Cost 0.33415316546248436,   \n",
      "  |    Weight  [-0.00285716  0.13880634  0.04578327  0.13833095  0.02150798],\n",
      "    |     Bias [1.50096439 1.50048762 1.5009067  1.50061351 1.50094509]\n",
      "Iterate 301: Cost 0.33403668544178605,   \n",
      "  |    Weight  [-0.00319097  0.13892881  0.04560631  0.13845447  0.02125287],\n",
      "    |     Bias [1.50578558 1.50530769 1.50572816 1.50543406 1.50576649]\n",
      "Iterate 302: Cost 0.3339202520836681,   \n",
      "  |    Weight  [-0.00352472  0.13905123  0.04542938  0.13857796  0.0209978 ],\n",
      "    |     Bias [1.5106058  1.51012679 1.51054866 1.51025363 1.51058693]\n",
      "Iterate 303: Cost 0.3338038653694343,   \n",
      "  |    Weight  [-0.00385841  0.13917361  0.04525247  0.13870143  0.02074278],\n",
      "    |     Bias [1.51542506 1.51494493 1.51536819 1.51507225 1.5154064 ]\n",
      "Iterate 304: Cost 0.33368752528039636,   \n",
      "  |    Weight  [-0.00419204  0.13929594  0.04507558  0.13882486  0.0204878 ],\n",
      "    |     Bias [1.52024335 1.5197621  1.52018675 1.51988989 1.5202249 ]\n",
      "Iterate 305: Cost 0.3335712317978731,   \n",
      "  |    Weight  [-0.00452561  0.13941823  0.04489872  0.13894827  0.02023286],\n",
      "    |     Bias [1.52506066 1.5245783  1.52500435 1.52470658 1.52504244]\n",
      "Iterate 306: Cost 0.333454984903191,   \n",
      "  |    Weight  [-0.00485912  0.13954047  0.04472188  0.13907165  0.01997797],\n",
      "    |     Bias [1.52987702 1.52939355 1.52982099 1.5295223  1.52985901]\n",
      "Iterate 307: Cost 0.3333387845776839,   \n",
      "  |    Weight  [-0.00519258  0.13966267  0.04454506  0.139195    0.01972311],\n",
      "    |     Bias [1.5346924  1.53420783 1.53463666 1.53433705 1.53467462]\n",
      "Iterate 308: Cost 0.3332226308026932,   \n",
      "  |    Weight  [-0.00552597  0.13978482  0.04436828  0.13931832  0.0194683 ],\n",
      "    |     Bias [1.53950682 1.53902114 1.53945137 1.53915085 1.53948926]\n",
      "Iterate 309: Cost 0.3331065235595679,   \n",
      "  |    Weight  [-0.00585931  0.13990693  0.04419151  0.13944162  0.01921353],\n",
      "    |     Bias [1.54432027 1.54383349 1.54426512 1.54396368 1.54430294]\n",
      "Iterate 310: Cost 0.3329904628296641,   \n",
      "  |    Weight  [-0.00619259  0.14002899  0.04401477  0.13956489  0.01895881],\n",
      "    |     Bias [1.54913275 1.54864488 1.5490779  1.54877554 1.54911565]\n",
      "Iterate 311: Cost 0.3328744485943457,   \n",
      "  |    Weight  [-0.00652581  0.14015101  0.04383805  0.13968813  0.01870413],\n",
      "    |     Bias [1.55394427 1.5534553  1.55388971 1.55358644 1.5539274 ]\n",
      "Iterate 312: Cost 0.3327584808349841,   \n",
      "  |    Weight  [-0.00685897  0.14027298  0.04366136  0.13981134  0.01844948],\n",
      "    |     Bias [1.55875482 1.55826476 1.55870057 1.55839638 1.55873818]\n",
      "Iterate 313: Cost 0.33264255953295785,   \n",
      "  |    Weight  [-0.00719207  0.14039491  0.0434847   0.13993453  0.01819489],\n",
      "    |     Bias [1.56356441 1.56307326 1.56351046 1.56320536 1.563548  ]\n",
      "Iterate 314: Cost 0.33252668466965324,   \n",
      "  |    Weight  [-0.00752511  0.14051679  0.04330805  0.14005769  0.01794033],\n",
      "    |     Bias [1.56837303 1.56788079 1.56831939 1.56801338 1.56835685]\n",
      "Iterate 315: Cost 0.3324108562264639,   \n",
      "  |    Weight  [-0.00785809  0.14063863  0.04313143  0.14018082  0.01768582],\n",
      "    |     Bias [1.57318069 1.57268737 1.57312736 1.57282043 1.57316475]\n",
      "Iterate 316: Cost 0.33229507418479104,   \n",
      "  |    Weight  [-0.00819102  0.14076043  0.04295484  0.14030392  0.01743135],\n",
      "    |     Bias [1.57798737 1.57749298 1.57793436 1.57762652 1.57797167]\n",
      "Iterate 317: Cost 0.332179338526043,   \n",
      "  |    Weight  [-0.00852388  0.14088218  0.04277827  0.140427    0.01717692],\n",
      "    |     Bias [1.5827931  1.58229762 1.5827404  1.58243165 1.58277764]\n",
      "Iterate 318: Cost 0.3320636492316359,   \n",
      "  |    Weight  [-0.00885669  0.14100388  0.04260173  0.14055005  0.01692253],\n",
      "    |     Bias [1.58759786 1.58710131 1.58754548 1.58723581 1.58758264]\n",
      "Iterate 319: Cost 0.3319480062829933,   \n",
      "  |    Weight  [-0.00918944  0.14112554  0.04242521  0.14067307  0.01666819],\n",
      "    |     Bias [1.59240165 1.59190403 1.5923496  1.59203902 1.59238667]\n",
      "Iterate 320: Cost 0.33183240966154604,   \n",
      "  |    Weight  [-0.00952213  0.14124716  0.04224871  0.14079606  0.01641389],\n",
      "    |     Bias [1.59720448 1.59670579 1.59715275 1.59684126 1.59718975]\n",
      "Iterate 321: Cost 0.33171685934873235,   \n",
      "  |    Weight  [-0.00985476  0.14136873  0.04207224  0.14091903  0.01615963],\n",
      "    |     Bias [1.60200635 1.60150659 1.60195495 1.60164255 1.60199186]\n",
      "Iterate 322: Cost 0.33160135532599805,   \n",
      "  |    Weight  [-0.01018733  0.14149026  0.04189579  0.14104196  0.01590541],\n",
      "    |     Bias [1.60680725 1.60630643 1.60675618 1.60644287 1.60679301]\n",
      "Iterate 323: Cost 0.3314858975747964,   \n",
      "  |    Weight  [-0.01051985  0.14161174  0.04171937  0.14116487  0.01565124],\n",
      "    |     Bias [1.61160718 1.61110531 1.61155645 1.61124223 1.6115932 ]\n",
      "Iterate 324: Cost 0.33137048607658814,   \n",
      "  |    Weight  [-0.0108523   0.14173318  0.04154297  0.14128776  0.01539711],\n",
      "    |     Bias [1.61640616 1.61590323 1.61635576 1.61604063 1.61639242]\n",
      "Iterate 325: Cost 0.3312551208128411,   \n",
      "  |    Weight  [-0.0111847   0.14185457  0.0413666   0.14141061  0.01514302],\n",
      "    |     Bias [1.62120417 1.62070019 1.62115411 1.62083807 1.62119069]\n",
      "Iterate 326: Cost 0.331139801765031,   \n",
      "  |    Weight  [-0.01151704  0.14197592  0.04119025  0.14153344  0.01488897],\n",
      "    |     Bias [1.62600121 1.62549618 1.6259515  1.62563455 1.62598799]\n",
      "Iterate 327: Cost 0.33102452891464057,   \n",
      "  |    Weight  [-0.01184932  0.14209722  0.04101392  0.14165624  0.01463497],\n",
      "    |     Bias [1.6307973  1.63029122 1.63074793 1.63043007 1.63078433]\n",
      "Iterate 328: Cost 0.33090930224316023,   \n",
      "  |    Weight  [-0.01218154  0.14221848  0.04083762  0.14177901  0.014381  ],\n",
      "    |     Bias [1.63559241 1.63508529 1.6355434  1.63522463 1.63557971]\n",
      "Iterate 329: Cost 0.33079412173208783,   \n",
      "  |    Weight  [-0.0125137   0.1423397   0.04066134  0.14190176  0.01412708],\n",
      "    |     Bias [1.64038657 1.63987841 1.64033791 1.64001823 1.64037412]\n",
      "Iterate 330: Cost 0.33067898736292833,   \n",
      "  |    Weight  [-0.0128458   0.14246087  0.04048509  0.14202448  0.0138732 ],\n",
      "    |     Bias [1.64517977 1.64467057 1.64513146 1.64481087 1.64516758]\n",
      "Iterate 331: Cost 0.33056389911719447,   \n",
      "  |    Weight  [-0.01317785  0.14258199  0.04030886  0.14214717  0.01361937],\n",
      "    |     Bias [1.649972   1.64946176 1.64992405 1.64960255 1.64996008]\n",
      "Iterate 332: Cost 0.3304488569764062,   \n",
      "  |    Weight  [-0.01350983  0.14270307  0.04013266  0.14226983  0.01336558],\n",
      "    |     Bias [1.65476327 1.654252   1.65471568 1.65439328 1.65475161]\n",
      "Iterate 333: Cost 0.33033386092209077,   \n",
      "  |    Weight  [-0.01384176  0.14282411  0.03995648  0.14239246  0.01311183],\n",
      "    |     Bias [1.65955357 1.65904128 1.65950635 1.65918304 1.65954219]\n",
      "Iterate 334: Cost 0.3302189109357831,   \n",
      "  |    Weight  [-0.01417363  0.1429451   0.03978033  0.14251507  0.01285812],\n",
      "    |     Bias [1.66434292 1.6638296  1.66429606 1.66397185 1.6643318 ]\n",
      "Iterate 335: Cost 0.3301040069990255,   \n",
      "  |    Weight  [-0.01450544  0.14306605  0.0396042   0.14263765  0.01260445],\n",
      "    |     Bias [1.6691313  1.66861696 1.66908481 1.6687597  1.66912046]\n",
      "Iterate 336: Cost 0.32998914909336735,   \n",
      "  |    Weight  [-0.01483719  0.14318695  0.03942809  0.1427602   0.01235083],\n",
      "    |     Bias [1.67391872 1.67340336 1.67387261 1.67354658 1.67390815]\n",
      "Iterate 337: Cost 0.3298743372003656,   \n",
      "  |    Weight  [-0.01516889  0.14330781  0.03925201  0.14288273  0.01209724],\n",
      "    |     Bias [1.67870518 1.6781888  1.67865944 1.67833252 1.67869489]\n",
      "Iterate 338: Cost 0.3297595713015848,   \n",
      "  |    Weight  [-0.01550052  0.14342862  0.03907595  0.14300522  0.0118437 ],\n",
      "    |     Bias [1.68349068 1.68297329 1.68344532 1.68311749 1.68348066]\n",
      "Iterate 339: Cost 0.3296448513785965,   \n",
      "  |    Weight  [-0.0158321   0.14354939  0.03889992  0.14312769  0.01159021],\n",
      "    |     Bias [1.68827522 1.68775681 1.68823024 1.6879015  1.68826548]\n",
      "Iterate 340: Cost 0.3295301774129801,   \n",
      "  |    Weight  [-0.01616362  0.14367012  0.03872391  0.14325014  0.01133675],\n",
      "    |     Bias [1.6930588  1.69253938 1.6930142  1.69268456 1.69304934]\n",
      "Iterate 341: Cost 0.3294155493863218,   \n",
      "  |    Weight  [-0.01649508  0.1437908   0.03854792  0.14337255  0.01108334],\n",
      "    |     Bias [1.69784142 1.697321   1.69779721 1.69746666 1.69783224]\n",
      "Iterate 342: Cost 0.3293009672802158,   \n",
      "  |    Weight  [-0.01682648  0.14391143  0.03837196  0.14349494  0.01082997],\n",
      "    |     Bias [1.70262307 1.70210165 1.70257926 1.70224781 1.70261418]\n",
      "Iterate 343: Cost 0.329186431076263,   \n",
      "  |    Weight  [-0.01715782  0.14403202  0.03819603  0.1436173   0.01057664],\n",
      "    |     Bias [1.70740377 1.70688135 1.70736035 1.70702799 1.70739516]\n",
      "Iterate 344: Cost 0.3290719407560724,   \n",
      "  |    Weight  [-0.01748911  0.14415257  0.03802012  0.14373963  0.01032335],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |     Bias [1.71218351 1.71166009 1.71214048 1.71180722 1.71217518]\n",
      "Iterate 345: Cost 0.32895749630125976,   \n",
      "  |    Weight  [-0.01782033  0.14427307  0.03784423  0.14386194  0.01007011],\n",
      "    |     Bias [1.71696228 1.71643787 1.71691965 1.7165855  1.71695425]\n",
      "Iterate 346: Cost 0.3288430976934486,   \n",
      "  |    Weight  [-0.0181515   0.14439353  0.03766837  0.14398422  0.00981691],\n",
      "    |     Bias [1.7217401  1.7212147  1.72169787 1.72136282 1.72173236]\n",
      "Iterate 347: Cost 0.32872874491426973,   \n",
      "  |    Weight  [-0.01848261  0.14451395  0.03749253  0.14410647  0.00956375],\n",
      "    |     Bias [1.72651696 1.72599057 1.72647514 1.72613918 1.72650951]\n",
      "Iterate 348: Cost 0.32861443794536094,   \n",
      "  |    Weight  [-0.01881366  0.14463431  0.03731671  0.14422869  0.00931063],\n",
      "    |     Bias [1.73129286 1.73076548 1.73125144 1.73091458 1.7312857 ]\n",
      "Iterate 349: Cost 0.32850017676836796,   \n",
      "  |    Weight  [-0.01914465  0.14475464  0.03714092  0.14435088  0.00905755],\n",
      "    |     Bias [1.7360678  1.73553944 1.73602679 1.73568903 1.73606093]\n",
      "Iterate 350: Cost 0.32838596136494347,   \n",
      "  |    Weight  [-0.01947559  0.14487492  0.03696516  0.14447305  0.00880452],\n",
      "    |     Bias [1.74084178 1.74031244 1.74080119 1.74046253 1.74083521]\n",
      "Iterate 351: Cost 0.3282717917167477,   \n",
      "  |    Weight  [-0.01980646  0.14499516  0.03678942  0.14459519  0.00855153],\n",
      "    |     Bias [1.7456148  1.74508449 1.74557462 1.74523506 1.74560853]\n",
      "Iterate 352: Cost 0.32815766780544803,   \n",
      "  |    Weight  [-0.02013728  0.14511535  0.0366137   0.14471731  0.00829858],\n",
      "    |     Bias [1.75038686 1.74985558 1.75034711 1.75000665 1.7503809 ]\n",
      "Iterate 353: Cost 0.32804358961271957,   \n",
      "  |    Weight  [-0.02046804  0.14523549  0.03643801  0.14483939  0.00804567],\n",
      "    |     Bias [1.75515797 1.75462572 1.75511863 1.75477728 1.7551523 ]\n",
      "Iterate 354: Cost 0.3279295571202442,   \n",
      "  |    Weight  [-0.02079874  0.1453556   0.03626234  0.14496145  0.00779281],\n",
      "    |     Bias [1.75992811 1.7593949  1.75988921 1.75954695 1.75992276]\n",
      "Iterate 355: Cost 0.32781557030971176,   \n",
      "  |    Weight  [-0.02112938  0.14547566  0.03608669  0.14508348  0.00753999],\n",
      "    |     Bias [1.7646973  1.76416312 1.76465882 1.76431567 1.76469225]\n",
      "Iterate 356: Cost 0.32770162916281886,   \n",
      "  |    Weight  [-0.02145996  0.14559567  0.03591107  0.14520549  0.0072872 ],\n",
      "    |     Bias [1.76946554 1.76893039 1.76942749 1.76908343 1.76946079]\n",
      "Iterate 357: Cost 0.32758773366126986,   \n",
      "  |    Weight  [-0.02179049  0.14571564  0.03573547  0.14532746  0.00703447],\n",
      "    |     Bias [1.77423281 1.77369671 1.77419519 1.77385024 1.77422838]\n",
      "Iterate 358: Cost 0.3274738837867762,   \n",
      "  |    Weight  [-0.02212096  0.14583557  0.0355599   0.14544941  0.00678177],\n",
      "    |     Bias [1.77899913 1.77846207 1.77896195 1.7786161  1.778995  ]\n",
      "Iterate 359: Cost 0.32736007952105683,   \n",
      "  |    Weight  [-0.02245137  0.14595545  0.03538436  0.14557133  0.00652912],\n",
      "    |     Bias [1.78376449 1.78322648 1.78372775 1.783381   1.78376068]\n",
      "Iterate 360: Cost 0.32724632084583793,   \n",
      "  |    Weight  [-0.02278172  0.14607528  0.03520883  0.14569323  0.0062765 ],\n",
      "    |     Bias [1.78852889 1.78798993 1.78849259 1.78814495 1.78852539]\n",
      "Iterate 361: Cost 0.32713260774285285,   \n",
      "  |    Weight  [-0.02311201  0.14619508  0.03503333  0.14581509  0.00602393],\n",
      "    |     Bias [1.79329234 1.79275243 1.79325648 1.79290795 1.79328916]\n",
      "Iterate 362: Cost 0.3270189401938427,   \n",
      "  |    Weight  [-0.02344224  0.14631483  0.03485786  0.14593693  0.0057714 ],\n",
      "    |     Bias [1.79805483 1.79751398 1.79801942 1.79766999 1.79805196]\n",
      "Iterate 363: Cost 0.32690531818055535,   \n",
      "  |    Weight  [-0.02377242  0.14643453  0.03468241  0.14605875  0.00551892],\n",
      "    |     Bias [1.80281636 1.80227457 1.80278141 1.80243108 1.80281382]\n",
      "Iterate 364: Cost 0.3267917416847464,   \n",
      "  |    Weight  [-0.02410254  0.14655419  0.03450698  0.14618053  0.00526647],\n",
      "    |     Bias [1.80757694 1.80703421 1.80754244 1.80719121 1.80757472]\n",
      "Iterate 365: Cost 0.32667821068817854,   \n",
      "  |    Weight  [-0.0244326   0.1466738   0.03433158  0.14630229  0.00501407],\n",
      "    |     Bias [1.81233656 1.8117929  1.81230252 1.8119504  1.81233466]\n",
      "Iterate 366: Cost 0.326564725172622,   \n",
      "  |    Weight  [-0.0247626   0.14679338  0.0341562   0.14642402  0.00476171],\n",
      "    |     Bias [1.81709522 1.81655063 1.81706164 1.81670863 1.81709365]\n",
      "Iterate 367: Cost 0.326451285119854,   \n",
      "  |    Weight  [-0.02509254  0.1469129   0.03398084  0.14654572  0.00450939],\n",
      "    |     Bias [1.82185293 1.82130742 1.82181981 1.82146591 1.82185169]\n",
      "Iterate 368: Cost 0.3263378905116592,   \n",
      "  |    Weight  [-0.02542243  0.14703239  0.03380551  0.1466674   0.00425712],\n",
      "    |     Bias [1.82660969 1.82606324 1.82657703 1.82622223 1.82660877]\n",
      "Iterate 369: Cost 0.3262245413298298,   \n",
      "  |    Weight  [-0.02575226  0.14715183  0.03363021  0.14678905  0.00400488],\n",
      "    |     Bias [1.83136549 1.83081812 1.8313333  1.83097761 1.8313649 ]\n",
      "Iterate 370: Cost 0.3261112375561648,   \n",
      "  |    Weight  [-0.02608203  0.14727122  0.03345493  0.14691067  0.00375269],\n",
      "    |     Bias [1.83612033 1.83557205 1.83608862 1.83573203 1.83612008]\n",
      "Iterate 371: Cost 0.3259979791724709,   \n",
      "  |    Weight  [-0.02641174  0.14739057  0.03327967  0.14703226  0.00350054],\n",
      "    |     Bias [1.84087422 1.84032502 1.84084298 1.8404855  1.8408743 ]\n",
      "Iterate 372: Cost 0.32588476616056195,   \n",
      "  |    Weight  [-0.02674139  0.14750988  0.03310444  0.14715383  0.00324843],\n",
      "    |     Bias [1.84562716 1.84507704 1.84559639 1.84523802 1.84562757]\n",
      "Iterate 373: Cost 0.32577159850225895,   \n",
      "  |    Weight  [-0.02707098  0.14762914  0.03292923  0.14727537  0.00299636],\n",
      "    |     Bias [1.85037914 1.84982811 1.85034885 1.84998959 1.85037989]\n",
      "Iterate 374: Cost 0.3256584761793906,   \n",
      "  |    Weight  [-0.02740052  0.14774836  0.03275404  0.14739688  0.00274434],\n",
      "    |     Bias [1.85513016 1.85457823 1.85510036 1.85474021 1.85513125]\n",
      "Iterate 375: Cost 0.3255453991737924,   \n",
      "  |    Weight  [-0.02773     0.14786753  0.03257888  0.14751836  0.00249236],\n",
      "    |     Bias [1.85988023 1.8593274  1.85985092 1.85948988 1.85988166]\n",
      "Iterate 376: Cost 0.3254323674673074,   \n",
      "  |    Weight  [-0.02805942  0.14798666  0.03240375  0.14763982  0.00224042],\n",
      "    |     Bias [1.86462935 1.86407561 1.86460053 1.86423859 1.86463113]\n",
      "Iterate 377: Cost 0.32531938104178587,   \n",
      "  |    Weight  [-0.02838878  0.14810574  0.03222863  0.14776125  0.00198852],\n",
      "    |     Bias [1.86937752 1.86882288 1.86934918 1.86898636 1.86937963]\n",
      "Iterate 378: Cost 0.3252064398790853,   \n",
      "  |    Weight  [-0.02871809  0.14822479  0.03205354  0.14788265  0.00173666],\n",
      "    |     Bias [1.87412473 1.87356919 1.87409689 1.87373318 1.87412719]\n",
      "Iterate 379: Cost 0.3250935439610705,   \n",
      "  |    Weight  [-0.02904733  0.14834378  0.03187848  0.14800403  0.00148485],\n",
      "    |     Bias [1.87887099 1.87831456 1.87884364 1.87847904 1.8788738 ]\n",
      "Iterate 380: Cost 0.32498069326961354,   \n",
      "  |    Weight  [-0.02937652  0.14846274  0.03170344  0.14812538  0.00123307],\n",
      "    |     Bias [1.88361629 1.88305897 1.88358945 1.88322396 1.88361945]\n",
      "Iterate 381: Cost 0.32486788778659376,   \n",
      "  |    Weight  [-0.02970565  0.14858164  0.03152842  0.1482467   0.00098134],\n",
      "    |     Bias [1.88836064 1.88780244 1.8883343  1.88796792 1.88836415]\n",
      "Iterate 382: Cost 0.3247551274938977,   \n",
      "  |    Weight  [-0.03003472  0.14870051  0.03135343  0.14836799  0.00072965],\n",
      "    |     Bias [1.89310404 1.89254495 1.89307821 1.89271094 1.8931079 ]\n",
      "Iterate 383: Cost 0.32464241237341923,   \n",
      "  |    Weight  [-0.03036374  0.14881933  0.03117846  0.14848926  0.000478  ],\n",
      "    |     Bias [1.89784649 1.89728652 1.89782116 1.89745301 1.89785071]\n",
      "Iterate 384: Cost 0.32452974240705956,   \n",
      "  |    Weight  [-0.03069269  0.14893811  0.03100352  0.1486105   0.0002264 ],\n",
      "    |     Bias [1.90258798 1.90202713 1.90256317 1.90219413 1.90259256]\n",
      "Iterate 385: Cost 0.3244171175767269,   \n",
      "  |    Weight  [-3.10215933e-02  1.49056838e-01  3.08286005e-02  1.48731709e-01\n",
      " -2.51647581e-05],\n",
      "    |     Bias [1.90732853 1.9067668  1.90730422 1.9069343  1.90733346]\n",
      "Iterate 386: Cost 0.3243045378643369,   \n",
      "  |    Weight  [-0.03135043  0.14917553  0.0306537   0.14885289 -0.00027669],\n",
      "    |     Bias [1.91206812 1.91150552 1.91204433 1.91167352 1.91207341]\n",
      "Iterate 387: Cost 0.32419200325181236,   \n",
      "  |    Weight  [-0.03167922  0.14929417  0.03047883  0.14897405 -0.00052817],\n",
      "    |     Bias [1.91680676 1.91624329 1.91678349 1.91641179 1.91681241]\n",
      "Iterate 388: Cost 0.32407951372108346,   \n",
      "  |    Weight  [-0.03200794  0.14941277  0.03030399  0.14909518 -0.0007796 ],\n",
      "    |     Bias [1.92154444 1.92098011 1.9215217  1.92114912 1.92155046]\n",
      "Iterate 389: Cost 0.3239670692540875,   \n",
      "  |    Weight  [-0.03233661  0.14953133  0.03012916  0.14921629 -0.001031  ],\n",
      "    |     Bias [1.92628118 1.92571598 1.92625896 1.92588549 1.92628756]\n",
      "Iterate 390: Cost 0.32385466983276906,   \n",
      "  |    Weight  [-0.03266522  0.14964984  0.02995436  0.14933736 -0.00128236],\n",
      "    |     Bias [1.93101696 1.9304509  1.93099528 1.93062092 1.93102371]\n",
      "Iterate 391: Cost 0.3237423154390798,   \n",
      "  |    Weight  [-0.03299377  0.14976831  0.02977959  0.14945841 -0.00153367],\n",
      "    |     Bias [1.9357518  1.93518488 1.93573064 1.9353554  1.93575891]\n",
      "Iterate 392: Cost 0.323630006054979,   \n",
      "  |    Weight  [-0.03332226  0.14988673  0.02960484  0.14957943 -0.00178494],\n",
      "    |     Bias [1.94048568 1.93991791 1.94046506 1.94008893 1.94049316]\n",
      "Iterate 393: Cost 0.3235177416624327,   \n",
      "  |    Weight  [-0.0336507   0.15000511  0.02943011  0.14970043 -0.00203617],\n",
      "    |     Bias [1.94521861 1.94464999 1.94519853 1.94482152 1.94522646]\n",
      "Iterate 394: Cost 0.3234055222434145,   \n",
      "  |    Weight  [-0.03397907  0.15012345  0.02925541  0.14982139 -0.00228736],\n",
      "    |     Bias [1.9499506  1.94938112 1.94993105 1.94955316 1.94995882]\n",
      "Iterate 395: Cost 0.3232933477799052,   \n",
      "  |    Weight  [-0.03430739  0.15024174  0.02908073  0.14994233 -0.0025385 ],\n",
      "    |     Bias [1.95468163 1.9541113  1.95466262 1.95428385 1.95469023]\n",
      "Iterate 396: Cost 0.3231812182538925,   \n",
      "  |    Weight  [-0.03463565  0.15035999  0.02890607  0.15006325 -0.00278961],\n",
      "    |     Bias [1.95941171 1.95884054 1.95939325 1.95901359 1.95942068]\n",
      "Iterate 397: Cost 0.3230691336473716,   \n",
      "  |    Weight  [-0.03496386  0.15047819  0.02873144  0.15018413 -0.00304067],\n",
      "    |     Bias [1.96414084 1.96356883 1.96412293 1.96374239 1.96415019]\n",
      "Iterate 398: Cost 0.32295709394234506,   \n",
      "  |    Weight  [-0.035292    0.15059635  0.02855684  0.15030499 -0.00329169],\n",
      "    |     Bias [1.96886902 1.96829618 1.96885166 1.96847024 1.96887876]\n",
      "Iterate 399: Cost 0.32284509912082227,   \n",
      "  |    Weight  [-0.03562009  0.15071447  0.02838225  0.15042582 -0.00354267],\n",
      "    |     Bias [1.97359626 1.97302258 1.97357945 1.97319715 1.97360637]\n",
      "Iterate 400: Cost 0.32273314916482,   \n",
      "  |    Weight  [-0.03594812  0.15083254  0.02820769  0.15054663 -0.0037936 ],\n",
      "    |     Bias [1.97832254 1.97774803 1.97830629 1.97792311 1.97833304]\n"
     ]
    }
   ],
   "source": [
    "y2 = y_train.iloc[:,2:3].values.reshape(-1,1)\n",
    "equation3 =  gradient_descent(x,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def metrics(predictions, Y_test):\n",
    "\n",
    "    \n",
    "    M_A_E = np.mean(np.abs(predictions-Y_test)) #calculating mean absolute error\n",
    "\n",
    "    M_S_E = np.square(np.subtract(Y_test,predictions)).mean()  #calculating root mean square error\n",
    "    \n",
    "    R_M_S_E = math.sqrt(M_S_E)\n",
    "\n",
    "    #calculating r_square\n",
    "    rss = np.sum(np.square((Y_test- predictions)))\n",
    "    mean = np.mean(Y_test)\n",
    "    sst = np.sum(np.square(Y_test-mean))\n",
    "    r_square = 1 - (rss/sst)\n",
    "    \n",
    "\n",
    "    return M_A_E, R_M_S_E, r_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regularization (L1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Lasso Regularization Function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def lasso_Regularization(X,y,alpha = 0.01, lambda_val = 0.1,epochs= 5000, TOL = 1e-7) :\n",
    "    m = np.shape(X)[0]\n",
    "    n = np.shape(X)[1]\n",
    "    X = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
    "    W = np.random.randn(n + 1, 1)\n",
    "    c_list = [Cost_Function(X,y,alpha,W)]\n",
    "    W_list= [W]\n",
    "    for i in np.arange(epochs):\n",
    "        if i%100 == 0:\n",
    "            print(f'{i:5d}\\t{c_list[-1]:7.4f}\\t')\n",
    "        y_estimatedValue = X.dot(W)\n",
    "        error = y_estimatedValue - y\n",
    "        ridge_regre_term = (lambda_val / 2 * m) * np.sum(W)\n",
    "        cost = (np.sum(np.square(error)))/(2*m) + ridge_regre_term\n",
    "        gradient = (1 / m) * (X.T.dot(error) + (lambda_val*W))\n",
    "        W_new = W - alpha * gradient\n",
    "        W_list.append(W_new)\n",
    "        c_list.append(cost)\n",
    "        if np.sum((W_new - W)**2) < TOL:\n",
    "          print('Convergence achieved in Lasso Regularization.')\n",
    "          break\n",
    "        W = W_new\n",
    "    return W_new,W_list, c_list\n",
    "\n",
    "def Cost_Function(X, y, lamda_value, theta):\n",
    "  m = len(y)\n",
    "  ridge_regre_term = (lamda_value/2*m)*np.sum(theta**2)\n",
    "  error = np.dot(X,theta) - y\n",
    "  cost = (np.sum(np.square(error)))/(2*m) + ridge_regre_term\n",
    "  return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\t 7.9593\t\n",
      "  100\t 6.5319\t\n",
      "  200\t 5.3720\t\n",
      "  300\t 4.4243\t\n",
      "  400\t 3.6501\t\n",
      "  500\t 3.0175\t\n",
      "  600\t 2.5008\t\n",
      "  700\t 2.0786\t\n",
      "  800\t 1.7338\t\n",
      "  900\t 1.4520\t\n",
      " 1000\t 1.2219\t\n",
      " 1100\t 1.0339\t\n",
      " 1200\t 0.8803\t\n",
      " 1300\t 0.7548\t\n",
      " 1400\t 0.6523\t\n",
      " 1500\t 0.5685\t\n",
      " 1600\t 0.5001\t\n",
      " 1700\t 0.4442\t\n",
      " 1800\t 0.3985\t\n",
      " 1900\t 0.3611\t\n",
      " 2000\t 0.3306\t\n",
      " 2100\t 0.3056\t\n",
      " 2200\t 0.2852\t\n",
      " 2300\t 0.2684\t\n",
      " 2400\t 0.2547\t\n",
      " 2500\t 0.2435\t\n",
      "Convergence achieved in Lasso Regularization.\n"
     ]
    }
   ],
   "source": [
    "W, W_list, j_l = lasso_Regularization(x,y0,alpha=0.001,lambda_val=0.001,epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c552eeccd0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(j_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, beta):\n",
    "    return X_test.dot(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.099362 , -0.085577 , -0.14391  , -0.10402  ,  0.29407  ],\n",
       "       [-0.16614  ,  0.27708  , -0.19033  , -0.056387 , -0.13422  ],\n",
       "       [-0.25278  , -0.085391 , -0.096496 ,  0.42242  , -0.27044  ],\n",
       "       [ 0.072448 ,  0.55437  , -0.046507 ,  0.32599  , -0.33308  ],\n",
       "       [-0.26697  , -0.10882  ,  0.038903 ,  0.21548  , -0.44817  ],\n",
       "       [-0.026047 , -0.11385  , -0.21647  , -0.27754  , -0.50857  ],\n",
       "       [-0.26957  , -0.1741   , -0.16534  ,  0.34008  , -0.34401  ],\n",
       "       [ 0.058377 ,  0.21905  , -0.13063  , -0.28932  , -0.18443  ],\n",
       "       [ 0.064301 ,  0.11323  ,  0.012695 ,  0.14594  , -0.22967  ],\n",
       "       [-0.20489  , -0.0095122,  0.09632  , -0.063046 , -0.21177  ],\n",
       "       [ 0.11231  ,  0.18911  , -0.27253  ,  0.25377  , -0.23738  ],\n",
       "       [ 0.010858 , -0.093202 ,  0.17802  ,  0.14902  , -0.19984  ],\n",
       "       [ 0.057883 ,  0.056138 ,  0.11567  , -0.11862  ,  0.06563  ],\n",
       "       [ 0.094047 , -0.33348  , -0.18819  ,  0.12699  ,  0.090238 ],\n",
       "       [ 0.38607  ,  0.36486  ,  0.11839  , -0.095188 ,  0.11336  ],\n",
       "       [-0.43027  , -0.097851 , -0.12563  , -0.052929 ,  0.22546  ],\n",
       "       [-0.10134  , -0.062144 , -0.1397   , -0.24258  ,  0.055439 ],\n",
       "       [ 0.10071  ,  0.40447  ,  0.076967 , -0.19482  ,  0.10515  ],\n",
       "       [-0.10331  , -0.094876 ,  0.14224  ,  0.41666  , -0.032058 ],\n",
       "       [-0.052583 , -0.24533  ,  0.17994  ,  0.21202  ,  0.14517  ],\n",
       "       [ 0.2429   , -0.023089 ,  0.01348  , -0.5658   ,  0.1054   ],\n",
       "       [-0.18724  ,  0.24639  , -0.074786 ,  0.0572   ,  0.49143  ],\n",
       "       [ 0.069239 ,  0.37695  ,  0.27821  ,  0.1042   ,  0.14269  ],\n",
       "       [-0.50297  , -0.19121  , -0.051006 , -0.057027 ,  0.32464  ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.shape(x)[0]\n",
    "x = np.concatenate((np.ones((m, 1)), x), axis=1)\n",
    "predictions = predict(x, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.92994313],\n",
       "       [3.08700314],\n",
       "       [2.86761314],\n",
       "       [3.02581306],\n",
       "       [2.93353352],\n",
       "       [3.13291112],\n",
       "       [2.9007592 ],\n",
       "       [3.13175278],\n",
       "       [2.95269506],\n",
       "       [2.98530378],\n",
       "       [2.99008858],\n",
       "       [2.87080516],\n",
       "       [2.94913667],\n",
       "       [2.83714017],\n",
       "       [2.98441413],\n",
       "       [2.93816997],\n",
       "       [3.02083679],\n",
       "       [3.0493361 ],\n",
       "       [2.76989533],\n",
       "       [2.75752498],\n",
       "       [3.07286529],\n",
       "       [2.91030439],\n",
       "       [2.90617617],\n",
       "       [2.88999399]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y1 curve metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  0.5004841763651399\n",
      "Root Mean Square Error:  0.6503250735569945\n",
      "R square:  -0.5145862393908689\n"
     ]
    }
   ],
   "source": [
    "m_a_e, r_m_s_e, r_square = metrics(predictions, y0)\n",
    "\n",
    "print(\"Mean Absolute Error: \", m_a_e)\n",
    "print(\"Root Mean Square Error: \", r_m_s_e)\n",
    "print(\"R square: \", r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y2 curve metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  0.5662818625171845\n",
      "Root Mean Square Error:  0.7201170906960122\n",
      "R square:  -0.9594314061082005\n"
     ]
    }
   ],
   "source": [
    "m_a_e, r_m_s_e, r_square = metrics(predictions, y1)\n",
    "print(\"Mean Absolute Error: \", m_a_e)\n",
    "print(\"Root Mean Square Error: \", r_m_s_e)\n",
    "print(\"R square: \", r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y3 curve metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  22.653166013588102\n",
      "Root Mean Square Error:  24.49740948692826\n",
      "R square:  -5.897726188569176\n"
     ]
    }
   ],
   "source": [
    "m_a_e, r_m_s_e, r_square = metrics(predictions, y2)\n",
    "print(\"Mean Absolute Error: \", m_a_e)\n",
    "print(\"Root Mean Square Error: \", r_m_s_e)\n",
    "print(\"R square: \", r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regularization (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Ridge Regularization Function\n",
    "import numpy as np\n",
    "\n",
    "def ridge_regularization(X,y,alpha = 0.01, lambda_val = 0.1,epochs= 5000, TOL = 1e-7) :\n",
    "    m = np.shape(X)[0]\n",
    "    n = np.shape(X)[1]\n",
    "    X = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
    "    W = np.random.randn(n + 1, 1)\n",
    "    c_list = [Cost_Function(X,y,alpha,W)]\n",
    "    W_list= [W]\n",
    "    for i in np.arange(epochs):\n",
    "        if i%100 == 0:\n",
    "            print(f'{i:5d}\\t{c_list[-1]:7.4f}\\t')\n",
    "        y_estimatedValue = X.dot(W)\n",
    "        error = y_estimatedValue - y\n",
    "        ridge_regre_term = (lambda_val / 2 * m) * np.sum(np.square(W))\n",
    "        cost = (np.sum(np.square(error)))/(2*m) + ridge_regre_term\n",
    "        gradient = (1 / m) * (X.T.dot(error) + (lambda_val*W))\n",
    "        W_new = W - alpha * gradient\n",
    "        W_list.append(W_new)\n",
    "        c_list.append(cost)\n",
    "        if np.sum((W_new - W)**2) < TOL:\n",
    "          print('Convergence achieved in Ridge Regularization.')\n",
    "          break\n",
    "        W = W_new\n",
    "    return W_new,W_list, c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost_Function(X, y, lamda_value, theta):\n",
    "  m = len(y)\n",
    "  ridge_regre_term = (lamda_value/2*m)*np.sum(theta**2)\n",
    "  error = np.dot(X,theta) - y\n",
    "  cost = (np.sum(np.square(error)))/(2*m) + ridge_regre_term\n",
    "  return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\t 9.4358\t\n",
      "  100\t 7.8131\t\n",
      "  200\t 6.4740\t\n",
      "  300\t 5.3813\t\n",
      "  400\t 4.4897\t\n",
      "  500\t 3.7623\t\n",
      "  600\t 3.1688\t\n",
      "  700\t 2.6846\t\n",
      "  800\t 2.2896\t\n",
      "  900\t 1.9673\t\n",
      " 1000\t 1.7043\t\n",
      " 1100\t 1.4898\t\n",
      " 1200\t 1.3147\t\n",
      " 1300\t 1.1717\t\n",
      " 1400\t 1.0549\t\n",
      " 1500\t 0.9595\t\n",
      " 1600\t 0.8815\t\n",
      " 1700\t 0.8176\t\n",
      " 1800\t 0.7652\t\n",
      " 1900\t 0.7222\t\n",
      " 2000\t 0.6868\t\n",
      " 2100\t 0.6576\t\n",
      " 2200\t 0.6334\t\n",
      " 2300\t 0.6134\t\n",
      " 2400\t 0.5966\t\n",
      " 2500\t 0.5826\t\n",
      " 2600\t 0.5707\t\n",
      " 2700\t 0.5606\t\n",
      "Convergence achieved in Ridge Regularization.\n"
     ]
    }
   ],
   "source": [
    "x = X_train.to_numpy()\n",
    "W, W_list, j_l = ridge_regularization(x,y0,alpha=0.001,lambda_val=0.001,epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c552f9ffd0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(j_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, beta):\n",
    "    return X_test.dot(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.099362 , -0.085577 , -0.14391  , -0.10402  ,  0.29407  ],\n",
       "       [-0.16614  ,  0.27708  , -0.19033  , -0.056387 , -0.13422  ],\n",
       "       [-0.25278  , -0.085391 , -0.096496 ,  0.42242  , -0.27044  ],\n",
       "       [ 0.072448 ,  0.55437  , -0.046507 ,  0.32599  , -0.33308  ],\n",
       "       [-0.26697  , -0.10882  ,  0.038903 ,  0.21548  , -0.44817  ],\n",
       "       [-0.026047 , -0.11385  , -0.21647  , -0.27754  , -0.50857  ],\n",
       "       [-0.26957  , -0.1741   , -0.16534  ,  0.34008  , -0.34401  ],\n",
       "       [ 0.058377 ,  0.21905  , -0.13063  , -0.28932  , -0.18443  ],\n",
       "       [ 0.064301 ,  0.11323  ,  0.012695 ,  0.14594  , -0.22967  ],\n",
       "       [-0.20489  , -0.0095122,  0.09632  , -0.063046 , -0.21177  ],\n",
       "       [ 0.11231  ,  0.18911  , -0.27253  ,  0.25377  , -0.23738  ],\n",
       "       [ 0.010858 , -0.093202 ,  0.17802  ,  0.14902  , -0.19984  ],\n",
       "       [ 0.057883 ,  0.056138 ,  0.11567  , -0.11862  ,  0.06563  ],\n",
       "       [ 0.094047 , -0.33348  , -0.18819  ,  0.12699  ,  0.090238 ],\n",
       "       [ 0.38607  ,  0.36486  ,  0.11839  , -0.095188 ,  0.11336  ],\n",
       "       [-0.43027  , -0.097851 , -0.12563  , -0.052929 ,  0.22546  ],\n",
       "       [-0.10134  , -0.062144 , -0.1397   , -0.24258  ,  0.055439 ],\n",
       "       [ 0.10071  ,  0.40447  ,  0.076967 , -0.19482  ,  0.10515  ],\n",
       "       [-0.10331  , -0.094876 ,  0.14224  ,  0.41666  , -0.032058 ],\n",
       "       [-0.052583 , -0.24533  ,  0.17994  ,  0.21202  ,  0.14517  ],\n",
       "       [ 0.2429   , -0.023089 ,  0.01348  , -0.5658   ,  0.1054   ],\n",
       "       [-0.18724  ,  0.24639  , -0.074786 ,  0.0572   ,  0.49143  ],\n",
       "       [ 0.069239 ,  0.37695  ,  0.27821  ,  0.1042   ,  0.14269  ],\n",
       "       [-0.50297  , -0.19121  , -0.051006 , -0.057027 ,  0.32464  ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.shape(x)[0]\n",
    "x = np.concatenate((np.ones((m, 1)), x), axis=1)\n",
    "predictions = predict(x, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.28091863],\n",
       "       [2.6814531 ],\n",
       "       [3.90855928],\n",
       "       [4.17690575],\n",
       "       [3.53147855],\n",
       "       [2.87082909],\n",
       "       [3.78917559],\n",
       "       [2.55453808],\n",
       "       [3.67692232],\n",
       "       [2.66236011],\n",
       "       [4.09670989],\n",
       "       [3.55544787],\n",
       "       [2.67612388],\n",
       "       [3.47880976],\n",
       "       [3.20590933],\n",
       "       [1.88922358],\n",
       "       [2.18532296],\n",
       "       [2.46178488],\n",
       "       [3.8441352 ],\n",
       "       [3.25641768],\n",
       "       [1.89667463],\n",
       "       [2.22742379],\n",
       "       [3.06002492],\n",
       "       [1.64183295]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y1 curve metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  0.6861427396520571\n",
      "Root Mean Square Error:  0.8058512134310005\n",
      "R square:  -1.325641334411097\n"
     ]
    }
   ],
   "source": [
    "m_a_e, r_m_s_e, r_square = metrics(predictions, y0)\n",
    "\n",
    "print(\"Mean Absolute Error: \", m_a_e)\n",
    "print(\"Root Mean Square Error: \", r_m_s_e)\n",
    "print(\"R square: \", r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y2 curve metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  0.8832399384700489\n",
      "Root Mean Square Error:  1.0312951856473391\n",
      "R square:  -3.0187390684793334\n"
     ]
    }
   ],
   "source": [
    "m_a_e, r_m_s_e, r_square = metrics(predictions, y1)\n",
    "\n",
    "print(\"Mean Absolute Error: \", m_a_e)\n",
    "print(\"Root Mean Square Error: \", r_m_s_e)\n",
    "print(\"R square: \", r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y3 curve metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  22.623375755821343\n",
      "Root Mean Square Error:  24.484612813252973\n",
      "R square:  -5.8905217617511045\n"
     ]
    }
   ],
   "source": [
    "m_a_e, r_m_s_e, r_square = metrics(predictions, y2)\n",
    "\n",
    "print(\"Mean Absolute Error: \", m_a_e)\n",
    "print(\"Root Mean Square Error: \", r_m_s_e)\n",
    "print(\"R square: \", r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Elastic Net Regularization (L1 & L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Elastic Net Regularization Function\n",
    "import numpy as np\n",
    "\n",
    "def elastic_Regularization(X,y,alpha = 0.01, lambda_val = 0.1,epochs= 5000, TOL = 1e-7) :\n",
    "    m = np.shape(X)[0]\n",
    "    n = np.shape(X)[1]\n",
    "    X = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
    "    W = np.random.randn(n + 1, 1)\n",
    "    c_list = [Cost_Function(X,y,alpha,W)]\n",
    "    W_list= [W]\n",
    "    for i in np.arange(epochs):\n",
    "        if i%100 == 0:\n",
    "            print(f'{i:5d}\\t{c_list[-1]:7.4f}\\t')\n",
    "        y_estimatedValue = X.dot(W)\n",
    "        error = y_estimatedValue - y\n",
    "        ridge_regre_term = (lambda_val / 2 * m) * np.sum(np.square(W))\n",
    "        cost = (np.sum(np.square(error)))/(2*m) + ridge_regre_term + np.sum(W)\n",
    "        gradient = (1 / m) * (X.T.dot(error) + (lambda_val*W))\n",
    "        W_new = W - alpha * gradient\n",
    "        W_list.append(W_new)\n",
    "        c_list.append(cost)\n",
    "        if np.sum((W_new - W)**2) < TOL:\n",
    "          print('Convergence achieved in Elastic Net Regularization.')\n",
    "          break\n",
    "        W = W_new\n",
    "    return W_new,W_list, c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost_Function(X, y, lamda_value, theta):\n",
    "  m = len(y)\n",
    "  ridge_regre_term = (lamda_value/2*m)*np.sum(theta**2)\n",
    "  error = np.dot(X,theta) - y\n",
    "  cost = (np.sum(np.square(error)))/(2*m) + ridge_regre_term\n",
    "  return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\t12.0268\t\n",
      "  100\t 8.4648\t\n",
      "  200\t 7.0898\t\n",
      "  300\t 6.0037\t\n",
      "  400\t 5.1500\t\n",
      "  500\t 4.4831\t\n",
      "  600\t 3.9660\t\n",
      "  700\t 3.5685\t\n",
      "  800\t 3.2665\t\n",
      "  900\t 3.0404\t\n",
      " 1000\t 2.8743\t\n",
      " 1100\t 2.7555\t\n",
      " 1200\t 2.6738\t\n",
      " 1300\t 2.6210\t\n",
      " 1400\t 2.5904\t\n",
      " 1500\t 2.5770\t\n",
      " 1600\t 2.5763\t\n",
      " 1700\t 2.5853\t\n",
      " 1800\t 2.6012\t\n",
      " 1900\t 2.6220\t\n",
      " 2000\t 2.6461\t\n",
      " 2100\t 2.6723\t\n",
      " 2200\t 2.6995\t\n",
      " 2300\t 2.7272\t\n",
      " 2400\t 2.7547\t\n",
      " 2500\t 2.7816\t\n",
      " 2600\t 2.8078\t\n",
      " 2700\t 2.8328\t\n",
      "Convergence achieved in Elastic Net Regularization.\n"
     ]
    }
   ],
   "source": [
    "x = X_train.to_numpy()\n",
    "W, W_list, j_l = elastic_Regularization(x,y0,alpha=0.001,lambda_val=0.001,epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c553fdd880>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(j_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, beta):\n",
    "    return X_test.dot(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.099362 , -0.085577 , -0.14391  , -0.10402  ,  0.29407  ],\n",
       "       [-0.16614  ,  0.27708  , -0.19033  , -0.056387 , -0.13422  ],\n",
       "       [-0.25278  , -0.085391 , -0.096496 ,  0.42242  , -0.27044  ],\n",
       "       [ 0.072448 ,  0.55437  , -0.046507 ,  0.32599  , -0.33308  ],\n",
       "       [-0.26697  , -0.10882  ,  0.038903 ,  0.21548  , -0.44817  ],\n",
       "       [-0.026047 , -0.11385  , -0.21647  , -0.27754  , -0.50857  ],\n",
       "       [-0.26957  , -0.1741   , -0.16534  ,  0.34008  , -0.34401  ],\n",
       "       [ 0.058377 ,  0.21905  , -0.13063  , -0.28932  , -0.18443  ],\n",
       "       [ 0.064301 ,  0.11323  ,  0.012695 ,  0.14594  , -0.22967  ],\n",
       "       [-0.20489  , -0.0095122,  0.09632  , -0.063046 , -0.21177  ],\n",
       "       [ 0.11231  ,  0.18911  , -0.27253  ,  0.25377  , -0.23738  ],\n",
       "       [ 0.010858 , -0.093202 ,  0.17802  ,  0.14902  , -0.19984  ],\n",
       "       [ 0.057883 ,  0.056138 ,  0.11567  , -0.11862  ,  0.06563  ],\n",
       "       [ 0.094047 , -0.33348  , -0.18819  ,  0.12699  ,  0.090238 ],\n",
       "       [ 0.38607  ,  0.36486  ,  0.11839  , -0.095188 ,  0.11336  ],\n",
       "       [-0.43027  , -0.097851 , -0.12563  , -0.052929 ,  0.22546  ],\n",
       "       [-0.10134  , -0.062144 , -0.1397   , -0.24258  ,  0.055439 ],\n",
       "       [ 0.10071  ,  0.40447  ,  0.076967 , -0.19482  ,  0.10515  ],\n",
       "       [-0.10331  , -0.094876 ,  0.14224  ,  0.41666  , -0.032058 ],\n",
       "       [-0.052583 , -0.24533  ,  0.17994  ,  0.21202  ,  0.14517  ],\n",
       "       [ 0.2429   , -0.023089 ,  0.01348  , -0.5658   ,  0.1054   ],\n",
       "       [-0.18724  ,  0.24639  , -0.074786 ,  0.0572   ,  0.49143  ],\n",
       "       [ 0.069239 ,  0.37695  ,  0.27821  ,  0.1042   ,  0.14269  ],\n",
       "       [-0.50297  , -0.19121  , -0.051006 , -0.057027 ,  0.32464  ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.shape(x)[0]\n",
    "x = np.concatenate((np.ones((m, 1)), x), axis=1)\n",
    "predictions2 = predict(x, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.96536528],\n",
       "       [3.20889767],\n",
       "       [2.82398038],\n",
       "       [3.17892242],\n",
       "       [2.81303623],\n",
       "       [3.12029616],\n",
       "       [2.84811198],\n",
       "       [3.22438969],\n",
       "       [2.95502502],\n",
       "       [2.89859507],\n",
       "       [3.12866481],\n",
       "       [2.74452541],\n",
       "       [2.91966392],\n",
       "       [2.8096703 ],\n",
       "       [3.07806018],\n",
       "       [2.93207527],\n",
       "       [3.03990707],\n",
       "       [3.14888809],\n",
       "       [2.66412497],\n",
       "       [2.60999452],\n",
       "       [3.0744321 ],\n",
       "       [3.03331161],\n",
       "       [2.92165636],\n",
       "       [2.82987131]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y1 curve metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  0.6861427396520571\n",
      "Root Mean Square Error:  0.8058512134310005\n",
      "R square:  -1.325641334411097\n"
     ]
    }
   ],
   "source": [
    "m_a_e, r_m_s_e, r_square = metrics(predictions, y0)\n",
    "\n",
    "print(\"Mean Absolute Error: \", m_a_e)\n",
    "print(\"Root Mean Square Error: \", r_m_s_e)\n",
    "print(\"R square: \", r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y2 curve metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  0.8832399384700489\n",
      "Root Mean Square Error:  1.0312951856473391\n",
      "R square:  -3.0187390684793334\n"
     ]
    }
   ],
   "source": [
    "m_a_e, r_m_s_e, r_square = metrics(predictions, y1)\n",
    "\n",
    "print(\"Mean Absolute Error: \", m_a_e)\n",
    "print(\"Root Mean Square Error: \", r_m_s_e)\n",
    "print(\"R square: \", r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y3 curve metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  22.623375755821343\n",
      "Root Mean Square Error:  24.484612813252973\n",
      "R square:  -5.8905217617511045\n"
     ]
    }
   ],
   "source": [
    "m_a_e, r_m_s_e, r_square = metrics(predictions, y2)\n",
    "\n",
    "print(\"Mean Absolute Error: \", m_a_e)\n",
    "print(\"Root Mean Square Error: \", r_m_s_e)\n",
    "print(\"R square: \", r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparision & Conclusion:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From above we got the results for all the models as shown below\n",
    "\n",
    "Lasso Regularization (L1)\n",
    "\n",
    "Y1:\n",
    "Mean Absolute Error:  0.5342351867601477\n",
    "Root Mean Square Error:  0.7057092436296123\n",
    "R square:  -0.7835472586411634\n",
    "    \n",
    "Y2:\n",
    "Mean Absolute Error:  0.6126517594186947\n",
    "Root Mean Square Error:  0.7608804491172393\n",
    "R square:  -1.187543401176061\n",
    "    \n",
    "Y3:\n",
    "Mean Absolute Error:  22.64843987463401\n",
    "Root Mean Square Error:  24.493197792905043\n",
    "R square:  -5.895354622311516\n",
    "\n",
    "Ridge Regularization (L2)\n",
    "\n",
    "Y1:\n",
    "Mean Absolute Error:  0.5336276980695486\n",
    "Root Mean Square Error:  0.6534776199235621\n",
    "R square:  -0.5293061904459011\n",
    "    \n",
    "Y2:\n",
    "Mean Absolute Error:  0.6675893375336684\n",
    "Root Mean Square Error:  0.8241998845327354\n",
    "R square:  -1.5667816562877177\n",
    "    \n",
    "Y3:\n",
    "Mean Absolute Error:  22.655335883066538\n",
    "Root Mean Square Error:  24.509791964488464\n",
    "R square:  -5.9047010097826895\n",
    "\n",
    "Computing Elastic Net Regularization (L1 & L2)\n",
    "\n",
    "Y1:\n",
    "Mean Absolute Error:  0.5336276980695486\n",
    "Root Mean Square Error:  0.6534776199235621\n",
    "R square:  -0.5293061904459011\n",
    "    \n",
    "Y2:\n",
    "Mean Absolute Error:  0.6675893375336684\n",
    "Root Mean Square Error:  0.8241998845327354\n",
    "R square:  -1.5667816562877177\n",
    "    \n",
    "Y3:\n",
    "Mean Absolute Error:  22.655335883066538\n",
    "Root Mean Square Error:  24.509791964488464\n",
    "R square:  -5.9047010097826895\n",
    "\n",
    "\n",
    "From above models we observe that Ridge Regularization (L2) and Computing Elastic Net Regularization (L1 & L2) have better accuracy compared to Lasso Regularization (L1) using Gradient Descent.\n",
    "\n",
    "So we can conclude that Ridge Regularization gives us the best fit model which is having low bias and low variance so that bias and variance gets trade off by using cost function to minimize the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
